{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPb6VttdvMNOwIyau41qltE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/magnolia2001/Forest_Estimation/blob/main/notebooks/NNandCNN_FeatureNormalization_optimize.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 在划分训练集和测试集之前对特征进行标准化\n"
      ],
      "metadata": {
        "id": "FjqrJSYP6MZx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "PrFMkyfpaHR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3ffce62-b257-49f2-f480-0068063b57bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "MyDrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# 挂载 Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 检查挂载的路径结构\n",
        "!ls /content/drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "root_path = '/content/drive/My Drive/data/'\n",
        "path_images = f'{root_path}images/'\n",
        "path_masks = f'{root_path}masks/'"
      ],
      "metadata": {
        "id": "JRDi_LKk5Q9f"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datetime, os, cv2\n",
        "from matplotlib import pyplot as plt\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import mean_squared_error as mse, mean_absolute_error as mae, mean_absolute_percentage_error as mape\n",
        "# from keras.models import Sequential, load_model\n",
        "# from keras.layers import Dense, BatchNormalization, Dropout, InputLayer, Flatten, Conv2D, MaxPool2D, AveragePooling2D\n",
        "# from keras.callbacks import TensorBoard, ModelCheckpoint\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import Dense, BatchNormalization, Dropout, InputLayer, Flatten, Conv2D, MaxPool2D\n",
        "from tensorflow.keras.callbacks import TensorBoard, ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n"
      ],
      "metadata": {
        "id": "mBs7aC11PKVA"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.rcParams['font.sans-serif'] = 'SimHei'\n",
        "plt.rcParams['axes.unicode_minus'] = False"
      ],
      "metadata": {
        "id": "XbUjdpOlluvj"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 制作标签数据和特征数据\n",
        "\n",
        "# 窗口大小应为奇数，以保证标签在中间\n",
        "size = 5 #define window size should be odd so that the label is in the middle\n",
        "# 特征的形状，这里假设每个特征是一个大小为 (size, size) 的窗口，包含 6 个通道\n",
        "shape = (6, size, size) #define shape of features\n",
        "# np.ones(shape, dtype=None) 用于创建一个形状为 shape 的数组，并将所有元素初始化为 1.0\n",
        "# 其中 shape：指定数组的形状，通常是一个整数或元组。 dtype：指定数组元素的数据类型（可选）。如果不指定，默认使用 float64 类型。\n",
        "# labels1 用于存放标签数据（掩膜）, data1 用于存放提取的特征数据\n",
        "# np.ones(1)返回的是一个只有一个元素的数组，其中该元素值为 1。\n",
        "labels1 = np.ones(1) #array for labels\n",
        "# 创建了一个数组，形状为 shape 即 (6, 5, 5) 的 NumPy 数组，并且所有的元素值都被初始化为 1.0 。\n",
        "data1 = np.ones(shape) #array for features\n",
        "# 扩展维度，便于后续拼接操作\n",
        "data1 = np.expand_dims(data1, axis=0) #expand dimension to concatenate\n",
        "\n",
        "# 遍历目录中的图像（假设有 20 张图像, 具体数量还需要根据自己的情况修改）\n",
        "# 在 for j in range(20) 这个遍历过程中，区分 j < 10 和 j >= 10 的目的是为了处理不同的文件命名规则。\n",
        "# 对于小于 10 的文件名，文件名是 \"image_00X.npy\"，其中 X 是单个数字（0 到 9）。\n",
        "# 对于大于等于 10 的文件名，文件名是 \"image_0XY.npy\"，其中 XY 是两位数的数字（10 到 19）。\n",
        "\n",
        "# 对于每个图像和掩膜，筛选有效标签和有效遥感影像数据\n",
        "for j in range(142): #iterate over images in directory\n",
        "  if j < 10:\n",
        "    # 路径填写实际路径\n",
        "    X = np.load(f'{path_images}image_00'+ str(j) + '.npy')  # 读取遥感影像\n",
        "    y = np.load(f'{path_masks}mask_00'+ str(j) + '.npy')  # 读取掩膜数据\n",
        "    # 移除掩膜图像中的通道维度使其形状变为(height, width)\n",
        "    # y = y[0, :, :]  # 去掉通道维度，保留二维掩膜图像\n",
        "    # print(\"特征形状:\", X.shape) # 输出为： 特征形状: (6, 1024, 1024)\n",
        "    # print(\"掩膜形状:\", y.shape) # 输出为： 掩膜形状: (1024, 1024)\n",
        "\n",
        "    # 选择掩膜图像 y 中所有大于 0 的位置（即标签不为 0 的位置），并返回这些位置的索引。\n",
        "    # indices 数组返回 N 个元素，其中 N 为掩膜图像 y 中所有大于 0 的元素个数。每个元素都是一个长度为 2 的行向量，表示符合条件元素的行列索引。\n",
        "    # y > 0 是一个布尔条件，返回一个与 y 相同形状的布尔数组, 如果是大于 0，布尔值为 True，否则为 False。\n",
        "    # np.argwhere() 是 NumPy 库中的一个函数，它返回数组中满足某个条件的所有索引（行列坐标），即满足条件的元素的坐标位置。\n",
        "    # 这里 indices 是一个形状为 (N, 2) 的二维数组，每一行是 (y, x) 坐标. y 为行索引, x 为列索引\n",
        "    # indices = np.argwhere(y > 0) #select all values with label\n",
        "    # indices = np.argwhere(y > 0.78)\n",
        "    # indices = np.argwhere((y > 2.34) & (y < 127.58))\n",
        "\n",
        "    # 筛选掩膜中有效的标签（大于2.34且小于127.58），并且遥感影像中只要任何一个通道中存在无效值，就排除掉该像元及其对应的掩膜值\n",
        "    indices = np.argwhere((y > 2.34) & (y < 127.58) & (np.all(X != 0, axis=0)))  # 排除遥感影像中的无效值（0）\n",
        "\n",
        "\n",
        "    # indices_2d 是 indices 数组的一个切片，是一个 二维数组, 它包含了所有掩膜图像中标签值大于 0 的位置的 列索引。\n",
        "    # 切片操作 indices[:, 1:] 就是提取所有行中的第二列（即 行 和 列 坐标中的 列索引）。\n",
        "    # indices_2d = indices[:, 1:] #extract indices\n",
        "\n",
        "    # 初始化一个数组 ind_y 来收集符合条件的标签位置。\n",
        "    # np.ones(2) 会创建一个包含 2 个元素的数组，所有元素的值为 1. 。\n",
        "    # .reshape(-1, 2) 将该数组的形状重塑为 (-1, 2)，表示按列数为 2 进行重塑，-1 表示自动计算行数。由于只有 2 个元素，这会将数组变成形状为 (1, 2) 的二维数组。\n",
        "    ind_y = np.ones(2).reshape(-1,2) #array to collect indices\n",
        "\n",
        "    # 遍历掩膜中的每个标签位置\n",
        "    # for i in indices_2d: #iterate over indices\n",
        "    for i in indices:\n",
        "      # 提取图像块，并检查其形状。\n",
        "      # size//2 表示 size 除以 2 的整数部分，用于确定图像块中心点到边界的距离。右端点的值之所以加 1 是因为区间是左闭右开的,所以加 1 保证能取到右端点.\n",
        "      # 整个i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2)表达式计算出一个范围，用于选取以 (i[0], i[1])（标签的 y, x 坐标） 为中心，上下各延伸 size//2 个像素的区域。\n",
        "      # i[0] 是当前标签位置的 y 坐标（行索引）。i[1] 是当前标签位置的 x 坐标（列索引）。\n",
        "      # 利用 shape 确保当前窗口大小与指定的窗口大小一致\n",
        "      if shape == X[:, i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2) + 1].shape: #select only features with the same shape because of labels at the image border\n",
        "        temp = X[:, i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2) + 1] #save them temporary\n",
        "        # 将 temp 的维度扩展一个维度，使得它变成一个形状为 (1, channels, size, size) 的四维数组。扩展维度的目的是为了能够将 temp 与其他提取的窗口进行拼接。\n",
        "        temp2 = np.expand_dims(temp, axis=0) #expand dimension to concatenate\n",
        "        # 拼接特征数据\n",
        "        # data1 最终会变成 (num_samples, 6, 5, 5)，其中 num_samples 是提取的窗口数量。\n",
        "        data1 = np.concatenate((data1, temp2), axis=0) #concatenation\n",
        "        # 拼接标签索引\n",
        "        # i.reshape(-1, 2) 会把 i 重新调整为一个形状为 (1, 2) 的二维数组\n",
        "        # axis=0 表示在 第 0 维（行方向） 进行拼接，即新添加的行会被添加到原数组的最后。\n",
        "        # ind_y 则是一个 (num_samples, 2) 的数组，每个样本对应一个标签位置的 (y, x) 坐标。\n",
        "        ind_y = np.concatenate((ind_y, i.reshape(-1,2)), axis=0) #concatenation of index so that they have the same order and length as the features\n",
        "\n",
        "    # 去掉第一个虚拟值\n",
        "    # 初始时，ind_y 中的第一个元素是 np.ones(2).reshape(-1,2) 创建的虚拟数据。此步骤是将它移除，只保留实际的标签坐标。\n",
        "    ind_y = ind_y[1:] #remove first dummy values\n",
        "    # 提取所有的行索引\n",
        "    indices_1 = ind_y[:, 0].astype(int)\n",
        "    # 提取所有的列索引\n",
        "    indices_2 = ind_y[:, 1].astype(int)\n",
        "    # 提取标签值\n",
        "    # 从这句代码应该可以看出原作者的掩膜图像的形状包含了通道维度,即形状为(1, height, width)\n",
        "    # data_y = y[0, indices_1, indices_2] #extract labels\n",
        "    data_y = y[indices_1, indices_2]  # 提取标签\n",
        "    # 拼接标签，形成最终的标签数组。\n",
        "    labels1 = np.concatenate((labels1, data_y), axis = 0) #concatenate labels\n",
        "\n",
        "  if j >= 10 and j < 100:\n",
        "    X = np.load(f'{path_images}image_0'+ str(j) + '.npy')\n",
        "    y = np.load(f'{path_masks}mask_0'+ str(j) + '.npy')\n",
        "    # 移除掩膜图像中的通道维度使其形状变为(height, width)\n",
        "    # y = y[0, :, :]  # 去掉通道维度，保留二维掩膜图像\n",
        "    # indices = np.argwhere(y > 0)\n",
        "    # indices = np.argwhere(y > 0.78)\n",
        "    # indices = np.argwhere((y > 2.34) & (y < 127.58))\n",
        "    # 筛选掩膜中有效的标签（大于2.34且小于127.58），并且遥感影像中只要任何一个通道中存在无效值，就排除掉该像元及其对应的掩膜值\n",
        "    indices = np.argwhere((y > 2.34) & (y < 127.58) & (np.all(X != 0, axis=0)))  # 排除遥感影像中的无效值（0）\n",
        "\n",
        "    # indices_2d = indices[:, 1:]\n",
        "    ind_y = np.ones(2).reshape(-1,2)\n",
        "    # for i in indices_2d:\n",
        "    for i in indices:\n",
        "      if shape == X[:, i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2) + 1].shape:\n",
        "        temp = X[:, i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2) + 1]\n",
        "        temp2 = np.expand_dims(temp, axis=0)\n",
        "        data1 = np.concatenate((data1, temp2), axis=0)\n",
        "\n",
        "        ind_y = np.concatenate((ind_y, i.reshape(-1,2)), axis=0)\n",
        "\n",
        "    # 去掉第一个虚拟值\n",
        "    ind_y = ind_y[1:]\n",
        "    # 提取所有的行索引\n",
        "    indices_1 = ind_y[:, 0].astype(int)\n",
        "    # 提取所有的列索引\n",
        "    indices_2 = ind_y[:, 1].astype(int)\n",
        "    # data_y = y[0, indices_1, indices_2]\n",
        "    # 提取标签值\n",
        "    # 每一对 (indices_1[i], indices_2[i]) 会自动匹配，得到对应位置的标签值。\n",
        "    data_y = y[indices_1, indices_2]  # 提取标签\n",
        "    # 拼接标签，形成最终的标签数组。\n",
        "    labels1 = np.concatenate((labels1, data_y), axis = 0)\n",
        "\n",
        "  if j >= 100:\n",
        "    X = np.load(f'{path_images}image_'+ str(j) + '.npy')\n",
        "    y = np.load(f'{path_masks}mask_'+ str(j) + '.npy')\n",
        "    # 移除掩膜图像中的通道维度使其形状变为(height, width)\n",
        "    # y = y[0, :, :]  # 去掉通道维度，保留二维掩膜图像\n",
        "    # indices = np.argwhere(y > 0)\n",
        "    # indices = np.argwhere(y > 0.78)\n",
        "    # indices = np.argwhere((y > 2.34) & (y < 127.58))\n",
        "    # 筛选掩膜中有效的标签（大于2.34且小于127.58），并且遥感影像中只要任何一个通道中存在无效值，就排除掉该像元及其对应的掩膜值\n",
        "    indices = np.argwhere((y > 2.34) & (y < 127.58) & (np.all(X != 0, axis=0)))  # 排除遥感影像中的无效值（0）\n",
        "\n",
        "    # indices_2d = indices[:, 1:]\n",
        "    ind_y = np.ones(2).reshape(-1,2)\n",
        "    # for i in indices_2d:\n",
        "    for i in indices:\n",
        "      if shape == X[:, i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2) + 1].shape:\n",
        "        temp = X[:, i[0] - (size//2):i[0] + (size//2) + 1, i[1] - (size//2):i[1] + (size//2) + 1]\n",
        "        temp2 = np.expand_dims(temp, axis=0)\n",
        "        data1 = np.concatenate((data1, temp2), axis=0)\n",
        "\n",
        "        ind_y = np.concatenate((ind_y, i.reshape(-1,2)), axis=0)\n",
        "\n",
        "    # 去掉第一个虚拟值\n",
        "    ind_y = ind_y[1:]\n",
        "    # 提取所有的行索引\n",
        "    indices_1 = ind_y[:, 0].astype(int)\n",
        "    # 提取所有的列索引\n",
        "    indices_2 = ind_y[:, 1].astype(int)\n",
        "    # data_y = y[0, indices_1, indices_2]\n",
        "    # 提取标签值\n",
        "    # 每一对 (indices_1[i], indices_2[i]) 会自动匹配，得到对应位置的标签值。\n",
        "    data_y = y[indices_1, indices_2]  # 提取标签\n",
        "    # 拼接标签，形成最终的标签数组。\n",
        "    labels1 = np.concatenate((labels1, data_y), axis = 0)\n",
        "\n",
        "# 移除第一个虚拟值\n",
        "# data1 的形状会是 (num_samples, 6, 5, 5)，其中 num_samples 是提取的窗口数量（即符合条件的标签数量）。一个四维数组\n",
        "# labels1 的形状会是 (num_samples,)，其中 num_samples 是所有图像中符合条件的标签数量。一个一维数组\n",
        "data1 = data1[1:] #remove first dummy values\n",
        "labels1 = labels1[1:] #remove first dummy values\n",
        "\n",
        "# data1 和 labels1 应该是 一一对应的，因为它们的样本数（num_samples）相同。\n",
        "# 获得标签数据和特征数据\n",
        "features = data1\n",
        "labels = labels1\n"
      ],
      "metadata": {
        "id": "cwuDejh55Va5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 计算标签的统计信息\n",
        "print(\"数据导入后且数据增强前的标签的统计信息：\")\n",
        "print(f\"  最大值: {np.max(labels)}\")\n",
        "print(f\"  最小值: {np.min(labels)}\")\n",
        "print(f\"  均值: {np.mean(labels)}\")\n",
        "print(f\"  标准差: {np.std(labels)}\")\n"
      ],
      "metadata": {
        "id": "lrssggG4KX5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb5fef6-88b4-4dd4-e6a7-c1eaf58c3bc5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据导入后且数据增强前的标签的统计信息：\n",
            "  最大值: 126.9000015258789\n",
            "  最小值: 2.507999897003174\n",
            "  均值: 23.881254966278885\n",
            "  标准差: 11.637641243249083\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"数据导入后且数据增强前的标签分布直方图：\")\n",
        "import matplotlib.pyplot as plt\n",
        "plt.hist(labels, bins=np.arange(0, 40, 3))\n",
        "plt.title(\"Balanced Label Distribution\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PSaZ_3jWr4po",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b312e60f-5757-490d-d114-b14bbf1e59d5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "数据导入后且数据增强前的标签分布直方图：\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 检查 TensorFlow 版本\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "ebvXEcjYzVTB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8e7946-e4d7-4591-9ef7-aeaac4ee44f7"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据增强"
      ],
      "metadata": {
        "id": "oxuJ5nXIrpTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "\n",
        "# # 1. 数据增强管道\n",
        "# data_augmentation = tf.keras.Sequential([\n",
        "#     # TensorFlow 2.5 及以上\n",
        "#     # RandomRotation: 随机旋转特征数据，最大旋转角度为 ±40% 的全角。\n",
        "#     # 这些增强操作仅应用于特征数据，标签数据保持不变。\n",
        "\n",
        "#     # RandomFlip: 随机水平和垂直翻转特征数据。\n",
        "#     keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "#     # 在 Python 语法中，列表中最后一个元素后面的逗号是可选的。为了代码风格一致性，建议列表或字典等结构中，最后一行的元素后保持逗号，这样便于以后增加或调整内容\n",
        "#     # RandomRotation: 随机旋转特征数据，最大旋转角度为 ±40% 的全角。\n",
        "#     keras.layers.RandomRotation(0.4),\n",
        "\n",
        "#     # TensorFlow 2.4 及以下\n",
        "#     # keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\")\n",
        "#     # keras.layers.experimental.preprocessing.RandomRotation(0.4)\n",
        "# ])\n",
        "\n",
        "# # 2. 特征与标签的同步增强\n",
        "# def augment_feature_label(feature, label):\n",
        "#     \"\"\"\n",
        "#     对单个特征和标签进行同步数据增强。\n",
        "#     \"\"\"\n",
        "#     # features 的形状是 (num_samples, 6, 5, 5)\n",
        "#     # labels 的形状是 (num_samples,)\n",
        "#     # 对于特征数据，需要将 (6, 5, 5) 转换为 (5, 5, 6) 以便进行数据增强操作。\n",
        "#     # 增强后，再将其转换回原来的格式 (6, 5, 5)。\n",
        "\n",
        "#     #  1. Keras 数据增强层要求输入形状为 (H, W, C)，特征 feature 的形状从 (6, 5, 5) 转换为 (5, 5, 6)。\n",
        "#     feature = tf.transpose(feature, perm=[1, 2, 0])  # (6, 5, 5) -> (5, 5, 6)\n",
        "\n",
        "#     # 2. 将标签广播成与特征匹配的形状\n",
        "#     # 先将标签扩展到 (5, 5) 的二维张量，再扩展到 (5, 5, 1)\n",
        "#     # feature[..., 0]或者feature[:, :, 0]： 提取了第一个特征通道的二维切片，其形状为 (5, 5)。\n",
        "#     # tf.ones_like(feature[:, :, 0]) 生成了一个与这个切片形状相同的张量，值全为 1，形状为 (5, 5)。\n",
        "#     # label * tf.ones_like(feature[:, :, 0]) 将标量 label（形状为 ()）扩展为一个形状为 (5, 5) 的二维张量，每个元素的值都等于 label。\n",
        "#     # tf.expand_dims(..., axis=-1)在最后一个维度上为标签添加一个新维度。目的：将标签的形状与特征数据的通道维度对齐（即从二维变为三维）。\n",
        "#     expanded_label = tf.expand_dims(label * tf.ones_like(feature[..., 0]), axis=-1)  # (5, 5, 1)\n",
        "\n",
        "#     # 3. 将特征和标签沿通道维度拼接\n",
        "#     # 将特征和标签组合为一个四维张量 combined，使得增强操作能够同步作用在特征和标签上。\n",
        "#     # feature 是增强前的特征数据，其形状为 (5, 5, 6)，表示 5×5 空间大小，6 个特征通道。\n",
        "#     # tf.stack 将两个张量（特征数据和标签数据）沿新的维度进行堆叠。feature 的形状为 (5, 5, 6)。标签经过上述操作后，形状为 (5, 5, 1)。\n",
        "#     # 堆叠后的 combined 张量形状为 (5, 5, 10)，表示 6 个特征通道 + 1 个标签通道。\n",
        "#     combined = tf.concat([feature, expanded_label], axis=-1)  # (5, 5, 12)\n",
        "\n",
        "#     # 4. 数据增强\n",
        "#     # 使用 data_augmentation 对组合的张量进行数据增强，保证特征和标签同步增强。\n",
        "#     # augmented 是增强后的张量，其形状为 (5, 5, 10)：第三个维度（最后一个维度）包含 10 个通道，前 6 个是增强后的特征数据，最后 1 个是增强后的标签数据。\n",
        "#     augmented = data_augmentation(combined)\n",
        "\n",
        "#     # 5. 分离增强后的特征和标签\n",
        "#     # augmented_feature: 增强后的特征数据。\n",
        "#     # augmented_label: 增强后的标签数据，提取了原始广播的标签值，仍保持不变。\n",
        "#     # ... 是省略号，表示选取前面所有维度（这里是第 1 和第 2 维，即 (5, 5) 的空间维度）。\n",
        "#     # :-1 表示选择最后一个维度（第 3 维）的前 6 个通道。具体来说：从第 0 通道到第 10 通道（不包括第 6 通道）。\n",
        "#     # augmented_feature 的形状为 (5, 5, 6)，即增强后的特征数据。\n",
        "#     augmented_feature = augmented[..., :-1]  # 取前 6 个通道 (5, 5, 6)\n",
        "#     # ... 表示选取前面所有维度（这里是第 1 和第 2 维，即 (5, 5) 的空间维度）。\n",
        "#     # -1 表示选择最后一个通道（第 6 通道），即标签通道。\n",
        "#     # 选择标签通道后，形状为 (5, 5)。接下来的操作是从 (5, 5) 中提取一个标量标签：[0, 0] 表示取出标签通道的第 (0, 0) 位置的值。由于标签在增强过程中被广播为 (5, 5)，所以整个通道中的值都是一样的，选取任意一个值即可。这里选取了 (0, 0) 位置的值。\n",
        "#     # augmented_label 是一个标量，表示增强后的标签值，形状为 ()。\n",
        "#     augmented_label = augmented[..., -1, 0, 0]  # 提取标签，取第一个值即可（标量）\n",
        "\n",
        "#     # 6. 恢复特征原始格式 (C, H, W)\n",
        "#     # 将增强后的特征形状转换回原始格式 (6, 5, 5)\n",
        "#     augmented_feature = tf.transpose(augmented_feature, perm=[2, 0, 1])  # (5, 5, 6) -> (6, 5, 5)\n",
        "\n",
        "#     return augmented_feature, augmented_label\n",
        "\n",
        "# # 3. 对所有样本进行数据增强\n",
        "# augmented_features = []\n",
        "# augmented_labels = []\n",
        "\n",
        "# # 遍历每个样本，对每对 feature 和 label 调用 augment_feature_label 函数进行数据增强。\n",
        "# for i in range(features.shape[0]):\n",
        "#     feature = tf.convert_to_tensor(features[i], dtype=tf.float32)\n",
        "#     label = tf.convert_to_tensor(labels[i], dtype=tf.float32)\n",
        "\n",
        "#     aug_feature, aug_label = augment_feature_label(feature, label)\n",
        "#     augmented_features.append(aug_feature)\n",
        "#     augmented_labels.append(aug_label)\n",
        "\n",
        "# # 转换为 NumPy 数组\n",
        "# # 将增强后的特征列表转换为四维 NumPy 数组 (num_samples, 6, 5, 5)。\n",
        "# augmented_features = np.stack(augmented_features)\n",
        "# # 将增强后的标签列表转换为一维 NumPy 数组 (num_samples,)。\n",
        "# augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "# # 5. 打印验证形状\n",
        "# print(\"增强后的特征形状:\", augmented_features.shape)  # (num_samples, 6, 5, 5)\n",
        "# print(\"增强后的标签形状:\", augmented_labels.shape)  # (num_samples,)\n",
        "\n",
        "# features = augmented_features\n",
        "# labels = augmented_labels\n"
      ],
      "metadata": {
        "id": "hkJaXmFXrnxy"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "增强操作不影响标签的物理意义：森林高度是窗口中心点的属性，与方向无关。即使特征被旋转或翻转，标签值（高度）不会改变。\n",
        "例如，一棵树的高度不会因为图像旋转而改变。\n",
        "\n",
        "下面这段代码可能的误区是使用户可能认为数据增强会打乱数据顺序，但实际上循环是按顺序处理每个样本，逐个添加到列表，因此顺序不变。另外，用户可能担心增强操作是否会引入数据泄漏或错误，但在此代码中，每个样本的处理是独立的，不会有交叉影响。\n",
        "\n",
        "总结来说，修正后的代码确保了特征增强的同时，标签保持不变，且两者的顺序一致，因此特征和标签仍然正确对应。这段修正后的代码能够确保增强后的特征数据与标签数据严格对应，不会出现特征与标签错配的问题。"
      ],
      "metadata": {
        "id": "b5Uize57Vc8p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import tensorflow as tf\n",
        "# from tensorflow import keras\n",
        "\n",
        "# # 1. 数据增强管道（仅对特征操作）\n",
        "# data_augmentation = tf.keras.Sequential([\n",
        "#     keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "#     keras.layers.RandomRotation(0.2),\n",
        "#     keras.layers.RandomZoom(0.1),  # 随机缩放\n",
        "#     keras.layers.GaussianNoise(0.01),  # 为特征添加轻微的高斯噪声\n",
        "# ])\n",
        "\n",
        "# # 2. 仅增强特征，保持标签不变\n",
        "# def augment_feature_label(feature, label):\n",
        "#     \"\"\"\n",
        "#     对特征进行增强，标签保持不变。\n",
        "#     \"\"\"\n",
        "#     # 转换特征格式为 (H, W, C) 以便增强\n",
        "#     feature = tf.transpose(feature, perm=[1, 2, 0])  # (6, 5, 5) -> (5, 5, 6)\n",
        "\n",
        "#     # 仅对特征进行增强\n",
        "#     augmented_feature = data_augmentation(feature)\n",
        "\n",
        "#     # 恢复特征原始格式 (C, H, W)\n",
        "#     augmented_feature = tf.transpose(augmented_feature, perm=[2, 0, 1])  # (5, 5, 6) -> (6, 5, 5)\n",
        "\n",
        "#     # 标签保持不变\n",
        "#     return augmented_feature, label\n",
        "\n",
        "# # 3. 对所有样本进行数据增强\n",
        "# augmented_features = []\n",
        "# augmented_labels = []\n",
        "\n",
        "# for i in range(features.shape[0]):\n",
        "#     feature = tf.convert_to_tensor(features[i], dtype=tf.float32)\n",
        "#     label = tf.convert_to_tensor(labels[i], dtype=tf.float32)\n",
        "\n",
        "#     aug_feature, aug_label = augment_feature_label(feature, label)\n",
        "#     augmented_features.append(aug_feature)\n",
        "#     augmented_labels.append(aug_label)\n",
        "\n",
        "# # 转换为 NumPy 数组\n",
        "# augmented_features = np.stack(augmented_features)\n",
        "# augmented_labels = np.array(augmented_labels)\n",
        "\n",
        "# # # 打印验证形状\n",
        "# # print(\"增强后的特征形状:\", augmented_features.shape)  # (num_samples, 6, 5, 5)\n",
        "# # print(\"增强后的标签形状:\", augmented_labels.shape)  # (num_samples,)\n",
        "\n",
        "# # features = augmented_features\n",
        "# # labels = augmented_labels\n"
      ],
      "metadata": {
        "id": "oaPTSVS9UMF-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 打印验证形状\n",
        "# print(\"增强后的特征形状:\", augmented_features.shape)  # (num_samples, 9, 5, 5)\n",
        "# print(\"增强后的标签形状:\", augmented_labels.shape)  # (num_samples,)\n",
        "\n",
        "# features = augmented_features\n",
        "# labels = augmented_labels"
      ],
      "metadata": {
        "id": "utAF-6O1l-hs"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 计算数据增强后的标签的统计信息\n",
        "# print(\"数据增强后的标签的统计信息：\")\n",
        "# print(f\"  最大值: {np.max(labels)}\")\n",
        "# print(f\"  最小值: {np.min(labels)}\")\n",
        "# print(f\"  均值: {np.mean(labels)}\")\n",
        "# print(f\"  标准差: {np.std(labels)}\")"
      ],
      "metadata": {
        "id": "WZZSB6u4snIe"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"数据导入后且数据增强后的标签分布直方图：\")\n",
        "# import matplotlib.pyplot as plt\n",
        "# plt.hist(labels, bins=np.arange(0, 40, 3))\n",
        "# plt.title(\"Balanced Label Distribution\")\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "ho1-FUhVv0gH"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 数据平衡"
      ],
      "metadata": {
        "id": "big7o7PWKg4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 每个类别的样本数，确保每个标签区间有 800 个样本\n",
        "# sample_size = 800 #every class with labels smaller 36 meters has over 800 values\n",
        "# #features = np.mean(features, axis=(2, 3)) # patch mean of size * size features\n",
        "\n",
        "# # 生成从 3 到 36 步长为 3 的数字列表，即 [3, 6, 9, ..., 36]\n",
        "# num = (list(range(3, 37, 3))) #create list from 3 to 36 step 3\n",
        "# # 假设每个样本是一个 5x5 的图像块（大小为 5x5，6 个通道）\n",
        "# shape = (6, 5, 5)\n",
        "# # 创建一个初始的数组用于存储特征数据，形状为 (6, 5, 5)\n",
        "# data_bal = np.ones(shape) #create array to fill with features\n",
        "# # 扩展维度，使得形状变为 (1, 6, 5, 5)，这样可以进行拼接\n",
        "# data_bal = np.expand_dims(data_bal, axis=0) #expand one dimension to concatenate\n",
        "# # 创建一个用于存储标签的初始数组，形状为 (1,)\n",
        "# data_lab = np.ones(1) #create array to fill labels\n",
        "\n",
        "# # 在抽样之前，打印每个区间的样本数量，确保逻辑合理。\n",
        "# # 遍历每个标签区间\n",
        "# for i in num:\n",
        "#   # 注意这个 i 是区间右端点\n",
        "#   # 从标签中选择属于当前区间的索引\n",
        "#   # np.where() 返回的是一个元组，元组的元素个数取决于判断条件中的数据的维度, 元组的每个元素都是一个 数组，这些数组表示满足条件的元素在原始数组中的索引。因此，需要通过 indices[0] 访问索引数组\n",
        "#   # 如果输入数组是 多维的，返回的元组会包含 每一维的索引数组。例如，若数组是三维的，返回的元组就会包含三个数组，分别表示满足条件的元素在三维空间中每一维的索引。\n",
        "#   indices = np.where((labels > i-3) & (labels <= i)) #select indcies from every 3 meter interval until 36\n",
        "#   print(f\"区间 ({i-3}, {i}] 的样本数: {len(indices[0])}\")\n",
        "\n",
        "#   # 根据样本数决定如何抽样\n",
        "#   if len(indices[0]) < sample_size:\n",
        "#       print(f\"样本不足800，仅有 {len(indices[0])} 个样本，允许重复抽样。\")\n",
        "#       sampled_indices = np.random.choice(indices[0], size=sample_size, replace=True)\n",
        "#   else:\n",
        "#       sampled_indices = np.random.choice(indices[0], size=sample_size, replace=False)\n",
        "\n",
        "\n",
        "#   # 在当前区间中随机抽样 800 个样本\n",
        "#   # sampled_indices = np.random.choice(indices[0].flatten(), size=sample_size, replace=False) #random sample of each interval\n",
        "#   # sampled_indices = np.random.choice(indices[0], size=sample_size, replace=False)\n",
        "\n",
        "#   # 提取对应的特征和标签\n",
        "#   tempx = features[sampled_indices]\n",
        "#   tempy = labels[sampled_indices]\n",
        "#   # 将当前区间的特征和标签拼接到平衡数组中\n",
        "#   data_bal = np.concatenate((data_bal, tempx), axis=0)\n",
        "#   data_lab = np.concatenate((data_lab, tempy), axis=0)\n",
        "\n",
        "# # 处理 labels > 36 的标签，这部分直接拼接\n",
        "# indices = np.where((labels > 36)) #add the values > 36 m, they are so few no sample needed\n",
        "# # sampled_indices = indices[0].flatten()\n",
        "# sampled_indices = indices[0]\n",
        "# tempx = features[sampled_indices]\n",
        "# tempy = labels[sampled_indices]\n",
        "# data_bal = np.concatenate((data_bal[1:], tempx), axis=0)\n",
        "# data_lab = np.concatenate((data_lab[1:], tempy), axis=0)\n",
        "\n",
        "# # # 为了配合可视化界面，这里将data_bal重新赋值给features将data_lab重新赋值给labels，以便后续能够使用统一的变量。\n",
        "# features = data_bal\n",
        "# labels = data_lab\n"
      ],
      "metadata": {
        "id": "Oq5-JDlxKceX"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Neural Network"
      ],
      "metadata": {
        "id": "qH6Ck7wc7MuI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# features 数组形状为 (num_samples, 6, 5, 5)，意味着每个样本有 6 个特征（或 6 个通道），每个特征是一个 5x5 的空间窗口。\n",
        "# 得到每个样本的 6 个通道的均值，形状 (num_samples, 6)\n",
        "features_mean = np.mean(features, axis=(2, 3)) # patch mean of size * size features\n",
        "\n",
        "# 现在 features_mean 的形状是 (num_samples, 6)，适用于NN或者其他传统机器学习算法\n",
        "# 注意: train_test_split 只能处理 NumPy 数组或 Pandas DataFrame，并不能直接处理 TensorFlow Dataset 对象。因此，这部分代码在处理 TensorFlow Dataset 时会出错。\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features_mean, labels, test_size = 0.3, random_state=3)\n"
      ],
      "metadata": {
        "id": "0eSNeRy4568n"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "可以根据统计信息来决定是否需要对特征进行标准化处理"
      ],
      "metadata": {
        "id": "pyD_bqRA7lwU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 假设 features_mean 是 (num_samples, 6) 的数组，labels 是一维数组 (num_samples,)\n",
        "\n",
        "# 1. 计算每个特征的统计信息\n",
        "\n",
        "# 完整数据集：针对每个特征维度（即 6 个通道）计算统计信息\n",
        "for i in range(features_mean.shape[1]):  # 遍历 6 个特征通道\n",
        "    print(f\"完整数据集：特征通道 {i+1} 的统计信息：\")\n",
        "    print(f\"  最大值: {np.max(features_mean[:, i])}\")\n",
        "    print(f\"  最小值: {np.min(features_mean[:, i])}\")\n",
        "    print(f\"  均值: {np.mean(features_mean[:, i])}\")\n",
        "    print(f\"  标准差: {np.std(features_mean[:, i])}\")\n"
      ],
      "metadata": {
        "id": "6wWkZ-M67gCN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1debd09e-95de-4141-aa56-8694fea0b6aa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "完整数据集：特征通道 1 的统计信息：\n",
            "  最大值: 1752.88\n",
            "  最小值: 3.0\n",
            "  均值: 304.48570972320795\n",
            "  标准差: 267.4431236739359\n",
            "完整数据集：特征通道 2 的统计信息：\n",
            "  最大值: 38.22509475708008\n",
            "  最小值: 2.8289778137207033\n",
            "  均值: 22.766991665498683\n",
            "  标准差: 3.632237491386207\n",
            "完整数据集：特征通道 3 的统计信息：\n",
            "  最大值: 42.41987060546875\n",
            "  最小值: 2.923684387207031\n",
            "  均值: 26.32037469626319\n",
            "  标准差: 4.1296951329575515\n",
            "完整数据集：特征通道 4 的统计信息：\n",
            "  最大值: 457.08\n",
            "  最小值: 2.24\n",
            "  均值: 97.04047906316539\n",
            "  标准差: 63.28125158851863\n",
            "完整数据集：特征通道 5 的统计信息：\n",
            "  最大值: 0.2561902794986963\n",
            "  最小值: -22.749267196655275\n",
            "  均值: -12.635334562548197\n",
            "  标准差: 2.480597771290337\n",
            "完整数据集：特征通道 6 的统计信息：\n",
            "  最大值: 0.9986486744880676\n",
            "  最小值: -0.9985928344726562\n",
            "  均值: -0.0394123396109422\n",
            "  标准差: 0.5843025437478743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 2. 绘制特征的直方图、标签的分布图\n",
        "\n",
        "# # 绘制特征的直方图\n",
        "# for i in range(features_mean.shape[1]):\n",
        "#     plt.figure(figsize=(6, 4))\n",
        "#     plt.hist(features_mean[:, i], bins=50, color='blue', alpha=0.7)\n",
        "#     plt.title(f\"Distribution of channels {i+1}\")  # 通道 {i+1} 的分布\n",
        "#     plt.xlabel(f\"feature {i+1}\")\n",
        "#     plt.ylabel(\"frequency\")\n",
        "#     plt.grid(True)\n",
        "#     plt.show()\n",
        "\n",
        "# 绘制标签的分布图\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(labels, bins=50, color='green', alpha=0.7)\n",
        "plt.title(\"Label distribution\")#  标签的分布\n",
        "plt.xlabel(\"Label\")\n",
        "plt.ylabel(\"frequency\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "v5nj2I7-zV9i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ff4b0a7b-496d-47aa-bb25-9f1b0fbd997f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n",
            "WARNING:matplotlib.font_manager:findfont: Generic family 'sans-serif' not found because none of the following families were found: SimHei\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAGJCAYAAABVW0PjAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAO6dJREFUeJzt3XlYVnX+//EXy82mIqICUkqklppLpqmMy1giaMbkMjNuJZnpVFAuk5oz5Vox2WiLWTTfSmrSshqzNMe41dQ03FBci8w0KwUtQ1QUbuD8/mi4f55w4VbgPsDz4XVfl/c5n3PO+7w9ysuz3LeHYRiGAAAA3MzT3QUAAABIhBIAAGARhBIAAGAJhBIAAGAJhBIAAGAJhBIAAGAJhBIAAGAJhBIAAGAJhBIAAGAJhBKghjp06JA8PDz0z3/+s9zWuXbtWnl4eGjt2rVXtPz06dPl4eFhmnbdddfp3nvvvfriLqOkHykpKc5p9957r2rXrl3h2y7h4eGh6dOnV9r2AKshlABVSEpKijw8PLRt2zZ3l2JpK1assOwPdyvXBribt7sLAIBLyczMlKena/9/WrFihebPn+/SD/+IiAidPXtWNpvNxQpdc6nazp49K29v/llGzcXRD8DSfH19K3T9hYWFKi4ulo+Pj/z8/Cp0W5fj7u0D7sblG6CaKSgo0NSpU9WhQwfVrVtXtWrVUvfu3fXZZ59ddJnnnntOERER8vf31+9//3vt2bOn1JivvvpKf/zjHxUcHCw/Pz917NhRH3/88RXXuWHDBt16663y8/NT06ZN9eqrr15w3G/vKXE4HJoxY4aaN28uPz8/1a9fX926dZPdbpf0630g8+fPl/TrPRolL8l8H83zzz+vpk2bytfXV/v27bvgPSUlvv32W8XGxqpWrVoKDw/XzJkzdf4XrF/sXprfrvNStZVM++0ZlB07dqhv374KDAxU7dq11atXL23atMk0puSy3saNGzVhwgQ1bNhQtWrV0oABA3T8+PEL/wEAFsSZEqCayc3N1WuvvaahQ4dq9OjROnXqlF5//XXFxsZqy5Ytuvnmm03j33rrLZ06dUoJCQk6d+6cXnjhBd1+++3avXu3QkNDJUl79+5V165ddc011+ixxx5TrVq19N5776l///76z3/+owEDBrhU4+7duxUTE6OGDRtq+vTpKiws1LRp05zbu5Tp06crKSlJ999/vzp16qTc3Fxt27ZN27dvV+/evfWXv/xFR44ckd1u17///e8LrmPBggU6d+6cxowZI19fXwUHB6u4uPiCY4uKitSnTx916dJFs2fP1sqVKzVt2jQVFhZq5syZLu13WWo73969e9W9e3cFBgZq0qRJstlsevXVV9WzZ0+tW7dOnTt3No1/+OGHVa9ePU2bNk2HDh3S888/r8TERC1evNilOgG3MQBUGQsWLDAkGVu3br3omMLCQiM/P9807ZdffjFCQ0ON++67zznt4MGDhiTD39/f+OGHH5zTN2/ebEgyxo8f75zWq1cvo02bNsa5c+ec04qLi43f/e53RvPmzZ3TPvvsM0OS8dlnn11yP/r372/4+fkZ3333nXPavn37DC8vL+O3/yxFREQY8fHxzvft2rUz+vXrd8n1JyQklFrP+fscGBhoHDt27ILzFixY4JwWHx9vSDIefvhh57Ti4mKjX79+ho+Pj3H8+PFL7veF1nmx2gzDMCQZ06ZNc77v37+/4ePjYxw4cMA57ciRI0adOnWMHj16OKeVHBfR0dFGcXGxc/r48eMNLy8vIycn54LbA6yGyzdANePl5SUfHx9JUnFxsU6cOKHCwkJ17NhR27dvLzW+f//+uuaaa5zvO3XqpM6dO2vFihWSpBMnTmjNmjX685//rFOnTumnn37STz/9pJ9//lmxsbHav3+/fvzxxzLXV1RUpE8//VT9+/dXkyZNnNNbtmyp2NjYyy4fFBSkvXv3av/+/WXe5m8NGjRIDRs2LPP4xMRE5+89PDyUmJiogoICrVq16opruJyioiKlpqaqf//+uv76653TGzVqpGHDhmnDhg3Kzc01LTNmzBjT5aDu3burqKhI3333XYXVCZQnQglQDb355ptq27at856Lhg0b6pNPPtHJkydLjW3evHmpaTfccIMOHTokSfrmm29kGIaeeOIJNWzY0PSaNm2aJOnYsWNlru348eM6e/bsBbd74403Xnb5mTNnKicnRzfccIPatGmjiRMnateuXWXeviRFRkaWeaynp6cpFEi/9keSs0cV4fjx48rLy7tgT1q2bKni4mJ9//33punnhzxJqlevniTpl19+qbA6gfLEPSVANfP222/r3nvvVf/+/TVx4kSFhITIy8tLSUlJOnDggMvrK7nX4tFHH73omYxmzZpdVc2u6NGjhw4cOKCPPvpIqampeu211/Tcc88pOTlZ999/f5nW4e/vX641/fYD30oUFRWV63Yux8vL64LTjfNuygWsjFACVDMffPCBrr/+ei1ZssT0w7LkrMZvXegyyNdff63rrrtOkpxnCWw2m6Kjo6+6voYNG8rf3/+C283MzCzTOoKDgzVy5EiNHDlSp0+fVo8ePTR9+nRnKLlYSLgSxcXF+vbbb51nR6Rf+yPJ2aOSMxI5OTmmZS902aSstTVs2FABAQEX7MlXX30lT09PNW7cuEzrAqoKLt8A1UzJ/5bP/9/x5s2blZaWdsHxS5cuNd0TsmXLFm3evFl9+/aVJIWEhKhnz5569dVXdfTo0VLLu/rIqZeXl2JjY7V06VIdPnzYOf3LL7/Up59+etnlf/75Z9P72rVrq1mzZsrPz3dOq1WrlqTSIeFKvfTSS87fG4ahl156STabTb169ZL06weveXl5af369ablXn755VLrKmttXl5eiomJ0UcffWS6TJSdna1FixapW7duCgwMvMI9AqyJMyVAFfTGG29o5cqVpaaPHTtWd955p5YsWaIBAwaoX79+OnjwoJKTk9WqVSudPn261DLNmjVTt27d9OCDDyo/P1/PP/+86tevr0mTJjnHzJ8/X926dVObNm00evRoXX/99crOzlZaWpp++OEH7dy506X6Z8yYoZUrV6p79+566KGHVFhYqHnz5ummm2667P0hrVq1Us+ePdWhQwcFBwdr27Zt+uCDD0w3o3bo0EGS9Mgjjyg2NlZeXl4aMmSISzWW8PPz08qVKxUfH6/OnTvrv//9rz755BP97W9/c94sW7duXf3pT3/SvHnz5OHhoaZNm2r58uUXvNfGldqefPJJ2e12devWTQ899JC8vb316quvKj8/X7Nnz76i/QEszb0P/wBwRcmjnxd7ff/990ZxcbHx9NNPGxEREYavr6/Rvn17Y/ny5UZ8fLwRERHhXFfJ46rPPvusMWfOHKNx48aGr6+v0b17d2Pnzp2ltn3gwAFjxIgRRlhYmGGz2YxrrrnGuPPOO40PPvjAOaasjwQbhmGsW7fO6NChg+Hj42Ncf/31RnJysjFt2rTLPhL85JNPGp06dTKCgoIMf39/o0WLFsZTTz1lFBQUOMcUFhYaDz/8sNGwYUPDw8PDuc7z9/m3LvZIcK1atYwDBw4YMTExRkBAgBEaGmpMmzbNKCoqMi1//PhxY9CgQUZAQIBRr1494y9/+YuxZ8+eUuu8WG2GUfqRYMMwjO3btxuxsbFG7dq1jYCAAOO2224zvvjiC9OYiz0q7sqfB2AFHobBHVAAAMD9uKcEAABYAqEEAABYAqEEAABYAqEEAABYAqEEAABYAqEEAABYAh+eVgbFxcU6cuSI6tSpU64fXw0AQHVnGIZOnTql8PBweXpe+lwIoaQMjhw5wndMAABwFb7//ntde+21lxxDKCmDOnXqSPq1oWX9rgmHw6HU1FTFxMTIZrNVZHlVAv0wox9m9MOMfpjRD7Oq1o/c3Fw1btzY+bP0UgglZVByySYwMNClUBIQEKDAwMAqcdBUNPphRj/M6IcZ/TCjH2ZVtR9luf2BG10BAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAl8N03qFSDPxgshxwXnLds6LJKrgYAYCWcKQEAAJZAKAEAAJbA5RtYRtw7cZcdwyUeAKi+OFMCAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAsgVACAAAswa2hJCkpSbfeeqvq1KmjkJAQ9e/fX5mZmaYxPXv2lIeHh+n1wAMPmMYcPnxY/fr1U0BAgEJCQjRx4kQVFhaaxqxdu1a33HKLfH191axZM6WkpFT07gEAABe4NZSsW7dOCQkJ2rRpk+x2uxwOh2JiYnTmzBnTuNGjR+vo0aPO1+zZs53zioqK1K9fPxUUFOiLL77Qm2++qZSUFE2dOtU55uDBg+rXr59uu+02ZWRkaNy4cbr//vv16aefVtq+AgCAS/N258ZXrlxpep+SkqKQkBClp6erR48ezukBAQEKCwu74DpSU1O1b98+rVq1SqGhobr55ps1a9YsTZ48WdOnT5ePj4+Sk5MVGRmpOXPmSJJatmypDRs26LnnnlNsbGzF7SAAACgzt4aS3zp58qQkKTg42DR94cKFevvttxUWFqa4uDg98cQTCggIkCSlpaWpTZs2Cg0NdY6PjY3Vgw8+qL1796p9+/ZKS0tTdHS0aZ2xsbEaN27cBevIz89Xfn6+831ubq4kyeFwyOFwlGlfSsaVdXx1V9IHm2zlsp6qjuPDjH6Y0Q8z+mFW1frhSp2WCSXFxcUaN26cunbtqtatWzunDxs2TBEREQoPD9euXbs0efJkZWZmasmSJZKkrKwsUyCR5HyflZV1yTG5ubk6e/as/P39TfOSkpI0Y8aMUjWmpqY6w1BZ2e12l8ZXd8MChl3V8itWrCinSqyB48OMfpjRDzP6YVZV+pGXl1fmsZYJJQkJCdqzZ482bNhgmj5mzBjn79u0aaNGjRqpV69eOnDggJo2bVohtUyZMkUTJkxwvs/NzVXjxo0VExOjwMDAMq3D4XDIbrerd+/estmu7uxAdVDSj0V5i+TQlaf7xX9cXI5VuQ/Hhxn9MKMfZvTDrKr1o+RqQ1lYIpQkJiZq+fLlWr9+va699tpLju3cubMk6ZtvvlHTpk0VFhamLVu2mMZkZ2dLkvM+lLCwMOe088cEBgaWOksiSb6+vvL19S013WazuXwAXMky1Znjf7+uVHXrJceHGf0wox9m9MOsqvTDlRrd+vSNYRhKTEzUhx9+qDVr1igyMvKyy2RkZEiSGjVqJEmKiorS7t27dezYMecYu92uwMBAtWrVyjlm9erVpvXY7XZFRUWV054AAICr5dZQkpCQoLfffluLFi1SnTp1lJWVpaysLJ09e1aSdODAAc2aNUvp6ek6dOiQPv74Y40YMUI9evRQ27ZtJUkxMTFq1aqV7rnnHu3cuVOffvqpHn/8cSUkJDjPdjzwwAP69ttvNWnSJH311Vd6+eWX9d5772n8+PFu23cAAGDm1lDyyiuv6OTJk+rZs6caNWrkfC1e/Ot9Az4+Plq1apViYmLUokUL/fWvf9WgQYO0bNky5zq8vLy0fPlyeXl5KSoqSnfffbdGjBihmTNnOsdERkbqk08+kd1uV7t27TRnzhy99tprPA4MAICFuPWeEsMwLjm/cePGWrdu3WXXExERcdmnMnr27KkdO3a4VB8AAKg8lrjRFVVf3Dtxl5xvk03xAfGVVA0AoCriC/kAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAlEEoAAIAleLu7AMAVce/EXXL+sqHLKqkSAEB540wJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBEIJAACwBLeGkqSkJN16662qU6eOQkJC1L9/f2VmZprGnDt3TgkJCapfv75q166tQYMGKTs72zTm8OHD6tevnwICAhQSEqKJEyeqsLDQNGbt2rW65ZZb5Ovrq2bNmiklJaWidw8AALjAraFk3bp1SkhI0KZNm2S32+VwOBQTE6MzZ844x4wfP17Lli3T+++/r3Xr1unIkSMaOHCgc35RUZH69eungoICffHFF3rzzTeVkpKiqVOnOsccPHhQ/fr102233aaMjAyNGzdO999/vz799NNK3V8AAHBx3u7c+MqVK03vU1JSFBISovT0dPXo0UMnT57U66+/rkWLFun222+XJC1YsEAtW7bUpk2b1KVLF6Wmpmrfvn1atWqVQkNDdfPNN2vWrFmaPHmypk+fLh8fHyUnJysyMlJz5syRJLVs2VIbNmzQc889p9jY2ErfbwAAUJpbQ8lvnTx5UpIUHBwsSUpPT5fD4VB0dLRzTIsWLdSkSROlpaWpS5cuSktLU5s2bRQaGuocExsbqwcffFB79+5V+/btlZaWZlpHyZhx48ZdsI78/Hzl5+c73+fm5kqSHA6HHA5HmfalZFxZx1d1NtnKNP9y465WVel3TTs+Lod+mNEPM/phVtX64UqdlgklxcXFGjdunLp27arWrVtLkrKysuTj46OgoCDT2NDQUGVlZTnHnB9ISuaXzLvUmNzcXJ09e1b+/v6meUlJSZoxY0apGlNTUxUQEODSftntdpfGV1XxAfFlGjcsYFiF1rFixYoKXX95qynHR1nRDzP6YUY/zKpKP/Ly8so81jKhJCEhQXv27NGGDRvcXYqmTJmiCRMmON/n5uaqcePGiomJUWBgYJnW4XA4ZLfb1bt3b9lsFXt2wAoGfzD4kvNtsmlYwDAtylskhyou3S/+4+IKW3d5qmnHx+XQDzP6YUY/zKpaP0quNpSFJUJJYmKili9frvXr1+vaa691Tg8LC1NBQYFycnJMZ0uys7MVFhbmHLNlyxbT+kqezjl/zG+f2MnOzlZgYGCpsySS5OvrK19f31LTbTabywfAlSxTFZU1aDj+96uiVLVe15Tjo6zohxn9MKMfZlWlH67U6NanbwzDUGJioj788EOtWbNGkZGRpvkdOnSQzWbT6tWrndMyMzN1+PBhRUVFSZKioqK0e/duHTt2zDnGbrcrMDBQrVq1co45fx0lY0rWAQAA3M+tZ0oSEhK0aNEiffTRR6pTp47zHpC6devK399fdevW1ahRozRhwgQFBwcrMDBQDz/8sKKiotSlSxdJUkxMjFq1aqV77rlHs2fPVlZWlh5//HElJCQ4z3Y88MADeumllzRp0iTdd999WrNmjd577z198sknbtt3AABg5tYzJa+88opOnjypnj17qlGjRs7X4sX//76A5557TnfeeacGDRqkHj16KCwsTEuWLHHO9/Ly0vLly+Xl5aWoqCjdfffdGjFihGbOnOkcExkZqU8++UR2u13t2rXTnDlz9Nprr/E4MAAAFuLWMyWGYVx2jJ+fn+bPn6/58+dfdExERMRln7ro2bOnduzY4XKNAACgcvDdNwAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIs8THzsL64d+LcXQIAoJrjTAkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEQgkAALAEl0PJt99+WxF1AACAGs7lUNKsWTPddtttevvtt3Xu3LmKqAkAANRALoeS7du3q23btpowYYLCwsL0l7/8RVu2bKmI2gAAQA3icii5+eab9cILL+jIkSN64403dPToUXXr1k2tW7fW3Llzdfz48YqoEwAAVHNXfKOrt7e3Bg4cqPfff1/PPPOMvvnmGz366KNq3LixRowYoaNHj5ZnnQAAoJq74lCybds2PfTQQ2rUqJHmzp2rRx99VAcOHJDdbteRI0d01113lWedAACgmvN2dYG5c+dqwYIFyszM1B133KG33npLd9xxhzw9f803kZGRSklJ0XXXXVfetQIAgGrM5VDyyiuv6L777tO9996rRo0aXXBMSEiIXn/99asuDgAA1Bwuh5L9+/dfdoyPj4/i4+OvqCAAAFAzuXxPyYIFC/T++++Xmv7+++/rzTffLJeiAABAzeNyKElKSlKDBg1KTQ8JCdHTTz9dLkUBAICax+VQcvjwYUVGRpaaHhERocOHD5dLUQAAoOZx+Z6SkJAQ7dq1q9TTNTt37lT9+vXLqy7gisS9E3fZMcuGLquESgAArnL5TMnQoUP1yCOP6LPPPlNRUZGKioq0Zs0ajR07VkOGDKmIGgEAQA3g8pmSWbNm6dChQ+rVq5e8vX9dvLi4WCNGjOCeEgAAcMVcDiU+Pj5avHixZs2apZ07d8rf319t2rRRRERERdQHAABqCJdDSYkbbrhBN9xwQ3nWAgAAajCXQ0lRUZFSUlK0evVqHTt2TMXFxab5a9asKbfiAABAzeFyKBk7dqxSUlLUr18/tW7dWh4eHhVRFwAAqGFcDiXvvvuu3nvvPd1xxx0VUQ8AAKihXH4k2MfHR82aNauIWgAAQA3mcij561//qhdeeEGGYVREPQAAoIZyOZRs2LBBCxcuVNOmTRUXF6eBAweaXq5Yv3694uLiFB4eLg8PDy1dutQ0/95775WHh4fp1adPH9OYEydOaPjw4QoMDFRQUJBGjRql06dPm8bs2rVL3bt3l5+fnxo3bqzZs2e7utsAAKCCuXxPSVBQkAYMGFAuGz9z5ozatWun++6776KBpk+fPlqwYIHzva+vr2n+8OHDdfToUdntdjkcDo0cOVJjxozRokWLJEm5ubmKiYlRdHS0kpOTtXv3bt13330KCgrSmDFjymU/AADA1XM5lJwfEK5W37591bdv30uO8fX1VVhY2AXnffnll1q5cqW2bt2qjh07SpLmzZunO+64Q//85z8VHh6uhQsXqqCgQG+88YZ8fHx00003KSMjQ3PnziWUAABgIVf04WmFhYVau3atDhw4oGHDhqlOnTo6cuSIAgMDVbt27XItcO3atQoJCVG9evV0++2368knn3R+8V9aWpqCgoKcgUSSoqOj5enpqc2bN2vAgAFKS0tTjx495OPj4xwTGxurZ555Rr/88ovq1atXapv5+fnKz893vs/NzZUkORwOORyOMtVdMq6s463OJlu5LH+16ykPVvgzqW7Hx9WiH2b0w4x+mFW1frhSp8uh5LvvvlOfPn10+PBh5efnq3fv3qpTp46eeeYZ5efnKzk52dVVXlSfPn00cOBARUZG6sCBA/rb3/6mvn37Ki0tTV5eXsrKylJISIh5h7y9FRwcrKysLElSVlaWIiMjTWNCQ0Od8y4USpKSkjRjxoxS01NTUxUQEODSPtjtdpfGW1V8QHy5rGdYwLByWc/VWLFihbtLcKoux0d5oR9m9MOMfphVlX7k5eWVeewVfXhax44dtXPnTucZC0kaMGCARo8e7erqLun8bx1u06aN2rZtq6ZNm2rt2rXq1atXuW7rfFOmTNGECROc73Nzc9W4cWPFxMQoMDCwTOtwOByy2+3q3bu3bDb3nx24WoM/GHxVy9tk07CAYVqUt0gOuTfdL/7jYrduX6p+x8fVoh9m9MOMfphVtX6UXG0oC5dDyeeff64vvvjCdDlEkq677jr9+OOPrq7OJddff70aNGigb775Rr169VJYWJiOHTtmGlNYWKgTJ04470MJCwtTdna2aUzJ+4vdq+Lr61vqhlpJstlsLh8AV7KMFZVXkHD875c7WenPo7ocH+WFfpjRDzP6YVZV+uFKjS4/ElxcXKyioqJS03/44QfVqVPH1dW55IcfftDPP/+sRo0aSZKioqKUk5Oj9PR055g1a9aouLhYnTt3do5Zv3696ZqW3W7XjTfeeMFLNwAAwD1cDiUxMTF6/vnnne89PDx0+vRpTZs2zeWPnj99+rQyMjKUkZEhSTp48KAyMjJ0+PBhnT59WhMnTtSmTZt06NAhrV69WnfddZeaNWum2NhYSVLLli3Vp08fjR49Wlu2bNHGjRuVmJioIUOGKDw8XJI0bNgw+fj4aNSoUdq7d68WL16sF154wXR5BgAAuJ/Ll2/mzJmj2NhYtWrVSufOndOwYcO0f/9+NWjQQO+8845L69q2bZtuu+025/uSoBAfH69XXnlFu3bt0ptvvqmcnByFh4crJiZGs2bNMl1aWbhwoRITE9WrVy95enpq0KBBevHFF53z69atq9TUVCUkJKhDhw5q0KCBpk6dyuPAAABYjMuh5Nprr9XOnTv17rvvateuXTp9+rRGjRql4cOHy9/f36V19ezZ85IfV//pp59edh3BwcHOD0q7mLZt2+rzzz93qTYAAFC5ruhzSry9vXX33XeXdy0AAKAGczmUvPXWW5ecP2LEiCsuBgAA1FxX9Dkl53M4HMrLy5OPj48CAgIIJQAA4Iq4/PTNL7/8YnqdPn1amZmZ6tatm8s3ugIAAJRwOZRcSPPmzfWPf/yj1FkUAACAsiqXUCL9evPrkSNHymt1AACghnH5npKPP/7Y9N4wDB09elQvvfSSunbtWm6FAQCAmsXlUNK/f3/Tew8PDzVs2FC333675syZU151AQCAGsblUFJcXFwRdQAAgBqu3O4pAQAAuBounylx5Yvs5s6d6+rqAQBADeVyKNmxY4d27Nghh8OhG2+8UZL09ddfy8vLS7fccotznIeHR/lVCQAAqj2XQ0lcXJzq1KmjN998U/Xq1ZP06weqjRw5Ut27d9df//rXci8SAABUfy6Hkjlz5ig1NdUZSCSpXr16evLJJxUTE0MoqYLi3olzdwkAALh+o2tubq6OHz9eavrx48d16tSpcikKAADUPC6HkgEDBmjkyJFasmSJfvjhB/3www/6z3/+o1GjRmngwIEVUSMAAKgBXL58k5ycrEcffVTDhg2Tw+H4dSXe3ho1apSeffbZci8QAADUDC6HkoCAAL388st69tlndeDAAUlS06ZNVatWrXIvDgAA1BxX/OFpR48e1dGjR9W8eXPVqlVLhmGUZ10AAKCGcTmU/Pzzz+rVq5duuOEG3XHHHTp69KgkadSoUTx5AwAArpjLoWT8+PGy2Ww6fPiwAgICnNMHDx6slStXlmtxAACg5nD5npLU1FR9+umnuvbaa03Tmzdvru+++67cCgMqyuU+l2XZ0GWVVAkA4Hwunyk5c+aM6QxJiRMnTsjX17dcigIAADWPy6Gke/fueuutt5zvPTw8VFxcrNmzZ+u2224r1+IAAEDN4fLlm9mzZ6tXr17atm2bCgoKNGnSJO3du1cnTpzQxo0bK6JGAABQA7h8pqR169b6+uuv1a1bN9111106c+aMBg4cqB07dqhp06YVUSMAAKgBXDpT4nA41KdPHyUnJ+vvf/97RdUEAABqIJfOlNhsNu3atauiagEAADWYy5dv7r77br3++usVUQsAAKjBXL7RtbCwUG+88YZWrVqlDh06lPrOm7lz55ZbcQAAoOYoUyjZtWuXWrduLU9PT+3Zs0e33HKLJOnrr782jfPw8Cj/CgEAQI1QplDSvn17HT16VCEhIfruu++0detW1a9fv6JrAwAANUiZ7ikJCgrSwYMHJUmHDh1ScXFxhRYFAABqnjKdKRk0aJB+//vfq1GjRvLw8FDHjh3l5eV1wbHffvttuRYIAABqhjKFkn/9618aOHCgvvnmGz3yyCMaPXq06tSpU9G1AQCAGqTMT9/06dNHkpSenq6xY8cSSgAAQLly+ZHgBQsWVEQdAACghnP5w9MAAAAqAqEEAABYAqEEAABYAqEEAABYAqEEAABYAqEEAABYgltDyfr16xUXF6fw8HB5eHho6dKlpvmGYWjq1Klq1KiR/P39FR0drf3795vGnDhxQsOHD1dgYKCCgoI0atQonT592jRm165d6t69u/z8/NS4cWPNnj27oncNAAC4yK2h5MyZM2rXrp3mz59/wfmzZ8/Wiy++qOTkZG3evFm1atVSbGyszp075xwzfPhw7d27V3a7XcuXL9f69es1ZswY5/zc3FzFxMQoIiJC6enpevbZZzV9+nT961//qvD9AwAAZefyh6eVp759+6pv374XnGcYhp5//nk9/vjjuuuuuyRJb731lkJDQ7V06VINGTJEX375pVauXKmtW7eqY8eOkqR58+bpjjvu0D//+U+Fh4dr4cKFKigo0BtvvCEfHx/ddNNNysjI0Ny5c03hBQAAuJdbQ8mlHDx4UFlZWYqOjnZOq1u3rjp37qy0tDQNGTJEaWlpCgoKcgYSSYqOjpanp6c2b96sAQMGKC0tTT169JCPj49zTGxsrJ555hn98ssvqlevXqlt5+fnKz8/3/k+NzdXkuRwOORwOMpUf8m4so53J5tslbaNytjW1aqMP7OqdHxUBvphRj/M6IdZVeuHK3VaNpRkZWVJkkJDQ03TQ0NDnfOysrIUEhJimu/t7a3g4GDTmMjIyFLrKJl3oVCSlJSkGTNmlJqempqqgIAAl/bDbre7NN4d4gPiK21bwwKGVdq2rtSKFSsqbVtV4fioTPTDjH6Y0Q+zqtKPvLy8Mo+1bChxpylTpmjChAnO97m5uWrcuLFiYmIUGBhYpnU4HA7Z7Xb17t1bNpu1zw4M/mBwhW/DJpuGBQzTorxFcsja6X7xHxdX+Daq0vFRGeiHGf0wox9mVa0fJVcbysKyoSQsLEySlJ2drUaNGjmnZ2dn6+abb3aOOXbsmGm5wsJCnThxwrl8WFiYsrOzTWNK3peM+S1fX1/5+vqWmm6z2Vw+AK5kmcpWmSHB8b9fVlaZf15V4fioTPTDjH6Y0Q+zqtIPV2q07OeUREZGKiwsTKtXr3ZOy83N1ebNmxUVFSVJioqKUk5OjtLT051j1qxZo+LiYnXu3Nk5Zv369aZrWna7XTfeeOMFL90AAAD3cGsoOX36tDIyMpSRkSHp15tbMzIydPjwYXl4eGjcuHF68skn9fHHH2v37t0aMWKEwsPD1b9/f0lSy5Yt1adPH40ePVpbtmzRxo0blZiYqCFDhig8PFySNGzYMPn4+GjUqFHau3evFi9erBdeeMF0eQYAALifWy/fbNu2TbfddpvzfUlQiI+PV0pKiiZNmqQzZ85ozJgxysnJUbdu3bRy5Ur5+fk5l1m4cKESExPVq1cveXp6atCgQXrxxRed8+vWravU1FQlJCSoQ4cOatCggaZOncrjwAAAWIxbQ0nPnj1lGMZF53t4eGjmzJmaOXPmRccEBwdr0aJFl9xO27Zt9fnnn19xnQAAoOJZ9p4SAABQsxBKAACAJVj2kWDAXeLeibvk/GVDl1VSJQBQs3CmBAAAWAKhBAAAWAKXb2qAy12OAADACjhTAgAALIFQAgAALIFQAgAALIFQAgAALIFQAgAALIFQAgAALIFHgqs4HvcFAFQXnCkBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACWQCgBAACW4O3uAnBpce/EubsEAAAqBaEEcFFZguKyocsqoRIAqF64fAMAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACyBUAIAACzB0qFk+vTp8vDwML1atGjhnH/u3DklJCSofv36ql27tgYNGqTs7GzTOg4fPqx+/fopICBAISEhmjhxogoLCyt7V1DDxL0Td8kXAKA0y39L8E033aRVq1Y533t7//+Sx48fr08++UTvv/++6tatq8TERA0cOFAbN26UJBUVFalfv34KCwvTF198oaNHj2rEiBGy2Wx6+umnK31fAADAxVk+lHh7eyssLKzU9JMnT+r111/XokWLdPvtt0uSFixYoJYtW2rTpk3q0qWLUlNTtW/fPq1atUqhoaG6+eabNWvWLE2ePFnTp0+Xj49PZe8OAAC4CMuHkv379ys8PFx+fn6KiopSUlKSmjRpovT0dDkcDkVHRzvHtmjRQk2aNFFaWpq6dOmitLQ0tWnTRqGhoc4xsbGxevDBB7V37161b9/+gtvMz89Xfn6+831ubq4kyeFwyOFwlKnuknFlHX8xNtmuanmrKNmP6rI/V6u8jo/qgn6Y0Q8z+mFW1frhSp2WDiWdO3dWSkqKbrzxRh09elQzZsxQ9+7dtWfPHmVlZcnHx0dBQUGmZUJDQ5WVlSVJysrKMgWSkvkl8y4mKSlJM2bMKDU9NTVVAQEBLu2D3W53afxvxQfEX9XyVjMsYJi7S7CEkuPiao+P6oZ+mNEPM/phVlX6kZeXV+axlg4lffv2df6+bdu26ty5syIiIvTee+/J39+/wrY7ZcoUTZgwwfk+NzdXjRs3VkxMjAIDA8u0DofDIbvdrt69e8tmu/KzA4M/GHzFy1qJTTYNCximRXmL5FDVSPcV6e273i6X46O6KK+/L9UF/TCjH2ZVrR8lVxvKwtKh5LeCgoJ0ww036JtvvlHv3r1VUFCgnJwc09mS7Oxs5z0oYWFh2rJli2kdJU/nXOg+lRK+vr7y9fUtNd1ms7l8AFzJMuerbj/AHf/7VdOVHBNXe3xUN/TDjH6Y0Q+zqtIPV2q09CPBv3X69GkdOHBAjRo1UocOHWSz2bR69Wrn/MzMTB0+fFhRUVGSpKioKO3evVvHjh1zjrHb7QoMDFSrVq0qvX4AAHBxlj5T8uijjyouLk4RERE6cuSIpk2bJi8vLw0dOlR169bVqFGjNGHCBAUHByswMFAPP/ywoqKi1KVLF0lSTEyMWrVqpXvuuUezZ89WVlaWHn/8cSUkJFzwTAgAAHAfS4eSH374QUOHDtXPP/+shg0bqlu3btq0aZMaNmwoSXruuefk6empQYMGKT8/X7GxsXr55Zedy3t5eWn58uV68MEHFRUVpVq1aik+Pl4zZ8501y4BAICLsHQoeffddy8538/PT/Pnz9f8+fMvOiYiIkIrVqwo79IAAEA5q1L3lAAAgOqLUAIAACyBUAIAACyBUAIAACyBUAIAACzB0k/fANXV4A8GKz4gXoM/GHzRT7hdNnRZJVcFAO7FmRIAAGAJhBIAAGAJhBIAAGAJ3FPiZnHvxLm7BAAALIEzJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBL4RFfAoi73ab98izCA6oYzJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBIIJQAAwBL4nBKgirrc55hIfJYJgKqFMyUAAMASCCUAAMASCCUAAMASCCUAAMASCCUAAMASCCUAAMASeCQYqMYu99gwjwwDsBLOlAAAAEvgTAlQg/EBbACshDMlAADAEgglAADAEgglAADAErinBMAlleW+k8vhvhQAZUEoAVDhLhdslvxxSSVVAsDKuHwDAAAsoUadKZk/f76effZZZWVlqV27dpo3b546derk7rKAGm/wB4MVHxCvwR8MlkOOK1rH5S4R8fgzYH01JpQsXrxYEyZMUHJysjp37qznn39esbGxyszMVEhIiLvLAwCny4U0whOqqxoTSubOnavRo0dr5MiRkqTk5GR98skneuONN/TYY4+5uToAV6s8bsgtj3VcTnkEisqosywqY18IYDVLjQglBQUFSk9P15QpU5zTPD09FR0drbS0tFLj8/PzlZ+f73x/8uRJSdKJEyfkcJTt1LLD4VBeXp5+/vln2Wy2iw/MK+NOVAN5yqtR+3s59MOspvQj7vXLBwqbbFWiH2XZl/LYhk02/SngTxr81pVf3qsMKf1TKmU7Zf75YhGnTp2SJBmGcfnBRg3w448/GpKML774wjR94sSJRqdOnUqNnzZtmiGJFy9evHjx4lVOr++///6yP69rxJkSV02ZMkUTJkxwvi8uLtaJEydUv359eXh4lGkdubm5aty4sb7//nsFBgZWVKlVBv0wox9m9MOMfpjRD7Oq1g/DMHTq1CmFh4dfdmyNCCUNGjSQl5eXsrOzTdOzs7MVFhZWaryvr698fX1N04KCgq5o24GBgVXioKks9MOMfpjRDzP6YUY/zKpSP+rWrVumcTXic0p8fHzUoUMHrV692jmtuLhYq1evVlRUlBsrAwAAJWrEmRJJmjBhguLj49WxY0d16tRJzz//vM6cOeN8GgcAALhXjQklgwcP1vHjxzV16lRlZWXp5ptv1sqVKxUaGloh2/P19dW0adNKXQaqqeiHGf0wox9m9MOMfphV5354GEZZntEBAACoWDXinhIAAGB9hBIAAGAJhBIAAGAJhBIAAGAJhJIKMn/+fF133XXy8/NT586dtWXLFneXVOGSkpJ06623qk6dOgoJCVH//v2VmZlpGnPu3DklJCSofv36ql27tgYNGlTqQ+2qq3/84x/y8PDQuHHjnNNqWj9+/PFH3X333apfv778/f3Vpk0bbdu2zTnfMAxNnTpVjRo1kr+/v6Kjo7V//343VlxxioqK9MQTTygyMlL+/v5q2rSpZs2aZfp+kOrcj/Xr1ysuLk7h4eHy8PDQ0qVLTfPLsu8nTpzQ8OHDFRgYqKCgII0aNUqnT5+uxL0oP5fqh8Ph0OTJk9WmTRvVqlVL4eHhGjFihI4cOWJaR3XoB6GkAixevFgTJkzQtGnTtH37drVr106xsbE6duyYu0urUOvWrVNCQoI2bdoku90uh8OhmJgYnTlzxjlm/PjxWrZsmd5//32tW7dOR44c0cCBA91YdeXYunWrXn31VbVt29Y0vSb145dfflHXrl1ls9n03//+V/v27dOcOXNUr14955jZs2frxRdfVHJysjZv3qxatWopNjZW586dc2PlFeOZZ57RK6+8opdeeklffvmlnnnmGc2ePVvz5s1zjqnO/Thz5ozatWun+fPnX3B+WfZ9+PDh2rt3r+x2u5YvX67169drzJgxlbUL5epS/cjLy9P27dv1xBNPaPv27VqyZIkyMzP1hz/8wTSuWvTj6r/uDr/VqVMnIyEhwfm+qKjICA8PN5KSktxYVeU7duyYIclYt26dYRiGkZOTY9hsNuP99993jvnyyy8NSUZaWpq7yqxwp06dMpo3b27Y7Xbj97//vTF27FjDMGpePyZPnmx069btovOLi4uNsLAw49lnn3VOy8nJMXx9fY133nmnMkqsVP369TPuu+8+07SBAwcaw4cPNwyjZvVDkvHhhx8635dl3/ft22dIMrZu3eoc89///tfw8PAwfvzxx0qrvSL8th8XsmXLFkOS8d133xmGUX36wZmSclZQUKD09HRFR0c7p3l6eio6OlppaWlurKzynTx5UpIUHBwsSUpPT5fD4TD1pkWLFmrSpEm17k1CQoL69etn2m+p5vXj448/VseOHfWnP/1JISEhat++vf7v//7POf/gwYPKysoy9aNu3brq3LlztezH7373O61evVpff/21JGnnzp3asGGD+vbtK6nm9eN8Zdn3tLQ0BQUFqWPHjs4x0dHR8vT01ObNmyu95sp28uRJeXh4OL+Xrbr0o8Z8omtl+emnn1RUVFTqk2JDQ0P11VdfuamqyldcXKxx48apa9euat26tSQpKytLPj4+pb7cMDQ0VFlZWW6osuK9++672r59u7Zu3VpqXk3rx7fffqtXXnlFEyZM0N/+9jdt3bpVjzzyiHx8fBQfH+/c5wv93amO/XjssceUm5urFi1ayMvLS0VFRXrqqac0fPhwSapx/ThfWfY9KytLISEhpvne3t4KDg6u9v05d+6cJk+erKFDhzq/kK+69INQggqRkJCgPXv2aMOGDe4uxW2+//57jR07Vna7XX5+fu4ux+2Ki4vVsWNHPf3005Kk9u3ba8+ePUpOTlZ8fLybq6t87733nhYuXKhFixbppptuUkZGhsaNG6fw8PAa2Q+UjcPh0J///GcZhqFXXnnF3eWUOy7flLMGDRrIy8ur1BMU2dnZCgsLc1NVlSsxMVHLly/XZ599pmuvvdY5PSwsTAUFBcrJyTGNr669SU9P17Fjx3TLLbfI29tb3t7eWrdunV588UV5e3srNDS0RvWjUaNGatWqlWlay5YtdfjwYUly7nNN+bszceJEPfbYYxoyZIjatGmje+65R+PHj1dSUpKkmteP85Vl38PCwko9PFBYWKgTJ05U2/6UBJLvvvtOdrvdeZZEqj79IJSUMx8fH3Xo0EGrV692TisuLtbq1asVFRXlxsoqnmEYSkxM1Icffqg1a9YoMjLSNL9Dhw6y2Wym3mRmZurw4cPVsje9evXS7t27lZGR4Xx17NhRw4cPd/6+JvWja9eupR4R//rrrxURESFJioyMVFhYmKkfubm52rx5c7XsR15enjw9zf8Ee3l5qbi4WFLN68f5yrLvUVFRysnJUXp6unPMmjVrVFxcrM6dO1d6zRWtJJDs379fq1atUv369U3zq00/3H2nbXX07rvvGr6+vkZKSoqxb98+Y8yYMUZQUJCRlZXl7tIq1IMPPmjUrVvXWLt2rXH06FHnKy8vzznmgQceMJo0aWKsWbPG2LZtmxEVFWVERUW5serKdf7TN4ZRs/qxZcsWw9vb23jqqaeM/fv3GwsXLjQCAgKMt99+2znmH//4hxEUFGR89NFHxq5du4y77rrLiIyMNM6ePevGyitGfHy8cc011xjLly83Dh48aCxZssRo0KCBMWnSJOeY6tyPU6dOGTt27DB27NhhSDLmzp1r7Nixw/k0SVn2vU+fPkb79u2NzZs3Gxs2bDCaN29uDB061F27dFUu1Y+CggLjD3/4g3HttdcaGRkZpn9f8/PzneuoDv0glFSQefPmGU2aNDF8fHyMTp06GZs2bXJ3SRVO0gVfCxYscI45e/as8dBDDxn16tUzAgICjAEDBhhHjx51X9GV7LehpKb1Y9myZUbr1q0NX19fo0WLFsa//vUv0/zi4mLjiSeeMEJDQw1fX1+jV69eRmZmppuqrVi5ubnG2LFjjSZNmhh+fn7G9ddfb/z97383/ZCpzv347LPPLvjvRXx8vGEYZdv3n3/+2Rg6dKhRu3ZtIzAw0Bg5cqRx6tQpN+zN1btUPw4ePHjRf18/++wz5zqqQz88DOO8jw8EAABwE+4pAQAAlkAoAQAAlkAoAQAAlkAoAQAAlkAoAQAAlkAoAQAAlkAoAQAAlkAoAQAAlkAoAVBlpaSkKCgo6KrX4+HhoaVLl171egBcHUIJALe699571b9/f3eXAcACCCUAAMASCCUALGvu3Llq06aNatWqpcaNG+uhhx7S6dOnS41bunSpmjdvLj8/P8XGxur77783zf/oo490yy23yM/PT9dff71mzJihwsLCytoNAGVEKAFgWZ6ennrxxRe1d+9evfnmm1qzZo0mTZpkGpOXl6ennnpKb731ljZu3KicnBwNGTLEOf/zzz/XiBEjNHbsWO3bt0+vvvqqUlJS9NRTT1X27gC4DL4lGIBb3XvvvcrJySnTjaYffPCBHnjgAf3000+Sfr3RdeTIkdq0aZM6d+4sSfrqq6/UsmVLbd68WZ06dVJ0dLR69eqlKVOmONfz9ttva9KkSTpy5IikX290/fDDD7m3BXAzb3cXAAAXs2rVKiUlJemrr75Sbm6uCgsLde7cOeXl5SkgIECS5O3trVtvvdW5TIsWLRQUFKQvv/xSnTp10s6dO7Vx40bTmZGioqJS6wHgfoQSAJZ06NAh3XnnnXrwwQf11FNPKTg4WBs2bNCoUaNUUFBQ5jBx+vRpzZgxQwMHDiw1z8/Pr7zLBnAVCCUALCk9PV3FxcWaM2eOPD1/vf3tvffeKzWusLBQ27ZtU6dOnSRJmZmZysnJUcuWLSVJt9xyizIzM9WsWbPKKx7AFSGUAHC7kydPKiMjwzStQYMGcjgcmjdvnuLi4rRx40YlJyeXWtZms+nhhx/Wiy++KG9vbyUmJqpLly7OkDJ16lTdeeedatKkif74xz/K09NTO3fu1J49e/Tkk09Wxu4BKCOevgHgdmvXrlX79u1Nr3//+9+aO3eunnnmGbVu3VoLFy5UUlJSqWUDAgI0efJkDRs2TF27dlXt2rW1ePFi5/zY2FgtX75cqampuvXWW9WlSxc999xzioiIqMxdBFAGPH0DAAAsgTMlAADAEgglAADAEgglAADAEgglAADAEgglAADAEgglAADAEgglAADAEgglAADAEgglAADAEgglAADAEgglAADAEv4fmkwytPYxU/EAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在相关系数热力图的基础上，使用双星号 ** 标记显著性水平小于0.01的相关系数，使用单星号 * 标记显著性水平在0.01到0.05之间的相关系数，帮助观察者理解哪些相关性是在统计学上显著的"
      ],
      "metadata": {
        "id": "IMp4U4tjPqPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. 计算并输出特征之间的相关性矩阵，并标明是否存在高度相关的特征：\n",
        "# 绘制出热力图，呈现的内容包括相关系数及显著性P值\n",
        "# 这里用来绘制热力图的特征数据要是二维的，故这里使用的是features_mean\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import pearsonr\n",
        "\n",
        "# -------------------------------计算相关系数及显著性P值---------------------------------\n",
        "# 转换为 DataFrame，以便计算相关系数\n",
        "df = pd.DataFrame(features_mean)  # 创建 DataFrame，形状 (num_samples, 6)\n",
        "\n",
        "# 计算特征之间的相关性矩阵\n",
        "corr_matrix = df.corr()\n",
        "\n",
        "# 计算p值矩阵\n",
        "p_values = pd.DataFrame(np.zeros((6, 6)), columns=df.columns, index=df.columns)\n",
        "for i in range(6):\n",
        "    for j in range(6):\n",
        "        if i == j:\n",
        "            p_values.iloc[i, j] = 0\n",
        "        else:\n",
        "            _, p_value = pearsonr(df.iloc[:, i], df.iloc[:, j])\n",
        "            p_values.iloc[i, j] = p_value\n",
        "\n",
        "# ----------------------------绘制带有显著性标记的相关系数热力图--------------------------------\n",
        "# 创建相关系数热力图\n",
        "# 将 cmap='coolwarm' 改为 cmap='YlGnBu'，这将应用从黄色到蓝色的渐变色系\n",
        "plt.figure(figsize=(10, 10))\n",
        "sns.set(font_scale=1.2)\n",
        "\n",
        "# 设置横纵轴的标签\n",
        "feature_labels = [f\"feature_{i+1}\" for i in range(corr_matrix.shape[0])]\n",
        "\n",
        "sns.heatmap(corr_matrix, annot=True, cmap='YlGnBu', fmt=\".2f\", xticklabels=feature_labels, yticklabels=feature_labels)\n",
        "\n",
        "# 添加显著性标记\n",
        "for i in range(len(np.array(p_values))):\n",
        "    for j in range(len(np.array(p_values))):\n",
        "        if i != j:  # 跳过对角线上的元素\n",
        "            if np.array(p_values)[i, j] < 0.01:\n",
        "                plt.text(j + 0.5, i + 0.25, \"**\", horizontalalignment='center', verticalalignment='center', fontsize=16, color='black')\n",
        "            elif np.array(p_values)[i, j] < 0.05:\n",
        "                plt.text(j + 0.5, i + 0.25, \"*\", horizontalalignment='center', verticalalignment='center', fontsize=16, color='black')\n",
        "\n",
        "plt.xticks(rotation=45)\n",
        "plt.title('Correlation Coefficient Heatmap with Significance Levels')\n",
        "plt.show()\n",
        "\n",
        "# 检查高度相关的特征：阈值可以根据实际情况调整\n",
        "threshold = 0.9\n",
        "highly_correlated_features = np.where(np.abs(corr_matrix) > threshold)\n",
        "for i, j in zip(*highly_correlated_features):\n",
        "    if i < j:  # 避免重复输出\n",
        "        print(f\"特征 {i+1} 和 特征 {j+1} 之间的相关性为 {corr_matrix.iloc[i, j]:.2f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "MT4jM9CM1RKo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 928
        },
        "outputId": "63cd6f05-6db3-434d-cda9-29c11ba0a2ba"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x1000 with 2 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAx0AAAOFCAYAAAAPrI+9AAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzs3XdUFFcbBvBn6b13UBAQsKEi9t5FY0Fj7yWxxBqjxhJTjUmMfokllkRN1KjR2I0ae0UFFcWCoCC99973+wPZuO4uZVmkPb9zOIlz79y5M7M7s+/cMgKhUCgEERERERFRFVGq7goQEREREVHdxqCDiIiIiIiqFIMOIiIiIiKqUgw6iIiIiIioSjHoICIiIiKiKsWgg4iIiIiIqhSDDiIiIiIiqlIMOoiIiIiIqEox6CAiIiIioirFoKOe+PTTT+Hs7IyIiIgq3U6vXr3Qq1evKt1GXZKRkYFvvvkGvXr1QtOmTeHs7Ax/f38AQH5+PjZu3Ih+/fqhefPmcHZ2xsWLFxEREQFnZ2d8+umncm/3XX0eiKTZtGkTnJ2dcffu3XKvo4jPfWXcvXsXzs7O2LRpU43a9uPHjzF16lS0b98ezs7OGDp0KAB+x+sy3meptlKp7grUVEFBQdi/fz/u3r2L6Oho5ObmwsDAAE2bNkXfvn0xdOhQqKmpVXc137mJEyfC29sbAQEB1V2VCouOjsaff/4JLy8vhIeHIysrC3p6enB2dkbPnj0xfPhw6OrqvtM6/fDDD/jrr7/Qs2dPDBkyBMrKyjAxMQEA7N69G1u2bEHbtm3h4eEBFRUVNGrU6J3Wryo4OzujXbt22Lt3b4XW+/TTT3Hs2DGsXbsWw4cPl5pn06ZN2Lx5M+bOnYt58+YporrlVvIj4PLly+90u3WJvJ8NeZ09exZ///03nj17hrS0NOjo6MDY2BhNmzZF586d4enp+U7qIa+MjAzMnDkTubm5GDp0KAwNDUXXD5ItIiICvXv3hrW1Nb+vRO8Qgw4pNm/ejC1btqCoqAitW7eGp6cntLS0kJCQAG9vb6xatQoHDhzA0aNHq7uqNc7vv/9e3VWQ6vDhw/jqq6+Ql5cHFxcXDBo0CPr6+khOTsaDBw/w7bff4pdffqnQk1dFuHr1Kuzs7LBt2zaJtCtXrkBLSwu7du0SC3Dz8/Nx5syZSgVIH3/8MT744AOYm5vLXQaRvMaPH4+BAwfCysqq2urw2Wef4dChQ9DQ0ED37t1hY2MDoVCIV69e4cqVK/D29hYLOlxdXXHmzBkYGhq+87rK2rafnx8SExOxaNEizJo1SyyN33EiqmkYdLxl27Zt2LRpEywtLfHzzz+jZcuWEnmuXLmCXbt2VUPtar6GDRtWdxUknDx5EqtWrYK+vj42bdqEHj16SOS5f/8+vvrqq3det7i4OLRt21ZmmqGhoUSLmqqqKhwcHCq1XTMzM5iZmVWqDCJ5GRkZwcjIqNq2f+/ePRw6dAgWFhb466+/YGFhIZaen58Pb29vsWWampqV/t7JS9a24+LiAEDqd5nfcSKqaTim4w0RERHYvHkzVFVVsWPHDqkBBwD07NkTO3fulFh+5swZjB8/Hm3atIGrqysGDx6M7du3Iy8vTyJvSZ/MjIwMrF27Fr169UKzZs1EfXbLSgeKu4B9+umn6N69O5o3b45OnTph8eLFCA4OLvc+Hz16FPPmzUPv3r3h6uoKNzc3jBkzBidOnJA4Ns7OzqIbsbOzs+hv4sSJEvv1try8POzYsQODBw9Gy5Yt4ebmhnHjxuHMmTMSed/sux0REYFFixahffv2aNGiBYYPH44rV66Ue/8yMjKwZs0aAMCGDRukBhwA0KZNGxw+fFhi+e3btzF9+nS0a9cOzZs3R//+/fHjjz8iPT1dajkpKSlYv349PDw84OrqijZt2mDy5Mm4efOmWL6JEyfC2dkZQqEQ3t7eYsfyzb7YkZGRorSS41pa3/bs7Gzs2LEDw4cPR+vWrdG6dWt4eHjgm2++QUJCgihfaf29Hz16hPnz56Nz585o3rw5unfvjtWrVyM2NlYib8l+FBQUYNu2baLxJ927d8e6devEPvtHjx6Fs7MzAIjt87vqJ5+dnY3t27dj6NChaNWqFVq3bo3Ro0fj9OnTEnnz8vKwb98+fPDBB+jZsyeaN2+Odu3aYcqUKbh27ZpY3pL+9pGRkWLn6+1zVHJ+ExISsHz5cnTq1AmtWrXCmDFjcO/ePQBAVlYWvv/+e9E2Bw0ahLNnz0rULz09Hb/99hsmTZqEbt26oXnz5ujQoQNmzZoFX19fqftfsv3Y2FgsWbIEHTt2hKurK4YPH45Tp06V+ziOHj0azZs3R1ZWltjyCRMmwNnZGStWrBBbHhQUBGdnZyxdulS07O0xHRX9bFT2ulByjPr16ycRcADFgX3nzp3FlpU2rsLPzw/Tpk1D69at4ebmhilTpsDX11fm2JWSc5GUlITPPvsMXbp0EZ3vI0eOSJT/9rZLrgHLli0DACxfvlx0vEpa4Ev7jvv5+WHhwoXo2rUrmjdvji5dumDatGkS1+Py3h9KVOR68KagoCAsX74cvXr1QvPmzdGxY0eMGzcO+/fvl5q3sve9iiooKMCff/6JUaNGwc3NDS1btsSwYcOwb98+FBUVifI9fPgQzs7O+Oijj2SW5eHhgebNmyMlJUVs+Y0bN/DBBx+gffv2aN68Ofr06YPvv/8eaWlp5apjXl4e9uzZA09PT7Rt2xYtW7ZEr169MHv2bHh5ecm130SKxpaONxw9ehT5+fkYNGgQnJycSs379tPnDRs2YPv27TA0NMR7770HLS0t3LhxAxs2bMDNmzexc+dOiXXy8vIwadIkpKamonPnztDR0YGNjU250q9fv4558+ahoKAAPXv2RMOGDREbG4vz58/j6tWr2LNnD5o1a1bmPn/xxRdwdHRE27ZtYWpqipSUFFy7dg1Lly7Fq1evsHDhQgCAnp4e5s6di2PHjiEyMhJz584VlWFtbV3qNvLy8jB9+nR4e3vD3t4e48aNQ05ODv79918sWrQIz58/x8cffyyxXmRkJEaOHIkGDRpg6NChSE1NxZkzZzBnzhzs3r0bHTp0KHP//v33X6SkpKBVq1bo0qVLqXnfPj8HDx7EF198AU1NTQwYMADGxsbw9vbGr7/+iitXruDAgQPQ09MTq+/EiRMRGRkJd3d3dO3aFdnZ2bhy5QpmzJiBr776CqNGjQIAeHp6ol27dti8eTOsra1F3Tisra2hp6cHa2tr/PHHHwCAyZMnA0CZ3alSU1MxadIkPH/+HI0aNcKIESOgqqqK8PBwHDlyBH379i2zv/fff/+N1atXQ01NDb169YKFhQVCQ0Nx+PBhXL58GYcOHZLaJWbx4sW4f/8+unbtiu7du+P69ev47bffkJSUhLVr1wIAmjRpgrlz50rsMwC0a9eu1HpVVlpaGiZPnoxnz56hWbNmGDFiBIqKinDz5k0sXrwYL168wKJFi0T5U1NTsWbNGrRu3RqdOnWCkZER4uPjceXKFXz44Yf45ptvMHLkSADF52zu3LkS56tkn9+ux9ixY6GtrY1BgwaJPtPTp0/HX3/9hdWrVyM1NRU9evRAQUEBTp8+jUWLFsHS0hKtWrUSlRMUFISffvoJ7u7u6NGjB/T09BAdHY3Lly/jxo0b2Lp1K7p16yZxHFJTUzF27Fjo6upi+PDhSE9Px9mzZ/HJJ58gNjYWM2bMKPNYdujQAQ8fPsS9e/dE28jOzsbDhw8BAHfu3BHLf/v2bQBAx44dZZZZkc+GIq4LBgYGAIDQ0NAy85bFx8cH06ZNQ1FREfr27YuGDRsiMDAQkyZNKrUuJZ8FNTU19O/fH3l5eTh37hxWrFgBJSWlUseTlFyP/f39cenSJfTu3Vv0WXv7M/e2Q4cO4YsvvoCSkhJ69eoFOzs7JCYm4smTJzhw4AAGDhwoylve+8PbynM9KHH16lUsWLAAeXl56Nq1KwYNGoS0tDQEBATgt99+w7hx40R5FXXfq4j8/HzMmjULN2/eRKNGjfDee+9BXV0dd+/exddff41Hjx5h3bp1AIBWrVqhUaNGuHbtGpKTk6V2hwsODkb//v1Fn0GguEv3pk2bYGBggB49esDIyAiBgYHYtWsXrl+/jr/++gs6Ojql1nP58uU4ffo0nJycMHToUGhoaCAuLg7379/HjRs30KlTJ4UeFyK5CElk0qRJQicnJ+GhQ4cqtN6DBw+ETk5Owu7duwvj4uJEy/Pz84UzZ84UOjk5Cbdu3Sq2Ts+ePYVOTk7CyZMnCzMzMyXKLC09JSVF6O7uLmzXrp3wxYsXYmkBAQHCVq1aCYcNGya2fNmyZUInJydheHi42PLQ0FCJbefm5gonTZokbNq0qTAmJkYsbcKECUInJyeZx6Jnz57Cnj17ii3btm2b0MnJSThjxgxhfn6+aHlCQoJoP+/fvy9aHh4eLnRychI6OTkJN23aJFbW9evXRWWVx/Lly4VOTk7CDRs2lCt/iYiICGGzZs2ErVu3Fr58+VIs7fPPPxc6OTkJV61aJbZ8woQJQmdnZ+Hp06fFlqempgqHDBkibNGihTA+Pl4szcnJSThhwgSpdZB2LIXC/47PsmXLxJZ//PHHQicnJ+Hq1auFhYWFYmkZGRnCtLQ00b+lfR6Cg4OFzZo1E/bp00fivHt5eQldXFyEc+bMkdhnJycnoaenpzA5OVm0PDMzU9inTx+hi4uL2HeirH0uTUmdZ8+eLdy4caPUv5L6bNy4Ueq6O3bsEFuek5MjnDZtmtDZ2Vn47Nkz0fLc3FxhdHS0RB3S0tKEgwYNErZt21aYnZ0tlibrfL25305OTsLPPvtM7PwcO3ZM6OTkJGzbtq1w5syZwpycHFGaj4+P0MnJSeK4p6WlCRMTEyW2ER0dLezcubNwwIABMrc/f/58se2HhYUJ27ZtK2zWrJkwLCxMZv1LeHl5CZ2cnITfffedaFnJ93Lq1KlCJycnsevKnDlzhE5OTsKoqCjRso0bNwqdnJyEd+7ckaijrM+GIq8LMTExwjZt2gidnJyEM2fOFJ48eVL46tUrYVFRkcx17ty5I/HZKiwsFPbt21fo5OQkvHr1qlj+/fv3i+orbT+dnJyEK1asEBYUFIiWv3jxQtikSROhh4dHmdsWCoXCI0eOCJ2cnIRHjhyRqK+07/iLFy+ETZs2FbZt21YYGBgosc7bn3l57w/lvR4kJiYK3dzchM2aNRPevXu31PrIc9+TpeSzVNr3tUTJZ/Wrr74SO1cFBQWi+8uFCxdEy0vud3v37pUo64svvhA6OTkJL126JFp2+/ZtoZOTk3D06NHC1NRUsfwl53fNmjViy9++1qSlpQmdnZ2Fnp6eYnUskZSUVOZ+Er0L7F71hvj4eACo8MC7kubw2bNnw9TUVLRcRUUFy5Ytg5KSktSuO0BxE7iWlpbMsqWlHz9+HGlpaZg/fz4cHR3F0pycnDBy5Eg8e/YML1++LLPu0sZgqKmpYfz48SgoKBA9payMI0eOQCAQ4NNPP4WKyn+Na8bGxpg9ezYASD0+1tbWovQSXbt2hZWVFfz8/Mq17ZJzKq0LRWlOnjyJ/Px8TJgwQaIv9aJFi6CtrY0TJ06Iugs8f/4c3t7e6NevHwYNGiSWX09PD/PmzUNubi7+/fffCtWjvBITE3HmzBmYmpqKPnNv0tbWLrOl5MCBA8jPz8fKlSslvgMdO3ZEr169cOXKFWRkZEis+8knn4g9udPS0sLgwYNRVFSEJ0+eyL9jUly6dAmbN2+W+vd2P3wASE5OxsmTJ9G8eXN88MEHYmnq6upYsmQJhEKhWBcjNTU1qZ8ZXV1djBgxAqmpqXj8+HGF666pqYmlS5eKnZ/BgwdDRUUFqampWLlyJdTV1UVp7u7usLa2Fk2j/GY9pI2JsLCwwIABAxAcHIyoqCiJdGVlZXzyySdi22/QoAEmTpyI/Px8md1m3uTm5gZ1dXWxFo3bt29DRUVFNGNYyXWjqKgI3t7esLOzg6WlZZlll4cirgvm5ubYvHkzGjZsiCtXruCTTz5B//790aZNG0yfPh0nTpxAYWFhmeU8ePAAoaGhaN++Pbp37y6WNnr0aNjZ2clcV1NTE8uXL4eysrJomaOjI9zc3BAUFITMzMxy7UtFHDhwAAUFBZgzZw4aN24skf72Z17e+0N5rwfHjx9HRkYGxowZI7W18836KPK+V15FRUXYt28fTE1NJc6VsrIyPv30UwgEArFrx9ChQ6GkpIRjx46JlZWXl4czZ87A2NhYrBWyZKa2r7/+WqzlHACGDx+OJk2alNn9USAQQCgUQk1NTeLaD6BaJj8gkobdqxTg2bNnACC1Kb1Ro0awsLBAREQE0tPTxX74qauri/oxSyMrvaQbw/Pnz6X2Lw4JCQFQ3AXj7Yvz26KiovDrr7/i9u3biI6ORk5Ojli6tH78FZGRkYHQ0FCYm5tLHQhZcsze/lEFAC4uLmIX+RIWFhaiY1BVSjun+vr6aNq0KXx8fBAcHAwXFxdRH/GMjAyp5yQpKQkAqqzf8ePHj1FUVIS2bduWGsSWpuSYent7S/1BnZiYiMLCQoSEhKB58+ZiaW//G4DoR2Zqaqpc9ZGlPFPmvunx48coLCyEQCCQem4KCgoASJ6bFy9eYOfOnfDx8UF8fDxyc3PF0uX5btjZ2Ul0k1BWVoaxsTGys7PRoEEDiXXMzc2l/pi+f/8+9uzZg4cPHyIxMRH5+fkS9Xu7K5ylpaXUbZT84Cv53JdGXV0drVu3xt27d0VdSO7cuYMWLVqgdevWMDExwe3btzF69Gg8ffoUaWlp8PDwKLPc8lLUdaFDhw74999/8eDBA3h7e8Pf3x8PHjzAzZs3cfPmTRw/fhzbt28vdWr0kutWmzZtJNKUlJTg5uYmuh6/zdbWVmqXmZIf2mlpadDW1i73/pRHyfHp2rVrufLLe38o7/WgpD7SugK+TZH3vfJ69eoVUlJSYGdnh61bt0rNo6GhIXbtsLCwQMeOHXHr1i28fPlSVJcrV64gJSUFU6ZMEXv49vDhQ6iqquLcuXM4d+6cRPn5+flISkqS2l2rhI6ODnr27IkrV65g6NCh6NevH9zd3dGyZUtoampW5hAQKRSDjjeYmpoiKCiowj8mSgYVv9nK8Xa5UVFRSEtLEws6jI2NIRAIZJYrK71kANqhQ4dKrdfbAz3fFh4ejvfffx9paWlwd3dHly5doKOjA2VlZURGRuLYsWMyB/6VV8lTcVnHpmR2FWmD5d5+6lNCRUVFbPBeaUq2WxXnFPiv3iXn5NatW7h165bMcss6J/IqqUdlpscs2QdpkyS8Sdo+SDtXJT8My3uuqkrJfj1+/LjU1ok3nyw/fPgQkydPRmFhITp06IBevXpBR0cHSkpKon708nw3ZLU2qaiolJpWEhiVuHDhAubPnw91dXV06tQJDRs2hKamJpSUlODt7Q1vb2+p9ZM1pqdkuawJEt7WsWNH3LlzB3fv3kXHjh3h7++PmTNnAij+Me/l5QWhUFiu8RwVpYjrQgklJSW4u7vD3d0dACAUCnHr1i18+umn8PLywv79+zFlyhSZ65ccL1nH1djYWOa6pe0HgHK1tFRUSX3Lc52ozP2hvNeDitRHUfe9iijZZkhIiMTDjDe93Srl6emJW7du4dixY1iyZAkAiFo+3h6rk5KSgoKCglLLB4r3q7QWi59++gm//vorTp8+LQrK1NXV0b9/fyxbtozvb6EagUHHG9q0aYM7d+7gzp07okGi5VHyYyEhIUFqc3RJF5+3f1SUFnCUll5SzokTJ+Di4lLuer5t9+7dSElJkfrk+PTp0xLNw/IoeZL35sxJbyqZ8rGqXsrXpk0bHDlyRGJwa1nePKfSuiG8fU5L/rty5UpMmjSpMlWWS8lNvjItUyXn6v79+2UOWqxNSs7NlClTsHz58nKts3XrVuTk5GDPnj1o3769WNr27dtx6dIlhdezIn7++WeoqqriyJEjEi2Iq1evltrNDJD9PSxZXt7vYUkLoJeXF5SUlFBUVCQKLDp06IDTp0/j+fPnuHPnDgQCgcQxrKkEAgG6dOmCBQsWYNWqVbhz506pQUdZ17fExMSqqKbcSs5vbGxsmd/xd3F/eLM+pbX6v5m3sve9iijZZt++fcsMCt7Ut29f6Ojo4OTJk/j444+RkpKCGzduwMXFRaLuOjo6olkMK0NDQwPz5s3DvHnzEB0dDR8fHxw7dgwnT55EZGSk1JnAiN41jul4w/Dhw6Gqqop///23zH6hbz7hKZktRNqL5UJDQxETEwMbGxuZT7YqqmQq3/v371eqnJKZW/r16yeRJusCWNJftLxP4XR0dEQzjEjrZlByzJo2bVqu8iqqZJYQX1/fMqcNLO85TUtLg7+/P9TV1UU/+ErOScnUp++aq6srlJSU4OPjI/eTvpLZkap6H5SUlKrkKa4sJcemIvsVGhoKAwMDqT+WS/tuvKv9Cg0NhaOjo0TAUVRUVOp1ITo6WuoUqiX7VN7vYYsWLaCjoyN6SKOhoYHWrVsD+C8guXbtGh48eABnZ+dyv5PjXX82ZClvt6aS4yXtmBcVFeHBgwcKrVdllXzHb9y4UWZeee4P8tbn+vXrZeZV1H2vIuzt7aGnp4eHDx9KdF8sjYaGBjw8PBAXFwcvLy+cOnUKBQUFUmcka9WqFVJTU/HixQuF1dvS0hJDhgzBzp07YWtri/v37yM5OVlh5RPJi0HHG2xsbDB37lzk5+fjww8/lNkV4/r162JTS44YMQJA8dPRkr77QPEP8++//x5FRUV4//33FVbP4cOHQ09PD5s3b5ba17uoqKhcb9Yumer27RvIjRs38Pfff0tdp2RwoLRBqrKMGDECQqEQP/zwg9gPiqSkJPzyyy+iPFVBR0cHK1euBFA8AFzWzfbhw4cYPXq06N9DhgyBqqoq9u3bJzGt5s8//4yMjAwMGTJE1N+7RYsWcHd3x4ULF2Qeu4CAgCp78mlkZISBAwciPj5e9Jl7U2ZmZpldZ8aPHw9VVVWsXbsWr169kkjPy8tTSEBiYGCAmJiYSpdTXsbGxhg8eDCePHmCLVu2SP1RGxYWhvDwcNG/ra2tkZKSgufPn4vlO3z4sMQ7V0oYGBggKSlJot97VbC2tkZISIhYy5ZQKMSmTZtKfWBSWFiIH3/8UezzER4ejr1790JFRQVDhgwp1/aVlZXRtm1bhIaG4ty5c2jTpo3ou9CgQQNYW1tjz549yM7OLtcUtiXe1Wfj+vXrOH/+vNQfkpmZmdizZw8AiLpdyeLm5oaGDRvi7t27Eu9v+euvv2SO56guY8eOhYqKCn755Repn5M3j70894eKGjZsGHR0dHDw4EH4+PiUWh9F3fcqQkVFBRMmTEB8fDy++eYbqd/tuLg4qceyJMA4fvw4Tpw4ARUVFQwePFgiX0lL2meffSa1pTorK6vMsUpJSUkICAiQum5WVhZUVFSgqqpaahlE7wK7V71l1qxZKCgowJYtW/D++++jdevWaN68ObS1tZGQkIB79+5JDKR1c3PDjBkz8Ntvv+G9995D//79oampiRs3biAwMFA0I4qiGBoaYuPGjfjoo48watQodOzYEY6OjhAIBIiJiYGvry9SUlLKnF1n3LhxOHr0KBYsWID+/fvDzMwML168wI0bN+Dh4SH1xX0dO3bEuXPnMG/ePHTv3h3q6uqwsrLCsGHDZG5n2rRpuH79Oi5duoShQ4eiW7duyMnJwblz55CYmIgZM2aUeXOvjCFDhiA3NxdfffUVZsyYgSZNmqB169bQ09NDSkoKHj58iOfPn4v1l7WxscHy5cvx1VdfwdPTEx4eHjAyMoKPjw98fX1hb2+PTz75RGw769evx+TJk7Fy5Urs3bsXLVu2hK6uLmJiYhAYGIjAwED89ddfpfbzrozVq1fjxYsXOHjwILy9vdGlSxeoqqoiIiICN2/exNatW0vt5uLg4IA1a9Zg5cqVeO+999C1a1fY2dmhoKAAUVFRuH//PgwNDaUOdqyIjh074p9//sGsWbPQtGlTqKiooG3btjLfzK4Iq1evRmhoKDZu3IiTJ0/Czc0NJiYmiIuLQ1BQEB4/fowNGzaIBlmXvNBx3Lhx8PDwgK6uLp48eYL79++jf//+Umch69ixIx4/fiz6PKupqcHFxUXqyzIra8qUKfj888/h6emJfv36QUVFBQ8ePEBQUJBoQKk0zs7O8PPzw/Dhw9G5c2fRezrS0tKwZMkSqd1DZenQoQOuXLmCxMREicCiY8eOoh+mFRnP8a4+G8HBwVi7di309fXRpk0b2NnZQVlZGTExMbh27RrS0tLQsmVLTJgwodRylJSU8M0332DGjBmYM2cO+vXrh4YNGyIgIAC3bt1Ct27dcP36dakzClUHR0dHfP755/j8888xbNgw9O7dG3Z2dkhOTsaTJ0+gra0tmk1JnvtDRRkZGWH9+vWYP3++6EWXzs7OyMjIQEBAgOjdM4Di7ntvSk5OlvqSVaC4teKLL77AnDlz8Pz5cxw8eBBXrlxBhw4dYG5ujsTERISGhuLBgwdYtGiRxOD1Nm3awNbWFv/++y/y8/PRs2dPqdf+jh07YvHixdiwYQP69++Pbt26wcbGBllZWYiKioKPjw/c3NxKHWsXGxuLYcOGwcnJCc7OzrC0tERGRgauXr2K+Ph4TJw4sU51maXai0GHFHPnzoWHhwf279+Pu3fv4ujRo8jLy4OBgQFcXFwwY8YMDB06VGydJUuWoGnTpti3bx+OHz+OgoICNGzYEAsXLsS0adNKnQFFHh07dsTJkyexa9cu3Lx5E/fu3YOqqirMzMzQoUMH9O/fv8wyXFxcsGfPHvz000+4du0aCgoK4OLigs2bN0NXV1fqTWXkyJGIiorCP//8g99++w0FBQVo165dqUGHmpoadu/ejd27d+P06dPYt28flJWV4eLighUrVuC9996rzKEol5EjR6JLly7Yt2+fqLk7Ozsburq6aNy4MZYvXy7RGjV+/HjY2tpi165dOH/+PLKzs2FpaYnp06dj1qxZEt3lLCwscOTIEezbtw/nz5/HqVOnUFhYCBMTEzg6OmLChAllvnSyMvT19XHw4EH88ccfOHPmDA4dOgQlJSVYWlpixIgR5ZrRZejQoXBxccHu3btx9+5d3Lx5E1paWjAzM0P//v0VMgvRypUrIRAIcPv2bVy7dg1FRUWYO3dulQYdOjo62Lt3Lw4dOoTTp0/j/PnzyM3NhYmJCWxtbUVvCC/RrVs3bNu2DVu3bsWZM2egrKwMV1dX7NmzB+Hh4VKDjtmzZyMtLQ1XrlzBgwcPUFhYCE9PzyoJOsaMGQM1NTX88ccfOH78ONTV1eHu7o61a9fi/PnzMoMOfX19/Prrr1i3bh2OHj2KjIwMODo6Ytq0aVKfwpbmzWBCVtChoqJSoQcK7+qzMWTIEOjo6MDLywvPnz/HvXv3kJWVBV1dXbi4uGDAgAEYOXJkua7b7du3x759+/DTTz/h6tWrAIq7Au3Zs0c01WlN+sE3atQoNG7cGLt27YK3tzcuXboEAwMDODs7i41llOf+II8ePXrgyJEjolmybt26BT09Pdjb24smJyihiPvem7KysmSOTdHV1cUXX3wBVVVV/PLLLzhx4gSOHTuGq1evigZ129jYYMGCBTK/O8OGDcPPP/8MQHIA+Zs+/PBDuLm5Ye/evbh//z4uX74MHR0dmJubY9SoUWXeI62trTFv3jx4e3uLZpUzMDBAo0aNsHjxYolp3Imqi0AoFAqruxJERFS1nJ2d0a5dO9GTbKp6Y8aMgZ+fH+7duyf3VNZERHVFzWjzJSIiqoWys7OlTvl99OhR+Pr6onPnzgw4iIjA7lVERERyi4qKgqenJzp16gRbW1sUFhbi2bNnuH//PvT09GSOGSAiUoQdO3bg2bNnePbsGcLCwqCkpFSuF72+LTs7G1u2bMGZM2cQFxcHMzMzDBo0CHPmzFHYSyYZdBAREcnJxMQEgwcPho+PD+7evYv8/HyYmJhg+PDhmD17doUG5xMRVdT69euhp6eHJk2aICsrS2wW1fIqLCzEhx9+CG9vbwwdOhRt27bF8+fPsXPnTvj5+WH37t0KmRCDQQcRUT0gbUpNqjx9fX2sWbOmuqtBRPXUhQsXRA83Jk6cKFfQcezYMXh7e2PixIlYtWqVaLm1tTW+//57nDx5stQJg8qLYzqIiIiIiGohRbSmnjhxAgAwdepUseXjxo2DhoYGjh8/XultAAw6iIiIiIjqJaFQiMePH8PMzEz0UtASGhoaaNKkSYXef1Madq8iIiIiIqomvXv3LjX90qVLVbbtlJQUZGdno3HjxlLTzc3N4evri4yMjEq/c6hWBB2aDcdWdxWoFIN+n13dVSAZYjPYmFlTRW97Ud1VoFJMWdOguqtAMqgp8/ViNdVS177VXQWZavJvyU7Sf++/Ezk5OQAg82Wo6urqAIpnt6oXQQcRERERUV1UlS0ZZdHQ0AAA5OXlSU3Pzc0FAIVMm8vHoERERERE9ZCBgQE0NTURExMjNT02NhY6OjqVbuUAGHQQERERUR0nECjV2L/qPS4CNG/eHHFxcYiMjBRLy8nJgb+/P1q0aKGQbTHoICIiIiKq47KzsxEUFIS4uDix5UOHDgUA7N69W2z5gQMHkJOTI0qvLI7pICIiIiKqhY4fP46oqCgAQGRkJIRCIX755RdR+pw5c0T/7+fnh0mTJsHT0xPfffedaPnw4cNx/Phx7N27F+np6XB3d0dAQAD279+Pdu3aYciQIQqpK4MOIiIiIqrTBHW0c8+RI0fg7e0ttuznn38W/f+bQYcsysrK2LFjB7Zs2YKzZ8/in3/+gampKaZOnYqPPvoIysrKCqkrgw4iIiIiolpo79695c7bvn17BAQESE3T1tbG0qVLsXTpUkVVTULdDPuIiIiIiKjGYEsHEREREdVp1T1LFLGlg4iIiIiIqhiDDiIiIiIiqlLsXkVEREREdRq7V1U/ngEiIiIiIqpSDDqIiIiIiKhKsXsVEREREdVpAoGguqtQ77Glg4iIiIiIqhSDDiIiIiIiqlLsXkVEREREdRyfs1c3ngEiIiIiIqpSDDqIiIiIiKhKsXsVEREREdVpfDlg9eMZoHrrSO/uiH/oW2a+ax8vwLM/dr+DGlGJm0O7IuVx2efGb+U8hB7Y9Q5qRG8KOjsN2YnPy8wXefd7JL04XvUVIiKiGo9BB9UbRQUF5UovK19581D58dzUbMKi0o9pSXpZ+cqbh4iI6p4qCzoCAwNx/PjxqiqeqEJyU1JwbsIYBB76S+qP0iivWzg/ZSJi7/ng+uKFeLDhR+SmpkrkS30VjOts+VCo/NRk3PtwNCKOH5R6bhLv3sSDj8Yj+aEPnqyaj5e/rEN+muS5yQwNxuOV8xHGlg+FKsxNQ+i1ZUh5dU5qwJAZ64uw6yuRlfAUUd4/IP7JHyjMy5DIl5segci7PyDp5Yl3UW0iIjECgVKN/asvqmxPL126hOXLl1dV8UQVoqavjxYz5+DV6ZO4+ME0xD24DwDIiIzAzeVLce+7b2HnMRDGzZrDdfZHyIiKxPnJExB08jhQVIT8zEw82rIJl2fPhLalFewHD63eHapDVPQM0GjqHMT8ewK+C6Yg5dE9AEBOdDiefrUEgT+vgXnvQdBzaY5G0+chOzoC9+eMQ/TZY0CREIWZGQj+bSMeLv4AGhZWsBzAc6NISmq6MHEZjbSwawi/+TmyEp4BAPKzYhF973+I8/sNejZdoGHgCGOXscjPikPY9eVIDb0CCIUoKshGwrP9iPT6CqpaJtBv0LOa94iIiKqDQCgUCqui4K1bt2Ljxo3w9/evdFmaDccqoEZUVQb9Pru6q1BuRYUFCDnzD/z37kFOYgKU1dXhMNQTzmPHQ01PTyxv7D0fPNn5K1ICAwCBANZduqHZ9BnQbdCwmmpfcbEZtecJirCwADHnTyP80B/IS0qAkpo6LAcNh82ICVDVFT83yb7eCN27AxlBxefGuEM32E74EFo2tefcRG97Ud1VqBBhUSHSIq4j+eUpFOamQKCkBn3bXjCwHwhlNR2xvFnxT5AUeAS5aaEABNA2d4OR03Co6VhWT+XlMGVNg+quAsmgplwlP1tIAZa69q3uKshk4DiruqsgU8rLbdVdhXeiQrNXnTp1qtx5nz8ve5Ah0bsmgAACJSUIBIL/likrA0oCybxKSngjGwTKSkA9agZ99wSvj/Eb5+atc/XmcvF8yhBIOYekQALB624Ab34pZHwnBOLnR2Y+IqJ3RMBhzNWuQkHHkiVLpP4AkEYoFJY7L9G7EHn9Gp7s+g0CgQBtln6Km0sXo+VH8xB58wb+nTAOzuPGw2GYJ9JCQvFk5w6kBASg6dRpUFZTh4GTM4RFRbj4wVTY9h+AJhOnQNPYuLp3qc5I8LqK0H2/AgIBnOavwJPPF8H+g/lIvHMD92aNgc2ICbAaNBxZ4SEI2bMdGUEBsB03A0pq6tBxcIJQKITvgikw6+WBhqOnQM3IpLp3qU7JiLmHpMCjAAQwc52GaJ/1MGk6FpmxDxB2bRkM7QdBz7Y38jOikBj4N3JTQ2DU2BMCJTWo69sCQiEibq6GrnVnGDoOgYqGQXXvEhERvWMVCjo0NDTg7OyMMWPGlJn3ypUruHDhgtwVI1Kk3JQUPNqyCY4j3ofj8PehpFL80dextkGXtT8g6tZNPNq6Gfr2DvDf8zt07ezQbsVnUNfXR8S1q1DV1kbTyVPRaNB7eLjpZwQdO4LmMz6s5r2qG/JTkxH820ZYDR4Jq8EjRedGw7IBmq1eh8S7NxC8cxO07RwQdnA3tBo2gvPiz6Gqp4/4W5ehrK0D27HTYNFvMIJ2/A9R/xyB3cSZ1bxXdUdhbhoSnh2AgV1f6Nv1gUCp+PyoapnD0n0RMmN9keB/AGq6Nkh+eRKqulYwbzkTymo6yIjxgZKKJowaD4Nug25IePYnUkMvwdh5RDXvFRERvWsVCjqcnZ2Rm5sLT0/PMvPGxMQw6KAaQ93AAAP+PCj6Qfs2q85dYNG+A5RUVGDaqrXMfPqN7NF9w8+cllWBVPUN4b7jkMxjbty+KwzbdISSigr0W7jJzKdtaw/XNZt4bhRMWV0Ptj2+FwUbb9M2bw0t0xYQKKlA09hFZj51XRtYt1/GKXOJqFrUp1miaqoKnQEXFxe8fPkSeXl5VVUfoioj68fq2+ll5StvHio/npuaTVYg8XZ6WfnKm4eIiOqeCl39+/fvj7y8PKSkpMDMzKzUvL169YKFhUWlKkdUlUZculaufN03/FzFNaG3dTlxo1z5XNdsquKakDQOHuV7F4p1+2VVXBMiIqotKhR0dOrUCZ06dSpXXmdnZzg7O8tVKSIiIiIiRWH3qur3zs5AVlYWNm/ejIiIiHe1SSIiIiIiqgHeadCxZcsWhIeHv6tNEhERERFRDfBOR/RV0cvPiYiIiIhkYveq6sczQEREREREVYpBBxERERERVSlOmE5EREREdZoAguquQr3Hlg4iIiIiIqpSDDqIiIiIiKhKvdPuVQIBm7aIiIiI6N3i7FXV752eAU6ZS0RERERU/yikpSMvLw/JyckwNDSEmpqa1DwmJiZ4/vy5IjZHRERERES1SKVaOvz9/TF58mS4ubmhR48euH//PgAgMTERkydPhpeXl0IqSUREREQkL4FAqcb+1Rdy72lAQADGjRuH0NBQDB06VCzN2NgYOTk5OH78eGXrR0REREREtZzcQcfGjRthYmKC06dPY/HixRLjNTp06IBHjx5VuoJERERERFS7yT2m4969e5g+fTp0dHSQnJwskW5lZYX4+PhKVY6IiIiIqLLqUzemmkruM5CVlQV9fX2Z6dnZ2ZytioiIiIiI5A86rK2tS52N6t69e7Czs5O3eCIiIiIiqiPkDjr69++P48eP4/Hjx6JlJS//O378OC5dugQPD4/K15CIiIiIqFKUavBf/SD3mI4PP/wQly9fxrhx49CqVSsIBAJs2bIFa9euRWBgIJo2bYopU6YosKpERERERFQbyR1eaWtr48CBAxg7dixevnwJoVAIHx8fREdHY/z48fjjjz9kviiQiIiIiIjqD7laOgoLCxEbGwstLS2sWLECK1asQFJSEoRCIYyMjETdrIiIiIiIqhtnr6p+cp2BgoIC9O7dG4cPHxYtMzIygrGxMQMOIiIiIiISI1dLh7q6OvT19aGtra3o+tRIngPboWv7pnBtZosWTRpCT1cLB47exLSFWypclrWFET5bPBL9erSEkYEOYuJScOr8Paz56QhSUjOlruPS2BqrFr2Prh2aQE9HE2GRCTh86jZ+3HICObn5ld29OiE/OQmxp04i/dkTFGZmQkVPH3otW8F80GAol/Nzmu7/DBlPnyA7Ihw5EeEozMyEloMjHD5ZVua6qQ/uI+nmdWSHhaEoNwcqunrQaNAAZv09oGXvUNndq9VMNdQw3cUW7c0MoKeqisTcPNyITsTuwDBk5BeWub6GshK6Whijo7khnPR1YKapDiGECMvIxsXIBBwJjkJBOabnntS4AT5oYgsAWOj1GPcTUiu9b7WdhbEWFkxsjW5tbGCop464pCxcuB2GTfsfIi0jr8z127ewwJ/flz1hSNdJhxCdIH59c2ygj/kTWqN9CwvoaKkiMi4T/1wLxrbDj5GbV/bnoq7LTEzGo8OnEfXIH7npmdA00EODti3hOmIg1HW0yl1ObkYm/I6cRbjPI2SnpEFdVxtWLZug5cj3oG1sKJE/9M4DxPq/RHJIBJLDIpGfnYNGXdqiy9wpCty7uqUgNw9+xy8g+NZ9ZCQkQVVTA5bNGsNt1CAY2FhUqKyiwiI8O3sVgVfuIC06HspqqjBzskOrEQNg7mwvkT/+RQhCvB8hKSQSia/CkZ2aDi0jA4zd/o2ido9IYeQeSN6xY0fcuXMH48aNU2R9aqRl8zzRspkd0jOyERmdBD3d8l/w39TI1gxXjn4Fc1N9nPrXBwFBUXBv6Yi50z3Qt7sreg3/AkkpGWLrtG3lgLMHV0FVRQXHztxFRHQienRqhpULR6Bn52bwGLsGeXkFCtjL2is3Pg7B675DQXo69Fq2grq5BbJCXiHxyiVkPHsK+0+WQUVHp8xykq5dQdqjhxCoqkLN1AyFmdKDwDcJCwsR/scupPp4Q83MDPpt3KGsqYmCtDRkvQpCdlhYvQ46rLQ0sLWrK4zU1XAjOhGhGVloYqCLUQ7WaG9miDk3/ZCWX/rn19VID6vbOCM1Lx++Cam4EZMIXVUVdLEwxtxmjdDd0hgLvR4jr0h24OGkr40pzg2QVVAALRW5L3t1SkMLXRxaPwgmhpq4cDsUweGpcHU2xdRhzdCtjTVGf3IGKem5pZYREZuBjX/6Sk1zsjPEgM52CAhJlgg4WjqbYO/aAVBRVsK5WyGIjs9Cx5YWmDe+NTq2ssKk5eeQV1CksH2tbdJj4nHu8/XISU2Hjbsr9K3MkRAUiudnryDq0TMM+PJjqOuWfU3LTc/AudXrkRYdB4tmTrDr1AapUbEIunoHkb5PMeCrT6BrbiK2zuNj55AcGgkVDXVoGRkgPzunqnazTijMz8e5rzcjNiAYJg4N0XRgD2QmJOPVHV+EP3gKj8/nw6yxXbnKEgqFuPLTboTc8YW+lTmaDuiG3IwsBHvdxz+PfkLvT2bAtq2r2DpBN+/h6ZmrUFJWhoGNBbJT06tgL+sGdq+qfnLffZcsWYLx48fjf//7H2bMmAFdXV1F1qtGWfrVXkRGJyEoJAZdOzTB+UOr5Srn52+mwdxUHx+v/h1bf/9XtPz7zyZg/geD8MXS0Zi/YqdouZKSANvXz4K2lgben/4j/rlwH0Dx1MR/bl0Az4HtMX/GQPz4y8nK7WAtF3XgTxSkp8Ny1BiY9Oz93/K//0LipYuIPXkM1uMmllmOSb8BMB8yDOoWlshPTkLAquVlrhN7+iRSfbxhOmAgzAcPhUBJ/KImLKzfAeFiVwcYqavhp8dBOPIqWrR8brNGGO1gjQ+a2GK9X1CpZSTl5uOr+wG4EpUg1qKx5WkINnVugRZGevBsZIW/giKlrq+mJMCq1k54npKByMwcDGhgppidq+W+/KgjTAw18eXWO9h7yl+0fMUHbTHNszk+nuyG1Ztvl1pGZFwGNv75UGra/5Z2BwD8dS5AbLmSkgDfL+oKLQ1VzPzyIi7dDQcACATApuU9MaCLHaZ6NsP2w48lyqwv7u76Czmp6Wg7ZSRcBvQQLb+35wj8z1yG71+n0GHG2DLL8T14EmnRcWgyqBfcJ44QLfc/ewX3/vgb3rsOovfyuWLruE96H1pGBtC1MEXssxe48PXPCtuvuujJ6cuIDQiGXYfW6LVoqugeYO/TBhd/2IEbv+zD8PUrJO4N0gTfuo+QO74wc7aHx+p5UFFTBQC49OuC05/9Dze37YdlcyeoaWqI1mncowMce7SHoY0llFVVsHPkXFnFE1U7ucO+iRMnIicnBzt27EC7du3QuXNn9O7dW+yvT58+iqxrtbl++xmCQmIqVUYjWzP07d4SIWFx2PbHebG0rzf8jYzMHIwb3gVamuqi5V07NEWTxja4ccdfFHAAxU9DVny7HwAwY3zdOMbyyo2PQ4b/M6gaG8O4e0+xNPP3hkJJXR3Jd++gKLf0J7YAoG3vAA0r63LdHAAgPzUVCRfPQ7ORPSyGekpdT6Bcf5+qW2lpoJ2ZIaIyc3D0jYADAHY+D0NWQSH625hBQ7n04/0yLRMXIuMlulBlFxbi4OtAo7Wxvsz1Zzaxg6WWBr71DYSwHN2w6oOGFrro2sYa4THp2HfaXyzt532+yMzOx7BeDtBUl+/za6injn6dGiI7pwDHLokHle1aWMCxoQG8H8eIAg4AEAqB73f5AADGDnSWa7t1QXpMPKL9/KFtagznft3E0lqOHAQVdTUE3/BGfk7p17T8nBwE3/CGiroaWr4/SCzNpX93aJsYIeqRP9JjE8TSLJo5Qc/SjOMzy0EoFML//E0AQLsJ4g+dbNu6wryJA1IiYhD97GW5yvM/fwMA0GbMe6KAAwBMHW1h38kNOWkZCLkj3rJo3MgGJo0aQFm1/t5rqPaQO+iwsrKCo6Mj3N3d4e7uDnt7e1hZWYn9WVpaKrKutVr3js0AABdv+En88MnIzMHtewHQ1tJAOzdH0fIenYrXOX/tkUR5IWFxCAyKgm0DUzSyrb9PbjMDip+i6jZpJvGjX1lDA1r2DhDm5SHrVbDCt53qex/CggIYuLdFUV4eUh/cR9y/Z5F49QqyI8LLLqCOczMpDgR84pPx9k/97MJCPElKg6aKMpoZyt9KWlBU3AWnUEYw4Waij/ftrbDdPxQRmewmUqJDy+J+5jcfROHtQ5eZXYAHz+KgpaGKVi6mcpU/vLcj1NVUcPZmCNIzxceGdGxZfF+4fj9CYr3wmAwER6TCxlwXDS3qbut5aWKeBQIArFxdJK5pqpoaMHV2QGFuHhJevCq1nIQXISjMy4epswNU33gyDgACJSVYtWxSvL2ngQqsff2SHpOAzIRk6FuaSXRTA4AGrZsCAKKflH2MC/LyERfwCirqarBoItkl1+Z1WVGPeb7kJYBSjf2rL+QOjffu3avIetR5TvbFN9qXwdJbTIJexaBv95Zo3MgSV289LV7HoWSdaKnrvAyJgZODFRo3ssSr0LgqqHXNlxtbfDzVzM2lpquZmQP+z5AbGwsdlyYK3XZ2SAgAoCgvD4Fffob8pCSxdL3WbmgwZRqU1NSlrF33NdTRBACEy/ixH56ZjXYwRAMdTbkHdQ9qWHze78YlS6RpqyhjRavG8EtMw9+vouQqv65qZF0cEIZESj/uIVFp6NrGGo2s9XD7kfTrT2lGDXACABw4GyCRZm+tBwB4FZkmc9v2Nvqws9FDWEz965+eFhULANCzlP4wSc/CFNF+/kiLjoNlCxe5y9G1KF6eHl0/7x2KkFJyjK1knavi5alRZR/j9NgECIuKoGtmDCVlZcmyLIsfAKTxfFEtxva4d0RPr3jweWp6ltT0kuX6+v/NtFQyYF3WOmlpxcsN9OrHLGLSFOZkAwCUNTSlpitrFi8vzJZ+DCujIL34B1HsqRPQdnCE7ayPoG5mjpyoSET9tR9pvg8Qqa6OBpOnKXzbtYH26wHbmTIGime+nrlKR86B3cPtLNHB3AiBqRn4JyxWIn1hCwfoqqlinlf9HRsgi6528Ytb07Okz1BV0jqhp1PxF7y2a24OhwYGCAhJhq+/5A8k0bYzy9i2dv18uWxeVnGQrqol/ZpWsjwvK7uMcrJLLUdNVI7ir431Rf7rY6wm8xgXtzCV5xjnlVnW6/OVWfp5J6rJGHQQyUtY3LVHWUsbtrPnigIcrUb2sJ09F4Gfr0LK3TuwGOoJVQPJqSlJft0sjTGvuT0Sc/KwysdfontVd0tjDGhghvV+LxGdVfZ4HlKc0R7F4zEOSmnlIKptHhz6R2JZ4x4doGtmXA21ocrg7FXVT+6gw8XFpcyBZgKBAM+ePZN3E3VKSauEvozpdkuWp77xro609NLXKWk9SUkre2rXuqqkhaOkxeNthdmvW0I05ZvmuNRtaxWXqePiIgo4SqjqG0DTzh6ZAf7IDg2tl0FHZkFxC4e2jAGO2qrFXQgyCio2w1dXCyN80cYZKXl5mH/riURQoauqgk9cHXEvPgXHKzkBRF1V0pqgqyW9NaGkNaI87+p4k76OGgZ0tkV2TgGOX5Y+K5lo2zJaMkTbltESUteVPB3Pl9GSUdbT9f/K0Sy1nP+erCv+2liX+B4+K7HMsllj6JoZl9nqVNJqVZ5jrFZmWa/Pl3bp552oJpM76Bg2bJhE0FFQUIDw8HA8evQIzs7OaNJEsX3oa7PA1+MyHO2lvyjIoVHx8hdvzPITGFSyjvQB+Y52kuvUN+rmxccgL1ayew0A5MXFvs4nfcyHIrYtK6BR1i5eXpRXP388hWUU3yQbaGtITW/w+uYZnlH+7gI9LI3xeRtnJObmY6HXY6mDw8011WGgrgp3UwPcGNJFajk/dWoBANj4JBiHg+vfeI9Xr8dy2FlLn/XLzqr0cReyDO9TPID8yIUXMrtPBb8us9HrsR2yth0SUbFt1xV6VsXXKll999Ni4ovzyRirUd5y0mOKl+uWUU59N/3wZplpBiXHWMaYjbTXx1hfxpiPN+mam0CgpIT0uEQUFRZKjOtIiy7feSeqyeQOOr777juZaffu3cOcOXPw5Zdfylt8nXPtdvHg8D5dXSEQCMRmsNLR1kBHd2dkZuXA+8F/U+td9XqKT+d7ol/3lvhxywmx8uwamsHJwQqh4fH1dhA5AGg7F3flSPd/CmFRkdhsL4U5OcgKDoJATQ1ajSTf5FpZOi5NEHfmNHKipL8fIjeq+MesmonkrCb1wYPXg8PbmhpCAIjNYKWprIzmRnrILijE0+TyDRbua22KFa2dkJCTi/lej2V2m0rLy8fpUOktHC2N9dFARxO3Y5OQmJOH4HraSnjnUfHx6eJmBYEAYjNYaWuqwK2pGbJy8vHweXyFyh094HXXqnOyZ9i5/SgaH41piW5tbLDtkPh4mwYWOrC30UdEbHq9HEQOABZNiwfhR/k9l7im5WfnID4gCMrqajBp3KjUckwa20FZTRXxAUHIz84Rm8FKWFSEKL/nxdtr5lQFe1E/6FqYQNvEEKnRcUiPTZCYwSrct7inh2Xzso+xipoqzJwbIdY/CDH+QbB6a52I12VZteD5khenga5+VdLBzd3dHZ6envjxxx+rovgaTUVFGU4OVhLT2L4KjcOFa49g19AMsyb3E0v77OP3oaOtgf1HbyIr+78fUjfuPIP/iwh07dAEg/q2ES0XCARYs7z4xVC//XmxCvem5lM3NYNOk6bIT0xE4rUrYmmxp0+gKDcXhu07QEn9vxmkcmKikRNT+dYhLcfG0LBpgKygl0h9+EAsLenmdeTGREPN1AyatnaV3lZtFJWVA++4ZFhpa2B4I/HWuukuDaGloox/I+KQU/jfm6cb6miKZr1604AGZljp5oS47FzMvSU74ACAuJw8fP/opdS/J0nFT8//CorE949eyj1rVm0XFpOOG/cj0cBCFxPeE2+RXjChNbQ1VXH8chCyc//r+mZvow97G9nvQ3FvZg7HhrIHkJfwfhyDl2EpaNfCAr3bNxAtFwiApVPdAQAHztTf8SC6FqawdG2CzPhEBJy/Lpb26PA/KMjNg33XdlDV+O+alhoZg9RI8UBbVUMD9l3boSA3D4/+Fh+X8Pzfa8iMT4RVyyZSp3ql8hEIBGjSr7g11XvfCQiL/ruWhfr4IdY/CAY2FrBs6ii2XkZ8ElIiY1CQK94a2KRfVwDA/YOnUZCXL1oe/zIUwV4PoKGnA7v2rapob4iqXpUNJHdwcMChQ4eqqvh3anA/dwzuX3wzNDc1AAC0b9MYO9bPAgAkJqVj+Zo/AQBWFoZ4dGU9QsPj4dJ5vlg5C1btwpWjX2HDV1PQs3MzPH8ZhbatHNGjczMEBkXhix/+EstfVCTEzMXbcPbgKuzfuhDHztxFeFQCenZujjYtHeDl8xwbfztTxXtf81mNHY/gdd8h+tBBZAY8h7qFJbJeBSMzMABqZuYwH+Iplv/Fl8VvlG+x9Vex5ZkvXyDpVvHLmUpeJpgXF4vwP3aJ8rw5E5VAIIDN5GkI3rAOYTu2QbeFa/HsVdFRyHj6BErq6rCZPLXcLxusi9b7BWFrV1csbOGANiYGCM3IQhMDXbQxNUBYRhZ+9Q8Vy/9nr+LguuvJm6JlrY318WmrxlAWCPAgIQUDG0p2lcvIL6iX3aQq4/Mtt3Fo/SB8PrsDOrWyRFB4Klo6m6JjS0sER6Riwx/igfT5HcMBAI4Dd0stb4xH8RPYsgaQFxUJsex/N7B37QBsWtET526FIDouEx1bWcLVyRT3nsZi97GnCtjD2qv9tNE49/l6+Px+GNFPAqBvbYGElyGIfRoIPUsztB49WCz/ycVfAwAmHtwitrz1mCGIffYC/v9cRnJIBIwd7ZAaGYOIe37Q0NdFu6mjJbYd5vMI4T7F74bKSS0O0uMDX+HWL3sAABq6OmgzcbjC97m2av5eL4Tdf4qQO744uSIRVs2dkZGQhFd3fKGiroaucyZI3AOubd6DmGcvMfCL+bB8o6XJvnMbhNx9hJA7vji+9Ds0bNMCuemZCPa6D2FREbrMGicxliclMgZ+xy6ILcvLzML1zf+91qDdJE9o6OlUwd4TVUyVBR1PnjyBqqpq2RlrAddmtpg4srvYMntbc9jbFv/4CQ2PFwUdpXkVGocu763AZ4tHom+PlujfszVi4pKxeedZrPnpCFJSJbt6+DwMQpfBq/DZx++jdzdX6GprICwyAWt+OoIft5xAXl7FBuHWReqmZnD4dBXiTp9A+tOnSH/yGCr6+jDu2RvmgwZDWbt8Uwrnxcch5c5tsWUF6eliy96e/lbTxgaNV6xC7D+nkOH/DOlPnkBFRwcG7drDzOM9qFtIH8NTX0Rl5eCDaw8x3cUW7c0M0cHcEIk5eTgUFIndgWHIeD1tbmkstNSh/LpZ/D1b6cczOiuHQUcFhcWkw3PBKSyY2Brd2liju7sN4pOzsfv4U2za/7BCg8j1dNQwoLNdqQPI3/QoIAHDF5zCggmt0aW1NXS0VBEZl4FNf/pi2+HHyCsoKrOMukzXwhQD1yzDo8OnEfXoGaJ8n0LTUA8uHj3hOmIg1HXKN/hbXVcHA77+BH5/n0H4vUeIex4EdV1tOPTogJYj34O2seQEF8khEQi+fldsWUZcAjLiit9crm1ixKDjDcqqqvD4bC4eHTuP4Fv38eSfK1DT1IBt25ZwGzUQhg3K/5JkgUCAngun4NnZRgi8fBvPzl6DspoKLJo6otWIATB3luwmnJ2ShhfXxM9XQW6e2LLWowYy6ABnr6oJBMK3X49dTj4+PlKXp6amwsvLCwcPHoSHhwfWr19fqQoCgGbDsZUug6rOoN9nV3cVSIbYDF5ka6robS+quwpUiilrGpSdiaqFmrJcP1voHVjq2re6qyBTw5bfVHcVZAp7tKq6q/BOyN3SMXHiRKmDckpimC5dumDlypXy14yIiIiIiOoEuYOOb7/9ViLoEAgE0NfXh52dHRo1Kn1mDSIiIiKid0FQNXMnUQXIHXQMH84+nUREREREVDa5w77ly5fj0aNHMtP9/PywfPlyeYsnIiIiIqI6Qu6g49ixYwgLC5OZHhERgePHj8tbPBERERGRQggESjX2r76osj3NysqCikqVzchLRERERES1RIWigqioKERGRor+HRwcLHXq3NTUVBw4cAC2traVryEREREREdVqFQo6jh49is2bN0MgEEAgEGDbtm3Ytm2bRD6hUAglJSV8++23CqsoEREREZE86lM3ppqqQkFHnz59YG1tDaFQiBUrVmDUqFFo3bq1WB6BQAAtLS20aNEClpblfxMnERERERHVTRUKOlxcXODi4gKg+I3kI0aMQMuWLaukYkREREREVDfIPdJ77dq1iqwHEREREVGV4MsBq1+lp5cqLCzEq1evkJKSAqFQKJHetm3bym6CiIiIiIhqsUoFHTt37sT27duRnp4uM4+/v39lNkFERERERLWc3G1NR48exbp16+Dk5ISFCxdCKBRi8uTJmDZtGvT09NCiRQvOXkVERERERPIHHfv370eLFi2wb98+jBo1CgDQvXt3LFmyBCdPniz1beVERERERO+MQKnm/tUTcu9pUFAQPDw8ABRPkwsARUVFAABzc3OMHj0ae/bsUUAViYiIiIioNqtUeKWrqwsA0NTUBFD8JvISNjY2ePXqVWWKJyIiIiKiOkDuoMPc3ByRkZEAAHV1dZiamuLJkyei9JcvX0JHR6fyNSQiIiIiqgSBQKnG/tUXcs9e5ebmBi8vLyxcuBAA0Lt3b+zduxdaWlooKirCgQMH0LdvX0XVk4iIiIiIaim5g44xY8bg4sWLyMnJgYaGBhYsWAA/Pz9s3rwZANC4cWMsWbJEYRUlIiIiIqLaSe6gw9XVFa6urqJ/Gxoa4ujRowgICICysjLs7e2hpFR/moyIiIiIqGYqmfSIqk+l30j+NmdnZ0UXSUREREREtVilg4579+7hxo0bSExMxNSpU+Hg4IDMzEw8e/YMzs7O0NPTU0Q9iYiIiIjoLefPn8dvv/2GwMBAqKqqok2bNvj444/h5ORUrvWfP3+O7du349GjR4iPj4exsTGaNWuG6dOnw83NTWH1lLv/U1FRERYvXoyJEydi+/btOHLkCOLi4gAAKioqmDNnDg4cOKCwihIRERERyUMApRr7VxmHDx/GvHnzkJ2djU8++QSzZs1CQEAAxowZg4CAgDLX9/Pzw8iRI3Hv3j14enpi9erV8PT0xMOHDzF+/HjcvHmzUvV7k9wtHTt37sSZM2ewbNkydOvWDQMHDhSlqauro0+fPrh69SpmzpypkIoSEREREVGx1NRUfPfdd7CwsMCBAwdEr6rw8PDAoEGDsGbNmjJf1L1nzx7k5eVh586dYi0jffr0wfDhw3Ho0CF06dJFIfWVO7w6duwYhg4diilTpsDQ0FAi3cHBAeHh4ZWqHBERERERSbp06RIyMjIwcuRIsXfjWVlZoX///rh79y6io6NLLSMjIwMAYGZmJrbc3NwcwH8vAFcEuYOO8PDwUvt56evri72hnIiIiIioOlT3CwCr4uWAjx49AgC0bt1aIq1k2ePHj0sto6QVY/HixXj06BFiY2Ph6+uLTz75BPr6+pg2bZrc9Xub3N2rNDU1kZaWJjM9IiIC+vr68hZPRERERFTn9e7du9T0S5cuSV0eGxsLALCwsJBIK1kWExNTatljx45FbGws9u3bh1GjRomWOzk54dChQ7Czsyt1/YqQO7xydXXF2bNnpaZlZWXh2LFjcHd3l7tiREREREQkXXZ2NgBATU1NIq1kWU5OTqllKCkpwdzcHC4uLli6dCl++eUXLF26FImJiZgxYwYiIyMVVl+5WzpmzJiBqVOnYv78+RgxYgQAIDo6GhcvXsSmTZuQlJSk0CYZIiIiIiK51OCXA8pqyShLyXiLvLw8ibSSZRoaGqWWsX79euzevRvHjh0TG0jepUsXDB8+HD/88AN+/vlnuer3NrmDjg4dOuDrr7/G119/jQsXLgAAVq5cCaA4uvrmm2/E3lhORERERESKUTLYOyYmBg4ODmJpJd2qpHW9KpGfn4/ff/8d9vb2Eu/0cHZ2hr29Pe7evauw+pY76Jg0aRJmz56Njh07AgCOHz+ODh064NKlSzh37hyCg4NRVFQEOzs7eHh4iA4EEREREREplqurKw4ePAhfX1907txZLO3hw4cAgBYtWshcPzk5Gfn5+SgsLJSaXlBQIDNNHuUe0+Ht7Y2EhATRv5cvXw5fX1+YmJhgwoQJWL16Nb744gtMmTKFAQcRERER1RxKNfhPTn369IG2tjYOHz4smvoWAKKionDu3Dm0a9cOlpaWAIrHfwQFBYle5A0AJiYmMDQ0xKtXr0RBSglfX1+EhIQotNdSuXfV1NQUERERon8LhUKFVYKIiIiIiMpPX18fS5cuRUxMDMaOHYt9+/Zh165dmDBhAoD/hj0AxW8eHzhwIDZs2CBapqSkhHnz5qGoqAhTp07F999/j7/++gvff/89pk2bBlVVVSxYsEBh9S1396qOHTti69atePLkCfT09AAAhw4dgpeXl8x1BAIBvv3228rXkoiIiIiIxIwZMwYGBgbYuXMn1q1bB1VVVbi7u2PhwoVwcXEpc/3x48fD3Nwce/fuxd9//43MzEwYGBiga9eumDNnTrnKKC+BsJxNFsnJyfjuu+/g5eUl6mZV1qoCgQD+/v6VrqRmw7GVLoOqzqDfZ1d3FUiG2IxKtNtSlYre9qK6q0ClmLKmQXVXgWRQU2ZPi5pqqWvf6q6CTE4dt1Z3FWQKvF0/fkeVu6XD0NAQ33//vejfLi4uWLduHQYPHlwlFSMiIiIiorpB7segnp6eaNiwoSLrQkREREREdZDc7+lYu3atIutBRERERFQ1avDLAesLdvgmIiIiIqIqxaCDiIiIiIiqlNzdq4iIiIiIagU+Zq92PAVERERERFSlGHQQEREREVGVYvcqIiIiIqrThJy9qtqxpYOIiIiIiKoUgw4iIiIiIqpS7F5FRERERHUbe1dVO7Z0EBERERFRlWLQQUREREREVYrdq4iIiIioblNi/6rqxpYOIiIiIiKqUgw6iIiIiIioSrF7FRERERHVbXw5YLVjSwcREREREVUpBh1ERERERFSl2L2KiIiIiOo29q6qdmzpICIiIiKiKlUrWjoG/T67uqtApfhnytbqrgLJoKtlVd1VIBnabxpW3VWgUuy9L6zuKpAMj6dpVXcViEgOtSLoICIiIiKSG18OWO3YvYqIiIiIiKoUgw4iIiIiIqpS7F5FRERERHUbXw5Y7djSQUREREREVYpBBxERERERVSl2ryIiIiKiuo29q6odWzqIiIiIiKhKMeggIiIiIqIqxe5VRERERFS38eWA1Y4tHUREREREVKUYdBARERERUZVi9yoiIiIiqtvYu6rasaWDiIiIiIiqFIMOIiIiIiKqUuxeRURERER1mlDA/lXVjS0dRERERERUpRh0EBERERFRlWL3KiIiIiKq2/hywGrHlg4iIiIiIqpSDDqIiIiIiKhKMeioYkd6d0f8Q98y8137eAGe/bH7HdSIqOaLD9iAvKzwMvOlhB1CZoLXO6gRvel0v25IeFT2dc3rk/kI2LPrHdSISgR+0B1ZAWWfm/B1C5Bwkvecd0lduS2uXb1fZr6+vWbi6y93vIMa1TOCGvxXT8gVdKSnp8PPzw+RkZEy8yQlJcHHx0fuitVWRQUF5UovK1958xDVBUJhYbnSy8pX3jxUMbyu1VzCMo5nSXpZ+cqbh8ovP7/041mSXla+8uYhqukqHHTs3LkTnTt3xujRo9GnTx9MnjxZavBx8+ZNTJo0SSGVrC1yU1JwbsIYBB76S+qNNcrrFs5PmYjYez64vnghHmz4EbmpqRL5Ul8F4zpbPqieKCrIQlLwTmQl3ZMaMORmBCHp1e/IywxFSvhhpMdcQFFhtkS+gtwEpIQdQlbC7XdR7XojNyUFlyeNRtDfB6Ve12Ju38TV6RMQf98Ht5csgN9P65CXJnldS3sVjNtLFiBwL69rilKQnoJXK8Yg6fxfUgOGjIe3ELJ6IjKf+SB8/ULE7v0RhRmS5yY3MhjhPy5A4imeG0WJj0+Gi+NQ/G/DPqkBw6mT19Ci6fu4eOEu+vWehTmzvkViYopEvqdPXqJf71ls+aA6oUJBx927d7Fu3TpoamqiT58+aNGiBe7evYsRI0bAz8+vqupYa6jp66PFzDl4dfokLn4wDXEPiptRMyIjcHP5Utz77lvYeQyEcbPmcJ39ETKiInF+8gQEnTwOFBUhPzMTj7ZswuXZM6FtaQX7wUOrd4eI3gGBsia0TbsjJ8UPySF7kZcZBgAozEtGasRRpEefg4Z+c6hqWkHHtAcK81OQFLwb2cmPAAghLMpDRtwVJIf+CWU1fWgYtKzeHapj1PT10fTDOQj75ySuz5qKBN/i61pmZATurlyChz98iwb9B8KwaXM0mzUXmVGRuDJ1PEJOHQeKilCQmYmnWzfi5twPoWVhCdtBQ6p3h+oQZR19mI6cg9RrJxH61TRk+Refm7zYCET8vBQxu76FXueB0HRoDrNRHyEvLhKvVk1AytXjgLAIRdmZiDu4CWHfzISqiRX0u/OeoygmJgb47ocF+G3HMbi3HofLl7wBAC9fhGHIoAWYPuULTJk6BB07uWLd+kUICgpHc5f3sX3r3ygqEiI1NQOLF61Hx3aT0aiRNT6YObya96gOEAhq7l89IRAKhcLyZv7www/x/PlzHD16FCYmJgCAy5cvY9myZRAIBNi1axeaN28OADh58iSWLVsGf3//Slfy/cvXK13Gu1RUWICQM//Af+8e5CQmQFldHQ5DPeE8djzU9PTE8sbe88GTnb8iJTAAEAhg3aUbmk2fAd0GDaup9hX3z5St1V0FkkFXy6q6q1BuQmERclIfIyvxDooKMgGBCjQNWkHLuC2UlDXF8uZlhiAz/hYKcmMBAGo6jaFt2hkqakbVUXW5tN80rLqrUCFFhQUIP/sPAv/8A7mJCVBSV4fdkOFwHC15XYu/543nu39F6ovi65pF525wmfoBdGrRdS0wtNy3xmonLCxA6o1/kPjPHhSmJECgpg6Dnp4w8hgPZW3xc5P51AcJx35FbmjxudFp3Q0mnjOgZlF7zs3jaVrVXYVyKygowK7fTmDtmp2IioqHpqY6Zn80CkuWTYaRkb5Y3gvn72D1ql/w4L4/BAIBhnn2xJffzIazs131VF4Oakru1V0FmRyH/FHdVZDp5cnJ1V2Fd6JCLR2BgYEYPXq0KOAAgF69euHAgQNQU1PD9OnT8fz5c4VXsrYRQACBkhIEb0SvAmVlqXNEF+d749/KSoCA4/upvnprVJ1A1ig7pbey1bPReNVAAAHw9nVNSQkCadc1ZWWxp3cCZSXOkV+VBK/PzZvfASVlqU9QBUpv3V+UeM+pSgKBAMrK4t8bZWUlKL19Hl4vf/OUycpHVFtV6NOcnJwMS0tLieWOjo7Ys2cPVFVVMXXqVAQGBiqsgrVN5PVrOD99Cl78fRhtln4KAGj50TykBL3EvxPGIfDQQRTm5SI5MBA3ln2Cu199Adv+HjBp4QrH4e9D3dAIFz+Yigc/rUd2YmL17gzRO5KbHojkkD+QnfwAuhb9AQA6Zj1QmBuPpOBdxeM9igqQnxOLlPAjSIs6DQ29ZlDVtIamoRuUlLWRHLIH6TEXUViQUc17U/dE37iKqx9Mxqujh9Dyk+UAgGaz5yMt+CUuTx6LoMMHUJiXi9QXAbi7fDHuf/M5GvTzgFFzVzQaVnxduz5zKh5vXI+cxITq3Zk6Jv3+NYR8PgUpFw/DfGrxPcd09Dzkhr/EqxXjkPTvQRTl5yInNBAR//sEUdu/gH5nD2g2doVB7/ehom+E0C+nInbfehSk8J6jSMeOXEarFqOx8ecD+HXXagDA+v8tht+jF2jS2BMb1u9FTk4ufB88x6AB8zB+zApMmjIYXbq2xtz5Y2BuYQz3VuMwd853iI7m96bSlAQ196+eqFDQYWZmhujoaKlp9vb2+P333yEQCDBlyhQEBQUppIK1SW5KCh5t2YRGAwehz6+7YN6muJlRx9oGXdb+gDZLliHo5HEk+Pnh0eafoWVujn5/7IPDUE9ASQmq2tpoNXc+ev2yHelhYQg6dqSa94io6hUVZCEj7io09FvA0G4i1LRtAQDKaobQtxkOXYt+yE55hPzsCGTEXoGyqh6M7KdC07AVAAEESmrQMe8JQ9vxKMxLQnbyw+rcnTonNyUFT7duQkOPQei2bTdM3Yqva9rWNmi/Zh1aLl6G0FPHkeT3CE+2/AxNMwv03P0n7IYUX9dUtLXRfM4CdNm0A+lhoQg5cbSa96juKEhPQfzBTdDvMgi2q3dBu2nxuVEzt4HNgh9gMWUZUq8eR3agH+IO/AxVY3M0+mYfDHp6AgIlKGlqw2zMfDRcuR150WFIucx7jqLExydj8aL1mDp9KO757kfvPu0BAI6NG+LkPz9j+2+fYfvWv3Hjui8WLViHhrYWePL8b8yaPRJKSgLo6+tgw0+fwOvu7wh4/gq/bP6rmveIqPJUKpLZxcUFN2/exEcffSQ13dHREb///jsmTZqEHTvq30wL6gYGGPDnQSipSD+sVp27wKJ9ByipqMC0VWuZ+fQb2aP7hp85tSTVC0oqWjCynw6BQFlqurquI9R0GkEgUIaqVgOZ+VTUTWDQcBSnzFUwdQMD9Nrzl8zrlUWnrjBr1xFKKiowbuUmM59eI3t0+nEjr2sKpKJrgEZrD0Ig45jrtOoC7eYdIFBRgZZza5n51K3t0WDJz5wyV4FMTQ0REHQCqqrSj/mQod3hMbAzVFVV0KOnu8x8zZo74sLl7Zwyl+qECrV0dOvWDb6+vqUODndycsLvv/8OvbcGFtYXsm64b6eXla+8eYjqAlmBxNvpZeUrbx6qGF7Xai5ZgcTb6WXlK28eKj9ZgcTb6WXlK28eKkNVvdhPEX/1RIVmr8rLy0NERASMjIxgYGBQat7o6GiEh4ejXbt2la1jrZu9qr7h7FU1V22avaq+qW2zV9U3tWn2qvqmNs1eVd/U6NmrPPdUdxVkenmsfrzXrkItHWpqarC3ty8z4AAAS0tLsYAjKysLmzdvRkRERIUrSUREREREtdc7m4stKysLW7ZsQXh4+LvaJBERERFR9b8AkC8HfHdBBwBUoCcXERERERHVEXzrDBERERERVSlOh0BEREREdVs96sZUU7Glg4iIiIiIqhSDDiIiIiIiqlLsXkVEREREdRsfs1e7d3oKBOxPR0RERERU73DKXCIiIiIiqlIK6V6Vl5eH5ORkGBoaQk1NTWoeExMTPH/+XBGbIyIiIiIqP/a2qXaVaunw9/fH5MmT4ebmhh49euD+/fsAgMTEREyePBleXl4KqSQREREREdVecgcdAQEBGDduHEJDQzF06FCxNGNjY+Tk5OD48eOVrR8REREREdVycnev2rhxI0xMTHDs2DHk5eXhyJEjYukdOnTAuXPnKl1BIiIiIqJKYe+qaid3S8e9e/cwcuRI6OjoSJ2VysrKCvHx8ZWqHBERERER1X5yBx1ZWVnQ19eXmZ6dnc3ZqoiIiIiISP7uVdbW1qXORnXv3j3Y2dnJWzwRERERkUIIldi/qrrJ3dLRv39/HD9+HI8fPxYtK+lmdfz4cVy6dAkeHh6VryEREREREdVqcrd0fPjhh7h8+TLGjRuHVq1aQSAQYMuWLVi7di0CAwPRtGlTTJkyRYFVJSIiIiKi2kjulg5tbW0cOHAAY8eOxcuXLyEUCuHj44Po6GiMHz8ef/zxh8wXBRIRERERvTMCQc39qyfkaukoLCxEbGwstLS0sGLFCqxYsQJJSUkQCoUwMjKSOpsVERERERHVT3K1dBQUFKB37944fPiwaJmRkRGMjY0ZcBARERERkRi5WjrU1dWhr68PbW1tRdenxspPTkLsqZNIf/YEhZmZUNHTh17LVjAfNBjK5TwO6f7PkPH0CbIjwpETEY7CzExoOTjC4ZNlZa6b+uA+km5eR3ZYGIpyc6CiqweNBg1g1t8DWvYOld29WstzYDt0bd8Urs1s0aJJQ+jpauHA0ZuYtnBLhcuytjDCZ4tHol+PljAy0EFMXApOnb+HNT8dQUpqptR1XBpbY9Wi99G1QxPo6WgiLDIBh0/dxo9bTiAnN7+yu1cnWJrrY9n8AejV1RmGBtqIjU/D2YtP8OOW80hNyy53Oe/1a4HpE7qgRRNrqKqqIDQ8EX+fuo+tu68hP79QLK+KihKmju2M5k2s0KKJNZwczKGmpoJFqw7hz7/vKnoXay1jdTWMd7CFm4kh9FRVkZSbhztxiTgQHIbMgoJyldHKyABuJoaw19FBI11t6Kmp4llyKpbd85O5jhKArham8LCxhJWWJrRUlJGQkwv/lDQcC41EWGaWgvawdjPXUsOCNnboamMIAw1VxGXl4VJoAjY/CENaXvnOz/QWNmhvZQAHAy0YaqhCKBQiMiMXXpHJ2P04ArFZeTLX7W9ngpEuFmhuogstFWUk5uTBPzED2x+G41F8uqJ2s9bLycnDzl9P4tyZO4iKSoCOjibc2zXBR3NHwN7BWu5yk5PTMXzIp0hISEFrNyfs+fNziTxCoRBHDl/B0SNX8fJlBCAEGtlbYcT7PfD+qF5QUpK7F33dw2fi1U7ugeQdO3bEnTt3MG7cOEXWp0bKjY9D8LrvUJCeDr2WraBuboGskFdIvHIJGc+ewv6TZVDR0SmznKRrV5D26CEEqqpQMzVDYab0H7JvEhYWIvyPXUj18YaamRn027hDWVMTBWlpyHoVhOywsHoddCyb54mWzeyQnpGNyOgk6OlqyVVOI1szXDn6FcxN9XHqXx8EBEXBvaUj5k73QN/urug1/AskpWSIrdO2lQPOHlwFVRUVHDtzFxHRiejRqRlWLhyBnp2bwWPsGuSV84dBXWXXwBj/HJgHUxNdnL34BC+C49DatQFmTu6GXl1d8N64TUhOKfsH5opFHlg4sw8yMnNw+vxjpKRmoX2bRlj18SB069AYYz78FQUFRaL8WppqWLNyGAAgLj4NcQnpsLEyrKrdrJUsNDXwQ9uWMFRXw524BERkZqOxvi6G2lqjjYkhlvo8Qnp+2Z/fQQ0s0cHMBLmFhYjOyoGemmqZ63zSwgVdLUwRn5OL23EJyCoohJ2uNnpZmaO7pRm+ePAEfsmpitjNWquBrgYODmkFE001XAxJQHBqFlxN9TC5uQ262hhh7KmHSMkt+/yMdrFEVkEhfKJTkZiTBxWBAE1MdDC1hQ3ed7bAxH8ewT9R/F6kLAC+7+6CwY5meJWahTPB8UjPK4CpphpameuhmYkOg47X8vLy8eH0tfB9EIhmze0xfmJ/xMQk4sK/3rhx7SF+270Cri0d5Sr7q893Iisrp9Q8ny79BWdOe8HIWA8DB3aEhqY6bns9xtdf7sZD3xf49vvZcm2bqCrIHXQsWbIE48ePx//+9z/MmDEDurq6iqxXjRJ14E8UpKfDctQYmPTs/d/yv/9C4qWLiD15DNbjJpZZjkm/ATAfMgzqFpbIT05CwKrlZa4Te/okUn28YTpgIMwHD4XgracWwsL6/aN26Vd7ERmdhKCQGHTt0ATnD62Wq5yfv5kGc1N9fLz6d2z9/V/R8u8/m4D5HwzCF0tHY/6KnaLlSkoCbF8/C9paGnh/+o/458J9AMXTRv+5dQE8B7bH/BkD8eMvJyu3g7Xc95+PgKmJLpZ/cww7990ULf/q0yGYNaU7Viz0wJIvjpRaRoum1lg4sw9SUrPQd8T/EBqRJEr74fMRmDK2E2ZM6IJtv18XLc/OyceYD37Fk+eRiItPx5K5/bBkbn/F72AtNtvFEYbqatj+PAinw6NEy6c7NcIwWxtMdLTDL/4vyyzn75AI7H0ZiojMLJhoqGNn13al5m+sp4OuFqYIzcjE4rsPkVv0X7DY28ocC5s5YZR9Q/jdf1xKKXXf550dYaKphq+9XmLfs//Oz6ft7TG1hQ0Wudvh81tln5/3jt5DXqHki3pHOlvgm65OWOTeCB/++0QsbV4bOwx2NMNW3zD8fD8Eb6+twm7UInt+PwPfB4Ho278dftwwT9SycNnjHhbM/R9Wr9yBoye/q3CLw8njN3Dxgg9WrZ6Kb77aLTXPpQs+OHPaC9Y2pjhw6GsYGhb/DsvPK8CiBT/h1Mmb6NXbHX36ta3cThIpiNztbhMnTkROTg527NiBdu3aoXPnzujdu7fYX58+fRRZ12qRGx+HDP9nUDU2hnH3nmJp5u8NhZK6OpLv3kFRbm6ZZWnbO0DDyloicJAlPzUVCRfPQ7ORPSyGekpdT6Asd9xYJ1y//QxBITGVKqORrRn6dm+JkLA4bPvjvFja1xv+RkZmDsYN7wItTXXR8q4dmqJJYxvcuOMvCjiA4qbuFd/uBwDMGF/7P/+VYdfAGD27OCM0IhG7/rwllvb9pn+RmZmL94e0gZZm6bPcDezdHADw5993xQIOAFjzvzMAgGnjOostz88vxOUbzxHHp7FSWWhqwM3EELHZOfjnjYADAPYHhSG7oBA9Lc2gXo5rVUBqOsIys1BUZs5i5poaAIBHSSliAQcA3I1LBADoq5bdWlKXNdDVQFcbI0Sk5+DPZ+LnZ9ODUGTmF2KIozk0Vco+P9ICDgA4GxwPALDV0xRbbqKpiuktbOAbm4afpAQcAFAglF5mfSMUCnHo4CUAwMefjBULLHr1dodbG2cEBUXino9/hcqNjkrAd9/uwfARPdClW0uZ+S5dvAcAmDxloCjgAABVNRXMnf8+AODA/vNS162XlAQ196+ekDvosLKygqOjI9zd3eHu7g57e3tYWVmJ/VlaWiqyrtUiMyAAAKDbpJnEj35lDQ1o2TtAmJeHrFfBCt92qu99CAsKYODeFkV5eUh9cB9x/55F4tUryI4IV/j26qvuHZsBAC7e8IPwrZtpRmYObt8LgLaWBtq5/ddE3qNT8Trnrz2SKC8kLA6BQVGwbWCKRrZmVVjzmq1z++Ljde1WoMRxzczMhbdvCLS11NGmpW2p5ZiaFt9MQ8MTJdJS07KRnJIFu4YmaGhtpKCa132uRvoAAN/EZIkfldmFhfBPSYOGsjKcDfQUvu2wjOLudK6GBlB765ra1rT4HD5KSlH4dmuT9lYGAICbEZLnJzO/EA9iU6GlqoyWZvKfn162xgCAgCTxbqP9G5lCTVkJZ4LjoK6shP52JvjAtQHGNbGEs1H9GcdZHuFhsYiOToSdnSVsbCSv9V1fBwx37zwrd5lCoRCrVmyHjo4mlnw6vtS8CQkpAACbBpLbLln24H4A8ut5N1+qOeR+TL53715F1qPGyo0tfoquZm4uNV3NzBzwf4bc2FjouDRR6LazQ0IAAEV5eQj88jPkJ4k/5dVr7YYGU6ZBSU1dytpUXk72xcHxy2DpLSZBr2LQt3tLNG5kiau3nhav41CyTrTUdV6GxMDJwQqNG1niVWhcFdS65nNsZAoACAqJl5oeHBqPnl2c4WBnght3XsgsJym5uL95QxtjiTQ9XQ0YGhSP43FoZIqwyCSJPCTJWqv4mEVmSR/IH5WVDTcYwlpLE34KDgDCMrNwPDQCw2xtsLVTG/gkJCG7oBANdbTgZmyIazFx2PsyRKHbrG3s9YtbH0LSpI93Ck3NRlcboJG+Ju5EpZSrzPedLWChrQ4tFSU4GWmjk5UhItJzsN7nlVi+FibFQb6GijLOvu8Oa10NsfRzr+Kx7GoAcgrL27ZVd4W8Kr7+29pZSE1vaFu8PDRE+n1Cmr1/nIOPtz+2//YpdHS0kCpjEhMAMHjduhEZIXmNjQgvvu8UFBQiPCIO9vZW5a4DUVWp331zyqEwp/imrKyhKTVdWbN4eWG24mdbKUgv7hoSe+oEtB0cYTvrI6ibmSMnKhJRf+1Hmu8DRKqro8HkaQrfdn2ip1f8Ayw1Xfo5LFmur//fU76SAeuy1kl7/WPBQK/+PhnUff1jJS1d+kDIkuV6etK/WyUuXvXHwpl9MGFke+w+cAvhkcmitBULB4r+30BfvkkE6iMtFWUAQJaMGapKlmu/zqdoOwNfITIzGzOc7TGowX8/hl6kpeNyVJxEt6v6Rket+NacnlcoNT399Wxtumrlv4WPdLZAqzdaRvzi0rD46nOEpYl/P401i7u2LWhjhwexqfjo4lOEpGajsaE2VndyxIBGpsjKL8Ty64EV2qe6KP11q52OjAlMdHSKl6fLuE+8LehlBDb+9BdGje6Njp2al5m/W/fWOPvPbez54yw8BnaEvkHxhDb5+QXYsvm/sXJppQQu9QrHIlU7Bh01mbD4xquspQ3b2XNFAY5WI3vYzp6LwM9XIeXuHVgM9YSqAWfmobrJ2zcE+w7fxYSR7XH1xCc4fd7v9exV9mjqbInAoFg4OZijqIj9zGuLD53tMdDGCvuCQnAlOg6ZBQWw19XBDCd7fOnWHFv9X+JMRPmfDlPZRp98CAAwUFdBUxMdLGpjh6PD3LDwkj9uvhHIl/wuS83Nx6zzT5H5OsDxi0/H7PNP8e9Idwx1NMf/7oUgrpTpduuKXzZLTnQx1LMbrK1NFbqd/PwCLF+2FSamBvj4k7HlWsdjYEecPnkTt276YejgpejZqw3U1VVxx+sJ4hNSYGlpjOjoRCjVozED9dX58+fx22+/ITAwEKqqqmjTpg0+/vhjODk5lbuMp0+fYvv27bh//z5SU1NhaGiIZs2aYdWqVbCxsVFIPeUOOlxcXMp8EaBAIMCzZ+Xvy1gTlbRwlLR4vK0w+3VLiKbin7Iqv+4CoePiIgo4SqjqG0DTzh6ZAf7IDg1l0FEJJa0S+jKeVpUsf7OZOy299HVKWk9S0urvE6b0kpaMt7pnlChZnlaOd3V8/Nkh+D4Ow4SR7TFkQEtACNx/FArPSb9g0ey+cHIwR0ISB42XV1ZB8Q9JLRXpt4CS5ZkF0p+0V0ZvSzMMbmiN46ER+DskQrT8WUoavnr4FL91aYvJje1wOTq23nbhyXjdB19XTXpLk65q8fJ0Ofrqp+QWwCsyBY/jH+Ps+23xQw9n9DzojdzXx7qkzNtRKaKAo0R8dh4exaejk7UhWpjo4lKY5DirumbrlqMSy9q2awJra1Povm7JyJDRkpHxuiVEtxxTuf+24ySe+4di5+8roaUt/Zr5NmVlJWz6ZTH2/H4Wp0/dxMnjN6Curgr3dk2wYeNCLF7wMwDAyFjxY7Oo5jh8+DBWrVoFJycnfPLJJ8jNzcW+ffswZswYHDhwAM7OzmWWcfr0aSxduhQuLi6YPHkyjIyMkJSUhMePHyM1NbX6g45hw4ZJBB0FBQUIDw/Ho0eP4OzsjCZNFDvGoTqomxf3ycyLjZWanhcX+zqf9DEfiti2rIBGWbt4eVFe3X/aVJUCX4/LcLSX3i/XoVHx8hev/nvyGhhUso70yRIc7STXqW9eviruZ+xgJ/2JoL1tyZiPhHKVt/fQHew9dEdieZPGFigsLILf00g5a1r/RGYV/xiy1pLetc3q9XJZYz4qo61p8dgcvyTJ93Ck5OUjIjMbDno6sNbSQlB6hkSe+iA4tfi42+lJv/bbvh7z8SpV/vOTnleIh3Fp6GtngsaGWniSUHysX6Vkv06XHtCkvX43iHo5Zs6qCx77/ykzza5R8fU/VMYMimGhxctt7cqeVMffPwRCoRDTJn8jNd33QSBaNBkPXV0teHn/KlquqqqC6R8MxvQPBovlz83NQ2hoDAwNdaUOcq+X6mCDT2pqKr777jtYWFjgwIED0Hn9zjgPDw8MGjQIa9aswZ49e0ot49WrV1ixYgXee+89fPddxad3rgi5g47vvvtOZtq9e/cwZ84cfPnll/IWX2Nov44Q0/2fQlhUJDaDVWFODrKCgyBQU4NWI3uFb1vHpQnizpxGTpT0H1O5UcVTKaqZmCh82/XJtdvFg8P7dHWFQCAQm2lJR1sDHd2dkZmVA+8H/82Jf9XrKT6d74l+3Vvixy0nxMqza2gGJwcrhIbH19tB5ABw627x8ere2UniuGprq6NdaztkZuXi/qNQubfRqZ0DGlgb4dzlp0jPKP0lWvSfkh/8rY0NIQDEZkjSVFZGEwM95BQWIiAlTeHbVn3d1UNfxksES14uWCCsn60cAHD39eDwLjaS50dbVRlu5vrIyi/Eo7jKnR9zreLpqgve6JroFZWCj9xs0dhQ+ng0R8PiQChCxlit+qRBQ3NYWhojJCQaERFxEj/ub1wvnt2wfYemZZbVsWNzGBpIvu8sKysH587egbGJPrp3bw2NMqYYL3H2zG3k5xfAY1DHcuWn2unSpUvIyMjA1KlTRQEHUDzDbP/+/XHs2DFER0eXOpvszp07UVhYiE8//RRKSkrIzs6GsrIy1NTK91mriCoJZ9zd3eHp6Ykff/yxKop/p9RNzaDTpCnyExOReO2KWFrs6RMoys2FYfsOUFL/bwapnJho5MRU/gm3lmNjaNg0QFbQS6Q+fCCWlnTzOnJjoqFmagZNW7tKb6s+UFFRhpODlcQ0tq9C43Dh2iPYNTTDrMn9xNI++/h96GhrYP/Rm8jK/u9dLDfuPIP/iwh07dAEg/q2ES0XCARYs7y4P+5vf16swr2p+ULCE3HlZgBsbYwxbbz4ezSWzesPbW11/H3yPrKy/2upc2xkBsdGkk/ldLQlZ2izsTLE/74ehdy8Anz301nF70AdFpOdgwcJyTDX1BAbyA0A4xwaQlNFGVeixQd022hpwkZGy0hFPE0u/qE8zNZaNKC9xAAbC5hqqCMpNw/hGYqfnKO2CE/PwY2IJNjoamB8U/HzM8/NFtqqyjj5MhbZBf+dH3t9TdGsVyUstdVFA8PfNtrFEq5meojKyEFg8n/dQO/FpOJZQgbcLfTRx1Z8xriRzhZwNNRGSGo2niSwO6NAIMCoMcUvDN7w4wEUvfF9uXzpHh7cD4CDgzXc24r3+oiOSkBwcBSy37injB3fD19+84HE38LFYwAADRua48tvPsDylZPFysqQ8j157h+CDesOQE9fG9M/GKKw/aWa59Gj4sC2devWEmklyx4/Lv1Fq1evXoW9vT0ePXqEgQMHolWrVmjZsiVGjx6Nu3fvKrS+VTaQ3MHBAYcOHaqq4t8pq7HjEbzuO0QfOojMgOdQt7BE1qtgZAYGQM3MHOZDPMXyv/iy+K3YLbb+KrY88+ULJN26AQCilwnmxcUi/I9dojxvzkQlEAhgM3kagjesQ9iObdBt4Vo8e1V0FDKePoGSujpsJk8t98sG66LB/dwxuL87AMDc1AAA0L5NY+xYPwsAkJiUjuVripvHrSwM8ejKeoSGx8Ol83yxchas2oUrR7/Chq+moGfnZnj+MgptWzmiR+dmCAyKwhc//CWWv6hIiJmLt+HswVXYv3Uhjp25i/CoBPTs3BxtWjrAy+c5Nv52por3vuZb9uUR/HNgHtau8kS3Do0RGBwLN9eG6NqhMV6+isO3bwULXmeXAQDMXBaLLf9pzWjYWBni8bMIJKdmoaGNMfr3bApVFWV8tOwAngVKBvnzPuiFxvbFAUxzl+IfbmOHt0X7No0AAHfvv8Kffyv2glqbbH3+Ej+0bYmZLg5oaaSP8MxsOOnroqWRASIysySmrd3aufh7NvjCDbHlTQ300M+6uDuhhnJxEGGppYmFzf4bwPjT0/9mOjoTEYUelqZopKuDbZ3c4R2fiMyCQjjo6qClsQEKi4TY9vxluV82WFd9eeslDg5phc86OaKjlQGCUrLQ0kwPHawM8ColC/+7FyKW/+zI4rdOO/92XbSsqYkOfu7dBA9j0xGWlo2E7DwYaKiilZkunI10kJlXgKVXA/D2HAyfXg/A3kGu2NSnKa6EJSIkNRuOhtro3sAImfmF+PSa5Dr11aQpA3Htqi8u/OuNcaM/R/sOzRAdnYAL/3pDU1MdX635UKK7yopPt+Gejz92/bESbduV3QpSmg+nfwd1dTU4NraBtrYGgoOjcOPaQ6irq2LTL5/AzIzjPUVq8ID63r17l5p+6dIlqctjX3f9t7CQ7B5esiwmRvYLlNPT0xEfH4/8/HzMnTsXo0ePxqJFixASEoJt27Zh2rRp2L17N9q1a1feXSlVlQUdT548gWodeausuqkZHD5dhbjTJ5D+9CnSnzyGir4+jHv2hvmgwVDWLt+0qHnxcUi5c1tsWUF6utiyt6e/1bSxQeMVqxD7zylk+D9D+pMnUNHRgUG79jDzeA/qUj5o9YlrM1tMHNldbJm9rTnsbYvH2ISGx4uCjtK8Co1Dl/dW4LPFI9G3R0v079kaMXHJ2LzzLNb8dAQpUqYc9HkYhC6DV+Gzj99H726u0NXWQFhkAtb8dAQ/bjmBPL6QCSHhiej7/k9YNr8/enVxQe9uLoiNT8P2P67jxy3nkVqOQeQAcOHqM0wc1QGDB7SEjpY64hMzcPq8HzbuuIwXwdK7sPXq6ozO7RzFlrVza4R2bo1E/67PQUdMdg4+vuuL8Q62cDMxQhsTIyTn5uFEaCQOBIchU8Z0um+z1NRAbyvxMW2G6mpiy94MOnIKi7DU5xGG2dqgo5kxuluaQUUgQGp+Pm7GxONoaARepNXPsRxvCk/PwYjjvpjfxhZdbQzRrYER4rPy8MeTCGx+EIa0clxfniVkYM+TSLhb6KN7QyPoq6sgr6AI4ek52OkXjj1PoxCTmSuxXkBSJoYf88VHbg3Rxbp428k5+Tj5Mha/+IZVaixJXaOmpoodO5dj56+ncPYfL+z94yx0dDTRs3cbfDR3BBwcFTMAV5a+/drh7Jnb+OfULeTk5MHM3BAjRvbEjA+HwMJC8t1GVLdkv57MSFpXqJJlOTmyu0JmZhb/tklJScHMmTPx8ccfi9KaN2+OKVOmYMOGDTh48KBC6isQvv2q4HLy8fGRujw1NRVeXl44ePAgPDw8sH79+kpVEADev3y97ExUbf6ZsrW6q0Ay6GrxhVA1VftNw6q7ClSKwFA+yq+pHk/jO3lqKjUl9+qugkwOU2tu75ug3aPkWm/WrFm4cuUKzpw5AwcHB7G0a9eu4cMPP8TKlSsxadIkqesnJyejQ4cOAIB///0XdnZ2Yuk9e/ZETEwMHjx4AE3NynevlbulY+LEiVKnzC2JYbp06YKVK1fKXzMiIiIiIkWowd2r5GX+eubUmJgYiaCjpFuVtK5XJQwMDKClpYWsrCyYmkrONGlqaoqoqCikpaVVb9Dx7bffSgQdAoEA+vr6sLOzQ6NGjWSsSUREREREleHq6oqDBw/C19cXnTuLT9jy8OFDAECLFi1kri8QCNCiRQvcvXtXauASHR0NFRUVGBgYKKS+cgcdw4cPV0gFiIiIiIioYvr06YM1a9bg8OHDmDJlimja3KioKJw7dw7t2rUTTZebnZ2NqKgo6Orqwszsv1kiPT09cffuXfz5559YvXq1aPnFixcRFxeHrl27Ql1dcgZJecg97dHy5ctFU3VJ4+fnh+XLl8tbPBERERGRQggFNfdPXvr6+li6dCliYmIwduxY7Nu3D7t27cKECRMAQGyYg5+fHwYOHIgNGzaIlTF06FB07twZf/75JxYsWID9+/fj+++/x6JFi6Crq4tPP/1U/gq+Re6g49ixYwgLC5OZHhERgePHj8tbPBERERERlWLMmDH4+eefoaGhgXXr1uGXX36Bk5MTDhw4ABcXlzLXV1JSwtatWzFv3jz4+/vj22+/xdGjR9GnTx8cPnwYjo6OZZZRXlU2ZW5WVhZUVKqseCIiIiKiem/AgAEYMGBAqXnat2+PgIAAqWnq6uqYO3cu5s6dWxXVE6lQVBAVFYXIyEjRv4ODg6VOnZuamooDBw7A1ta28jUkIiIiIqqMOjh7VW1ToaDj6NGj2Lx5MwQCAQQCAbZt24Zt27ZJ5BMKhVBSUsK3336rsIoSEREREVHtVKGgo0+fPrC2toZQKMSKFSswatQotG7dWiyPQCCAlpYWWrRoIRoxT0RERERE9VeFgg4XFxfRoBQfHx+MGDECLVu2rJKKEREREREphJQXWtO7JfdI77Vr1yqyHkREREREVEdVenqpwsJCvHr1CikpKRAKhRLpbdu2rewmiIiIiIioFqtU0LFz505s374d6enpMvP4+/tXZhNERERERJXD2auqndwvBzx69CjWrVsHJycnLFy4EEKhEJMnT8a0adOgp6eHFi1acPYqIiIiIiKSP+jYv38/WrRogX379mHUqFEAgO7du2PJkiU4efJkqW8rJyIiIiKi+kPuoCMoKAgeHh4AiqfJBYCioiIAgLm5OUaPHo09e/YooIpERERERJWgVIP/6olK7aquri4AQFNTE0Dxm8hL2NjY4NWrV5UpnoiIiIiI6gC5gw5zc3NERkYCANTV1WFqaoonT56I0l++fAkdHZ3K15CIiIiIiGo1uWevcnNzg5eXFxYuXAgA6N27N/bu3QstLS0UFRXhwIED6Nu3r6LqSUREREQkH74csNrJHXSMGTMGFy9eRE5ODjQ0NLBgwQL4+flh8+bNAIDGjRtjyZIlCqsoERERERHVTnIHHa6urnB1dRX929DQEEePHkVAQACUlZVhb28PJaV6NDqGiIiIiIikqvQbyd/m7Oys6CKJiIiIiOTHlwNWu0oHHffu3cONGzeQmJiIqVOnwsHBAZmZmXj27BmcnZ2hp6eniHoSEREREVEtJXf/p6KiIixevBgTJ07E9u3bceTIEcTFxQEAVFRUMGfOHBw4cEBhFSUiIiIiotpJ7qBj586dOHPmDJYtW4YzZ85AKBSK0tTV1dGnTx9cvXpVEXUkIiIiIpKbUCCosX/1hdxBx7FjxzB06FBMmTIFhoaGEukODg4IDw+vVOWIiIiIiKj2kzvoCA8Ph5ubm8x0fX19sTeUExERERFR/ST3QHJNTU2kpaXJTI+IiIC+vr68xRMRERERKQbf4lDt5D4Frq6uOHv2rNS0rKwsHDt2DO7u7nJXjIiIiIiI6ga5g44ZM2bg2bNnmD9/Pvz8/AAA0dHRuHjxIsaOHYukpCRMmzZNYRUlIiIiIqLaSe7uVR06dMDXX3+Nr7/+GhcuXAAArFy5EgCgpqaGb775RuyN5URERERE1YIvB6x25Q46Jk2ahNmzZ6Njx44AgOPHj6NDhw64dOkSzp07h+DgYBQVFcHOzg4eHh4wNzevskoTEREREVHtUe6gw9vbGyNHjhT9e/ny5fjhhx8wePBgTJgwoUoqR0REREREtV+5gw5TU1NERESI/v3mywCJiIiIiGqsevQSvpqq3EFHx44dsXXrVjx58gR6enoAgEOHDsHLy0vmOgKBAN9++23la0lERERERLVWuYOO5cuXQyAQwMvLCwkJCRAIBPDx8YGPj4/MdRh0EBERERFRuYMOQ0NDfP/996J/u7i4YN26dRg8eHCVVIyIiIiISCE4e1W1k/s9HZ6enmjYsKEi60JERERERHWQ3O/pWLt2rSLrQUREREREdZTcQQcRERERUa3A3lXVTu7uVUREREREROXBoIOIiIiIiKoUu1cRERERUZ0m5OxV1Y4tHUREREREVKUYdBARERERUZVi9yoiIiIiqtvYvarasaWDiIiIiIiqFIMOIiIiIiKqUuxeRURERER1m4Ddq6obWzqIiIiIiKhKMeggIiIiIqIqxe5VRERERFS38TF7teMpICIiIiKiKsWgg4iIiIiIqhS7VxERERFR3cbZq6odWzqIiIiIiKhKMeggIiIiIqIqxe5VRERERFS3KbF7VXWrFUFHbAYbZGoyXS2r6q4CyZCeFVXdVSAZkjJ4A6zJVJSF1V0FkiG7ILG6q0AyqKlVdw2oJuOveSIiIiIiqlK1oqWDiIiIiEhu7F5V7djSQUREREREVYpBBxERERERVSl2ryIiIiKiOk3IlwNWO7Z0EBERERFRlWLQQUREREREVYrdq4iIiIiobuNj9mrHU0BERERERFWKQQcREREREVUpdq8iIiIiorqNs1dVO7Z0EBERERFRlWLQQUREREREVYrdq4iIiIioblNi96rqxpYOIiIiIiKqUgw6iIiIiIioSrF7FRERERHVbexeVe3Y0kFERERERFWKQQcREREREVUpdq8iIiIiorqNvauqHVs6iIiIiIioSjHoqGI3h3ZFymPfMvP5rZyH0AO73kGNqER8wAbkZYWXmS8l7BAyE7zeQY2Iagev4V2R+qTs69qTz+Yh7CCva+/Ss2ndkfm87HMT8v0CxB3f/Q5qRCUM1AfgxrVHZeYb1HcJ1n699x3UiOjdYtChYEUFBeVKLytfefNQ+QmFheVKLytfefMQ1RW8rtVcwjKOZ0l6WfnKm4fKLz+/9ONZkl5WvvLmodIJlQQ19q++kCvoiImJQWBgIAoL//vhFRERgc2bN+Pbb7/F2bNnFVbB2iQ/NRn3PhyNiOMHpd5YE+/exIOPxiP5oQ+erJqPl7+sQ35aqkS+zNBgPF45H2Fs+VCYooIsJAXvRFbSPakBQ25GEJJe/Y68zFCkhB9GeswFFBVmS+QryE1AStghZCXcfhfVJqp2+anJeDB7NCJPSL+uJXnfhO+88Uh56IOnq+cjaOs65KdLv649WT0f4X/xuqYoBWkpeLFsDBLP/SU1YEj3vYWXKyci46kPQn5YiKg/fkRBhuS5yYkIRsgPCxB/gi0fipIQn4JWLlOw6X9HpAYMZ07dRtsWH+DKxQcY3G8pFs75GUmJaRL5nj0NwXv9luK7r/e9i2oTVakKBR1FRUVYtmwZevbsiaFDh2LgwIEIDw/H06dPMXjwYGzevBl79uzBxx9/jJkzZ0IoFFZVvWskFT0DNJo6BzH/noDvgilIeXQPAJATHY6nXy1B4M9rYN57EPRcmqPR9HnIjo7A/TnjEH32GFAkRGFmBoJ/24iHiz+AhoUVLAcMreY9qjsEyprQNu2OnBQ/JIfsRV5mGACgMC8ZqRFHkR59Dhr6zaGqaQUd0x4ozE9BUvBuZCc/AiCEsCgPGXFXkBz6J5TV9KFh0LJ6d4joHVHRM4Dd5DmIPX8Cjz6eghS//65rz75Zghcbi69rui7NYTd1HnJiIuD70TjEnDsGCIUozMrAq50b4bf0A2iYW8GiP69riqKsqw/z0XOQfO0kgj6fhoxn9wEAebERCPvfUkT+9i0MugyElmNzWIz9CHlxkQhaPgFJV44DwiIUZWciZv8mvPpqJtRMrGDYk+dGUYxN9PH1dx/g99/OoIv7HFy7XNzlLfhlFEYO+Qyzpv+ICVP6oV3Hpvh23UwEB0WjTfPp2Ln9NIqKhEhLzcKni7ehZ8d5sGtkgakfDKrmPSKqPIGwApHB0aNHsWLFCnTr1g1WVlY4evQo2rZti/z8fDg5OWHYsGHIycnBnj17cOHCBXz11VcYOXJkpSvZ9eTNSpfxLgkLCxBz/jTCD/2BvKQEKKmpw3LQcNiMmABVXT2xvMm+3gjduwMZQQGAQADjDt1gO+FDaNk0rKbaV1zA0mPVXYVyEwqLkJP6GFmJd1BUkAkIVKBp0Apaxm2hpKwpljcvMwSZ8bdQkBsLAFDTaQxt085QUTOqjqrLJT0rqrqrQDK4/fxRdVehQoSFBYi9eBoRh/+7rlkMHA5rT8nrWspDb4T+uQOZr69rRu27wXb8h9C0rj3XtZSUouquQrkJCwuQfP0fJJzag4KUBAjU1GHUyxMmA8dDWUf83GQ88UHckV+RE1p8bnTdusFs+AyoW9aec+M1XrIVuqYqKCjEnl3nsG7tfkRHJUJTUx0fzB6MRUtGw9BIVyzv5Qv38dXq3/HwwQsIBAIMHtYZn305GY2dG1RT7StOX61/dVdBpob/u1rdVZApbFGP6q7CO1GhKXMPHTqETp06YceOHQAABwcHfPvtt+jbty9WrVolyufu7o4hQ4bg1KlTCgk6ah8BBMpKgOC/fnoCJSUIBJL99gRKb+dThqAe9e+rHgKIzZ0neOvfIkpvZZOVj6g+EBRfr/DWdU3a9Uoin7LYdY4UTCCQuJdASVn6G5iV3rquKSm9Pl9UFQQCQFlZ/P6vrCz9e1OcT/zfSjw3VIdU6NMcFhaGHj16iP7dtWtXCIVC9OrVSyLvgAEDEBgYWOkK1jYJXlfxYN4kRJ44BKf5KwAA9h/MR2ZIEO7NGoOIYwdQlJeLjKAAPPn8Yzxf9znMew+EXtOWsHrvfagaGsF3wRS83Poj8pISqnlv6pbc9EAkh/yB7OQH0LUofhqjY9YDhbnxSAreVTzeo6gA+TmxSAk/grSo09DQawZVTWtoGrpBSVkbySF7kB5zEYUFGdW8N0TvTuLtq/9n776jorjaMIA/S++9g3QpKmDBgt1YiTGW2Hv7UkyixkSNLc3YEk3VmGKJJWI0lhRLbDFqbNhABEER6b3DstT9/lhBV3YFlsWlPL9zOCfcO3PnDtfM7ju34db8qUj6cx/c35Y811xmSZ5rN94Yj8TDj59r4Z8sQNT6D2H1guS5Zjt0NLRMzRCyYDqif+BzTdnyrv2L6OXTkXliP+xmvg8AsJnwNorj7+P+4onIOL4XFaXFKIqNQuyG95C4+SOY9AyEnocvzAaMhoaxGR58MAPJOzegNCdTxXfTvPx+6AK6tX8N331zCN/9tAAAsHbD6wgLjUEH7xn49ovfIBKV4NbNexg1dCmmT1qNSVMHIaBnO7z+1ghYWZuih/8bWPDWt0hJZttQ01enoKOgoAAGBgZVvxsbGwMArK2tqx1rZWWFgoKW9cWsNDcbD7Z8A+uBL6HD1z/DpL0/AEDHthXafvA5Wr/9PpKPHULunRBE//gVtK1s0Om7PbB9cSSgJoC6vgHc/jcPfut/gjAhFklHDqj4jpqPijIhCtLOQsfYB6bOU6Cl7wQAUNcyhbHDKBjaDEJRTghKixJQkPoP1DWNYOY6A7qm7SF5w6sFA+t+MHWahPKSLBRl31Ll7RA9N6W52YjZ+g2s+r8Evy9+honf4+dam+Wfw/2t95Hy9yHkhYcgZstX0La0QYdNe2AbOBIQCKCuZwCXWfPgs+4nFCXEIvkon2vKUpaXg5Sgb2HSeyjcPt4Gg7aSttGydoDjO5/BbuZiZJ85DGFkKFJ++Rqa5tZwW7MbZi+MBARqUNPVh83EuXBZ8QOKk+OQdZptoywZ6TlY8u73mDpjCC5c+w59+3cEALi622H/Hyux8YcF2PLDX7h4/jYWv7MZrRytcT1sK2a/PgxqagIYGeth3Rdv4MzFbxAZGYcfv/tDxXfUDKgJGu9PC1Gn4VXGxsbIzs6u+l1dXR12dnbQ0dGpdmx2djb09fXrX8MmRNPYFP4/7oOahuw/q3nXXjDtFAA1DQ0Y+3SUe5y+kyt8V33LpSWVSE1DD2ausyAQqMvM1zZ0h5aBCwQCdWjqtZJ7nIa2BUwcx3LJXGoxNI1N0fF7+c81sy69YNJR8lwzavfs51q7lXyuKZOGkQlar9sLgZy/uWGHnjDw6QaBhgb0vTrIPU7HwRXOi7/mkrlKZGFpgpDIn6GpKftvPvTlAAwK7AxNTQ306usn97g2bZ1x5OTnXDKXmoU6BR2urq64d+9e1e9GRkY4c+aMzGNjYmJgb29fv9o1QfI+cJ/Or+m42h5DtScvkHg6v6bjansMUXPB51rjJS+QeDq/puNqewzVnrxA4un8mo6r7TFEjV2d/hW/8MILCA0NrfE4oVCIEydOYMSIEYrWq9no+fv5Wh3nu+rbBq4JPc3Sc0GtjjNxHNvANSFqWrofrN1zrd1KPteetzbb/q3Vcc6Lv27gmtDTcoqP1+q4Iyc/b+CatFDNeBTTiRMnsGXLFkRFRUFTUxOdOnXCggUL4OHhUeeyIiIiMHr0aJSVleGzzz7D8OHKW0q7TkHHtGnTanWcQCDA7t27Zc71ICIiIiKi+tu/fz+WL18ODw8PvPfeeyguLsbu3bsxfvx4BAUFwdPTs9ZllZWVYdmyZdDS0kJZAwy3bJC12HR1deHl5QVTU9OqNKFQiI0bNyIhIaEhLklERERE1GLk5uZi7dq1sLGxQVBQECZPnoxZs2bhl19+gVgsxqpVq+pU3rZt2/Dw4UP873//a5D6PrcFoIVCITZt2oT4+PjndUkiIiIiIlRuSdMYfxR1+vRpFBQUYMyYMVKry9rZ2WHw4MG4cuUKkpOTa1VWTEwMNm7ciHfeeQc2NjaKV+oZnuuuM3XY/JyIiIiIiOQICQkBAHTo0KFaXmXa7du3ayxHLBZj2bJl8PLywqRJk5RbySdwOQQiIiIiIhXp37//M/NPnz4tMz01NRUAZPZMVKalpKTUeP09e/YgNDQUBw4cgFp9ul5qwKCDiIiIiJo1QTNcvaqoqAgAoKWlVS2vMk0kEj2zjKSkJGzYsAEzZ86s06RzRTDoICIiIiJSEXk9GTXR1dUFAJSUlFTLq0yTtYH3kz744ANYWFjgzTffVKgOdfFc53QQEREREVH9VW5NIWsIVWXasyaFnzx5EufPn8esWbOQkpKC2NhYxMbGIjMzEwCQmZmJ2NjYqh6V+mJPBxERERE1a81xeJWvry/27t2LmzdvokePHlJ5t27dAgD4+PjIPT8xMRGApLdDlnXr1mHdunX46aef0Lt373rX97kGHYLm2OJERERERM/ZgAEDsGrVKuzfvx/Tp0+vWjY3KSkJx48fR5cuXWBrawtAMv8jKSkJhoaGsLKyAgD069dPZk/I1atX8csvv2DKlCnw9/dHmzZtlFLf5xp0cMlcIiIiIqL6MzY2xqJFi/Dhhx9iwoQJGDduHEpKSrB7924AwLJly6qODQ0NxdSpUzFy5EisXbsWAODk5AQnJ6dq5QqFQgCSXpIhQ4Yorb5KCTpKSkqQnZ0NU1NTmTPoAcDCwgJ3795VxuWIiIiIiGqtuY62GT9+PExMTLB161Z8/vnn0NTUhL+/P+bPnw8vLy9VV09KvYKOiIgIrF27FtevX0d5eTm2bduGgIAAZGZmYsGCBXjttdfQvXt3ZdWViIiIiIieMGTIkBp7JLp27YrIyMhalTdq1CiMGjVKGVWTovDqVZGRkZg4cSJiY2MxfPhwqTxzc3OIRCIcPny4vvUjIiIiIqImTuGejm+++QYWFhY4dOgQSkpKcODAAan8bt264fjx4/WuIBERERFRfTTT0VVNisI9HdeuXcOYMWNgYGAgc5ycnZ0d0tPT61U5IiIiIiJq+hQOOoRCIYyNjeXmFxUVcbUqIiIiIiJSfHiVvb39M1ejunbtGpydnRUtnoiIiIhIKTi8SvUU7ukYPHgwDh8+jNu3b1elVQ6zOnz4ME6fPo3AwMD615CIiIiIiJo0hXs6Xn31VZw5cwYTJ05E+/btIRAIsGnTJqxZswZRUVFo06YNpk+frsSqEhERERFRU6RwT4e+vj6CgoIwYcIE3L9/H2KxGMHBwUhOTsakSZOwY8cOuRsFEhERERE9LwK1xvvTUijU01FeXo7U1FTo6elh6dKlWLp0KbKysiAWi2FmZtZsd30kIiIiIqK6Uyi+KisrQ//+/bF///6qNDMzM5ibmzPgICIiIiIiKQr1dGhra8PY2Bj6+vrKrk+jZamjhVleTuhqZQIjTU1kFpfgfHImtkfFoaC0vMbzddTV0MvGHAHWpvAwNoCVrjbEECOuoAinEjNw4EESymqxxPDU1q3wP28nAMD8i7dxPSO33vfWHNhaG2Px3CF4oZcnTE30kZqeh2OnwrB+0wnk5hXVupyXBvlg1uSe8PG2h6amBmLjM/Hbn9exefu/KH2qnTU01DBjQg+087aDj7c9PNysoaWlgXeW78Mvv11R9i02SSNf7IJeXdvAt60TfLwdYWSoh6CDFzBz/qY6l2VvY4YV747BoL5+MDMxQEpaDv48cQ2rvjqAnNxCmed4tbbH8ndGo1c3bxgZ6CIuMQP7/7yE9Zt+h6i4tL631+RZ6mhhdhsndLMygZGWJjJFkufatrtxyK/lc623rTkCbEzhafLouSaWPNdOJmTgt+hnP9f62pnjZWcbeJoYQFdDHdnFJbiXW4hdkQm4k52vzFttkqz1tPBWB2f0dDCFibYm0oUlOBOXge9uxSGvpKxWZcxo54AutiZwM9aDqY4mKsRiJBUW41JiNnbcSUCqsKTGMl7zc8Tcjs4AgFnHQ3E5Oaced9X8iEQl2Ln1FE4cv4GUpCzoG+igo787Xn3zRbi42ihcbk52ASaMWovMjDz4dXDFTzvnyzwuNSUbP246ikv/RSA3pxAWlsbo84IPZr8eCCNjPYWv39zwnbjqKTyRPCAgAJcvX8bEiROVWZ9GyU5PB5t7+cJMWwvnkzMRWyCEt4khxrrZo6uVKeZcCEVe6bM/AHzNjPBBJ0/klpTiZkYuzqdkwlBTAz1tzPFWWxf0sTXH/Iu3UVIh/wPaw1gf0z1bQVhWBj0NhZuu2XFuZY4jQW/D0sIQx06F4d6DNHTwbYXXpvXGC7288NLEb5GdI6yxnKXvBGL+awNQUCjCXyduIydXiK6dXLB8wVD07tYa41/9CWVlFVXH6+lqYdWyEQCAtPQ8pGXkw8HOtKFus0la/PZI+LV1Rn5BERKTs2BkqNgHoIuTFf45+AmsLY3x59/BiIxOgr+fO96aFYiBfXzxwqiPkJVTIHVO5/ZuOLZ3OTQ1NHDo6BUkJGeib/e2WDb/FfTr0RaBE1ahpJZf3Joje30dfN/bF2Y6WjiXJHmutTE1xFh3e3S1NsXr50Jr/GLrZ26EDztLnms30nNxLvnRc83WHG/7uKCPnTnmXaj+XFMXAMs7eWBQKyvEFRThdGI6CkvLYaajhXZmhvA0MWjxQUcrQx3sHtoeFrpaOB2bgZhcIXwsjTClrQN62Jth8tFbyC2u+d/vWE9bCEvLcS01F5lFJdBQE8DLzADT2jlglIcNph8Lwd0s2UE7AHibG+ANP0cUlpZBX5OfO08rKSnF269+h5CbD+Dd1hHjJvVBakoOTp+8if/Oh+O7LW+hna+zQmWv+eRXFAmLn3lMQnw6Zk/+CllZ+ejdzwfOLta4ExaLvbv/xaULEfhp1zswMWk5L4ipcVP4CbJw4UJMmjQJX375JWbPng1DQ0Nl1qtRedfXDWbaWvjqdjQOxCRXpb/V1gXj3OzxP28nbAiNfmYZWcWl+OR6JP5JypB687fpzkN828MHPmZGGOlih1+jE2Wer6UmwPIOHribU4DEQhGGtLJSzs01A+s+fAWWFoZY8ukhbN19oSr9k/dfxuvT+2Dp/EAs/OjAM8vwaWOP+a8NQE6uEANf+RKxCVlVeZ99+AqmT+iO2ZN74vufz1WlF4lKMf5/PyHsbiLS0vOx8K1BWPjWYOXfYBO26JNdSEzOQvTDFPTq5o0T+z5QqJyvP50Ja0tjLPjgZ2z++e+q9HUrJmPu/4bio0XjMHfp1qp0NTUBftjwOvT1dDB61nocOXkdgGRZ7182z8PIF7ti7uwXsf67P+p3g03Yu35uMNPRwpch0fjtwePn2ts+Lhjvbo/X2jjh81s1P9c+Do7EmcSnnmthD/FtTx/4mhthlKsd9t6Xfq7N8nbCoFZW+PluHLZExOHpVy3qfCWJFQHusNDVwqrL97EnIqkqfVFnV0xr54B5HZ3xyaX7NZYz/PA1lJRXf5k12sMGH/fwwLxOLnjjZJjMc7XUBVjbyxNhGfmIyxdhuLu14jfUTO3Z+Q9Cbj7ACwPbY/X66VBTk4xaH3imAxbO24KVH+xB0MH3q9Jr68gfV/HPqRAsWj4Gn326X+5x6z7dj6ysfLz7/isYN6lPVfqXnx1E0K6z2PzNX1jywTiF7o1I2RSeMz9lyhSIRCL8+OOP6NKlC3r06IH+/ftL/QwYMECZdVUJOz0ddLEyRVKhCAefCDgAYOvdOAjLyjHYwQo66s/+U97PK8TJxPRqQw2Kysux91Gg0cFc/g7vr3k7w1ZPB6tvRnGn9yc4tzJHv56eiE3IxLZf/pPKW/ft3ygsLMbolztBT/fZK6m92L8dAOCX365IBRwAsOrLowCAmRN7SKWXlpbjzPm7SEtv2W9kn+XcpXBEP0ypVxkuTlYY2McPD+PS8P2OE1J5K7/4DQWFIkwc1RN6utpV6b26tYF3awecvxxRFXAAgFgsxtLVewAAsyc1/eeTouz1ddDVWvJcO/DgqedaxKPnWquan2v3cgtxIqH6c01YVl4VaHSwkH6umWlrYoK7PcKy8vCTjIADAMpb+DOulaEOetibISFfhKAnAg4A2HgzFsLScgxzs4auRs0f4bICDgA4HpMOAHAy0pV77judXGBvqIOlFyL5uSODWCzGwX2Sz523FwyXCiz6vOCL9h3dEBOdghvXag4On5SSnIUNaw/g5VHd0L1nG7nHJcSn48rFu7C1N8OYCb2k8l5980Xo6mrh2F/BNfaWtBRqgsb701IoHHTY2dnB3d0d/v7+8Pf3h6urK+zs7KR+bG1tlVlXlej46AMzOD272odjUXk5wrLyoKuhjramivf0lFVIhuzI+6DtaGGM0a52+CEiFgmFIoWv0xz16OoOAPj3v+rBWGFhMa7efAh9PW108nN6ZjmWlpL2i43PrJaXm1eE7BwhnB0t4GhvpqSaU231CWgLADh1PrRaGxcUinDpWiT09XTQpaN7VXrf7pJzTvwbUq28h3FpiIpOglMrS7g4tcwew8rn2tW06s81YVk5bmc+eq6ZKf+51s/eAlrqajiVkAEtNTX0tTPHZA8HjHKxhbsRh4EAQBcbEwDAxSTZ7XMzLRd6murwtTRS+Bp9W5kDAKKyCmTmd7U1weQ29vjqegzi8vi5I0tCfAZSkrPh6GwFewfzavnde3kDAK5duVfrMsViMT5e/gsMDHQwf+HIZx577aqk3G4BXtV6UvT1deDbwRWiohLcDn1Y6+sTNSSFh1ft2rVLmfVotBwNJG+B4uV82Y8vLEIXmKKVga7Ck7qHOkq6rK+kZVfL09dQx9L2rRGamYffYpKq5bd07i6WAIDoh+ky8x/EpqNfT0+4OVvg/GX5D/6sbMmYZkcZHxxGhjowNZHMRXBzsURcYla1Y6jheLhKXl7cfyC7xyQ6JgUD+/ihtYstzv53R3KOW+U5yTLPuf8wBR5udmjtYouY2LQGqHXj5mj46LlWIPu5llBQhK7Wj55r6Qo+15wePddSpZ9r3qYGACST0IMGdoSNno5U/j+JGVh5PQrF5RVoqZyNJe3zMFf2XLTYvCL0sAecjXRxpZaTul9pbQNrfW3oaarBw1Qf3WxNkZgvwhfXY6oda6CpjlU9PXA9NRe7w/m5I0/sQ8mzw9HJUmZ+K0dJelwdnjFBu87iRvB9fPvDHBgY6CJPzr8BAIirvL6z7Jcnjo6WuHLxLuJi09Clm2et60DUUDgrrAb6jyZsF8qZKF74aIUXAwUndo9ytkU3azNE5RbgSFxqtfz5Pm4w1NLE2xdvK1R+c2doKPnCkpcv+8tTZbrRM4YQAMCpsxGY/9oATB7TFduD/kN84uMvSkvnv1j13yZcCeS5MzKS/M1z82V/+FamGxs/fkteOWFd3jl5eZJ0kxb6Zr2m51pBmeS5ZqjgxOFXXG0RYGOGqJwC/BUr/Vwz0dIEAMz2dsLtrDy8fzkC8QVFcDXSwwI/N/Szt0BRWTlW3aj92+HmxlBL8ncvKJG9glj+o/TK42rjFQ8b+Fk97hm5nZ6HRf/eRZyMZ+fSbu4w1tbE9GOhdal2i1OQL1kZ0cBA9udLZXp+fu1WUHwQnYzN3/yFUWN7oEtAzUFCwaO20zfQkZmv/+jlQkEtr9/ccaqY6jHoUKHetuZ4u50rMkUlWB4cUW0YQh9bcwxpZYUNofeRzDGZDerqzYfYvf8KJo/pirO/v4e/ToQ+Wr3KFW08bREVnQoPN2tUPGN1MSIC+tiZY66PKzJEJVh2pfpzTe3RJ39+aSkWXQqH8FGAE55dgMWXwrF3YCcMdrTCD+GxyBDVvJwr1c7EI7cAAMbaGmhjboB5HZ2x7+WOePefCPyX9Pgly0AnCwx3t8bKS/eQIKcnrCX58buj1dJeGt4VdvbVe8Xro6y0HB8t2QVzCyO8vWC4UssmaiwUDjq8vLxq3AhQIBAgPDxc0Us0CoVlkjeB8pYK1NdUBwAUlNVt6c1eNmb4qJMnckpKMPe/sGpBhaGmBt7zdce19BwcrudE3OYsv7Inw1D2m57K9Lxa7NWxYMU+3Lwdh8ljuuLlIX6AGLgeEouRU7/DO28MhIebNTKyOGn8eavslTCWs9xuZXruE3t15OU/+5zK3pOcPPlLhTZnNT3XDDQkz7X8GpYCf1ovWzN83NkTOcUlePtCGJJkvCwpeFTmtbTcqoCjUmZxKe5kF6CzlQm8TA1wIbllDmXMf7RUsYGWusx8w0fp+Qos+ZxbXIZLSTkIy7iNv0Z2xprenhi4/yqKyytgrKWBD7q741JSNvbelT00saXZsvl4tbROnVvDzt4cBpU9CQWyP18q0w0Nn93TDgA/bzmByLuJ2Lz1Lejpadd4PAAYPPp8K5QTHBZW9sTU4vpEz4PCQceIESOqBR1lZWWIj49HSEgIPD094e3tXe8Kqlrco4dGK33ZX2pb6VeOja5992VfW3N82MkTmcWlmH/xtszJ4da62jDR1oS/pQnOv9xTZjlfdfcBAHwT9gD7H7TMcbf3H63A4uYse0ytq1PlnI+MWpW3a99l7Np3uVq6d2sblJdXIPSO7CWNqeFEPZqX4S5nky03F0n6vSdWl4uKrjxH9mIW7s7Vz2lJ4h59GWklZ1iGg0Hdn2v97MzxUWdPZIpKMfeC7Oca8PiZWiAnoKkMdLTruMRoc/IwV/I3cpYznLNyxamHddj49Gn5JeW4lZ6HAU4WcDfRw53MAtgaaMNMRwsBdlq4M6O3zPO2DvEFAKy9Eo1d4c3/eXj19jdy85wezaWIi5U9pzA+TpLuWIsFK+5GJEAsFuP1md/KzA+5+QBdfObCwFAXZy6uk5Rbef2HsueMxNXh+i0Bh1epnsJBx9q1a+XmXbt2DXPmzMHHH3+saPGNxo1Hk8M7W5pCAEitJKKrro52ZkYoKiuv9UZWA+0tsbSDBzJExZh78bbcYVN5JaX4K1Z2D4efuTFaGejiUmoWMkUleNBC39YCwH9XJEsR9unhAYFAILW6kb6+Nrp0cEahsBjXQ2IVvkb3Lm5oZW+G42fuIJ/DDZ67fy9JJocP6OVbrY0N9HUQ4O+JQqEIV288Xpby7MU7eH/uSAzq44f1m36XKs/Z0QoebnaIjU9vkZPIgcfPtS5W1Z9rehrq8DF/9FyrZc/eIAdLLOskea69ff62zB6OSsFpOZjh5QhXI9lfqF0e9U4lC1vu/2tXU3IAAN3tZLdPBytjCEvLEZqeV6/rWOtJlhKvHAKXU1yG36JkB+L+1sZwNtbDuYQspAmLcS+75X7uVHJoZQEbW1PEPUxDYkJmtRWsLp6PAAD4d21dY1ldAzxhYlp9jlmRsAQnj9+AmbkhevZpCx2dx8u/+3eRlHv50l1UVFRIrWBVWChC6M0H0NHVgo+CmxMSKVuDzOnw9/fHyJEjsX79+ia/ylWSUISradnoYmWKUS62UpsDzvJyhJ6GOg4/TIboiZVWKle8invqLeGQVlZ4v31rpAolAUdqkfwP5jRRCdaFyF7be2n71mhloItfoxMVXjGruXgYn4l/LkSiX09PzJzUQ2pzwMVvD4a+vjZ27L0IYdHjseHuLpK3PvdjpL9wGuhro6BQuk0c7Ezx5cqxKC4pw9qvjjXgnZCGhjpcnaxRWlYmFQzExKbh5L8hGNjHD69PGyS1OeCKBaNhoK+Dn3afgvCJ/5/OXw5HxL0E9OrmjaEDO0ltDrhqyQQAwJZfTj2nO2t8EgtFuJKaja7WpnjF1VZqc8BZ3o+eazG1e64FOlphScfWSBFKAo5nPdcAICQzD1E5BfCzMEZvW3OcS368TPUwZ2u4GOkhvqAId7NlL+XaEsTni/BfYhZ62Jthgred1OaAb3Vwgp6mOn69m4Sissft4/JoxauY3MftY6uvjZLyCmSKSqtdY4ynLXwsjZBcIELUowAipbAYH/4newL/qp4ecDbWw46wBFyu5YpZzZ1AIMCosT3w3dd/4dsvfpfaHPDfM6G4dSMaLm426OjvLnVeSnIWREWlsLE1hc6jPaTGTJDds5SUmImTx2+glaMlln88USrPoZUlunb3wpWLd7E/6LzU5oA/bjqKoqISjBzTA7q1HK5F1NAabCK5m5sb9u3b11DFP1cbQqOxuZcv5vu4oZOFCWILhPA2MUQnSxPEFQjxU4T0W/RfXugEAOj1x+MvwB3MjfF++9ZQFwhwIyMHLzpW39m1oLSsxQ6Tqo/FHx/AkaC3sWb5SPTu1hpRD1LR0dcRvbq1xv2YNKx+Kli4eGwxAMDK612p9K9WjYODnSluhycgO1cIRwdzDO7XBpoa6nhzcRDCZbwBfPt/L6C1qySIaedlBwCYMKozunZyAQBcuR6DX367ovR7biqGDfLHsMH+AABrSxMAQNdOrfHjhtcBAJlZ+Viy6hcAgJ2NKUL+2YDY+HR49ZgrVc685dvwz8FP8MUn09GvR1vcvZ+Ezu3d0bdHW0RFJ+Gjz36VOr6iQozX3v0ex/Yux57N83Ho6BXEJ2WgX4926OTnhovBd/HNluoTRFuSDSHR+L63L97xc0MnSxPE5gvRxuzRcy1fiB/CpZ9rQQMlz7Uehx4/1zpaGGNJx0fPtfScqmVyn1RQWoZ90dLPtU+vR2FjL1+s6uqF/1KyEF9QBBdDPQTYmEFYVo5Pr0eh5S6YK7Hy0n3sHtoey7q5o5utCR7kCuFraYSutiaIyRXi6xsPpY7/a1RnAEDb7eeq0rzNDfBFP2+EpOUjLq8ImaISmGhrwtfSEJ5mBigsLcP75yLB9TEUN3FqP1z49w7OnLyFGRO/QOeuHkhJzsbpkzeho6uFFZ9MrLaHxkdLd+PGtfvYvO1tdOpccy/IsyxePgazJ3+FDWsPIPhKFFxcrRF2OxbXr96Do7MV3pj7Ur3Kb05qmodMDa/Bgo6wsDBoamo2VPHPVZJQhP/9ewuzvJzQ1coU3axNkSkqwb7oRGyPikNBqexlDZ9ko6cN9Uf/4F9ykj02PVkoYtChgIfxmRg4+issnjsYL/T0Qv/eXkhNz8MPO85h/aYTyK3luOeTZ8MxZWw3DBviBwM9baRnFuCvE6H45sczuPdA9jCcF3p5okcX6bdYXTq6oEtHl6rfW3LQ4dvWCVPG9JFKc3WyhuujL6ex8elVQcezxMSmoedLS7Hi3TEY2NcPg/t1QEpaNjZuPYZVXx1ATm71oR7Bt6LRc9hyrFgwGv17+8JQXwdxiRlY9dUBrN/0O0oUmITbnCQWijDr7C3M9nZCV2tTBNg8eq7dT8S2u3HIr+NzbZiznOdaoaha0BGdJ8TMf25ippcjuliZIMDaFDklZfg7Lg0/R8ZX601pieLzRRj350281cEJPe1N0dvBDOlFJdh1JwHf3YpDXi3+/UZkFmB3eCI6WRujdyszGGtroKS8Agn5ImwPi8fu8CSkFHJlxPrQ0tLExh/fxI6tJ3Hi2A0E7foH+gY66NPPF6++GQhXt4bdJNmhlSV2/Poefth4FJf+i8DF8+GwsDTC+Ml9MPv1QBhxmXdqRATip7f4raXg4GCZ6bm5ubh48SL27t2LwMBAbNiwoV4VBKR7DKjxiVx0SNVVIDnyhQxiG6uOX7+p6irQM+TktPS+lsbr4iQGpY2VsdZgVVdBrnY/n1d1FeQKm95L1VV4LhTu6ZgyZYrMrqrKGKZnz55YtmyZ4jUjIiIiIlICQctdEK/RUDjoWL16dbWgQyAQwNjYGM7OznBxcZFzJhERERERtSQKBx2jRo1SZj2IiIiIiKiZUrizacmSJQgJCZGbHxoaiiVLlihaPBERERGRUggEjfenpVA46Dh06BDi4uLk5ickJODw4cOKFk9ERERERM1Eg02rEQqF0NBosBV5iYiIiIioiahTVJCUlITExMSq3x88eCBz6dzc3FwEBQXBycmp/jUkIiIiIqqHljSMqbGqU9Bx8OBBbNy4EQKBAAKBAN9//z2+//77aseJxWKoqalh9erVSqsoERERERE1TXUKOgYMGAB7e3uIxWIsXboUY8eORYcOHaSOEQgE0NPTg4+PD2xtG3YnTiIiIiIiavzqFHR4eXnBy8sLgGRH8ldeeQV+fn4NUjEiIiIiImXg8CrVU3im95o1a5RZDyIiIiIiaqbqvbxUeXk5YmJikJOTA7FYXC2/c+fO9b0EERERERE1YfUKOrZu3YoffvgB+fn5co+JiIiozyWIiIiIiOpFjcOrVE7hfToOHjyIzz//HB4eHpg/fz7EYjGmTZuGmTNnwsjICD4+Ply9ioiIiIiIFA869uzZAx8fH+zevRtjx44FAPTp0wcLFy7EH3/88czdyomIiIiIqOVQOOiIjo5GYGAgAMkyuQBQUVEBALC2tsa4ceOwc+dOJVSRiIiIiEhxAkHj/WkpFA46AMDQ0BAAoKurC0CyE3klBwcHxMTE1Kd4IiIiIiJqBhQOOqytrZGYmAgA0NbWhqWlJcLCwqry79+/DwMDg/rXkIiIiIiImjSFV6/q2LEjLl68iPnz5wMA+vfvj127dkFPTw8VFRUICgrCwIEDlVVPIiIiIiKFtKRhTI2VwkHH+PHjcerUKYhEIujo6GDevHkIDQ3Fxo0bAQCtW7fGwoULlVZRIiIiIiJqmhQOOnx9feHr61v1u6mpKQ4ePIjIyEioq6vD1dUVamr1mjJCRERERETNQL13JH+ap6ensoskIiIiIlKYgLsDqly9g45r167h/PnzyMzMxIwZM+Dm5obCwkKEh4fD09MTRkZGyqgnERERERE1UQqPf6qoqMC7776LKVOm4IcffsCBAweQlpYGANDQ0MCcOXMQFBSktIoSEREREVHTpHDQsXXrVhw9ehSLFy/G0aNHIRaLq/K0tbUxYMAAnD17Vhl1JCIiIiJSmKo3AOTmgPUIOg4dOoThw4dj+vTpMDU1rZbv5uaG+Pj4elWOiIiIiIiaPoWDjvj4eHTs2FFuvrGxsdQO5URERERE1DIpPJFcV1cXeXl5cvMTEhJgbGysaPFERERERErRkoYxNVYK93T4+vri2LFjMvOEQiEOHToEf39/hStGRERERETNg8JBx+zZsxEeHo65c+ciNDQUAJCcnIxTp05hwoQJyMrKwsyZM5VWUSIiIiIiapoUHl7VrVs3rFy5EitXrsTJkycBAMuWLQMAaGlp4dNPP5XasZyIiIiISBU4vEr1ah10TJ06FW+88QYCAgIAAIcPH0a3bt1w+vRpHD9+HA8ePEBFRQWcnZ0RGBgIa2vrBqs0ERERERE1HbUOOq5evYoxY8ZU/b5kyRJ89tlnGDZsGCZPntwglSMiIiIioqav1kGHpaUlEhISqn5/cjNAIiIiIqLGSo3Dq1Su1kFHQEAANm/ejLCwMBgZGQEA9u3bh4sXL8o9RyAQYPXq1fWvJRERERERNVm1DjqWLFkCgUCAixcvIiMjAwKBAMHBwQgODpZ7DoMOIiIiIiKqddBhamqKdevWVf3u5eWFzz//HMOGDWuQihERERERKQNXr1I9hffpGDlyJBwdHZVZFyIiIiIiaoYU3qdjzZo1yqwHERERERE1UwoHHURERERETYFA4bE9pCxsAiIiIiIialAMOoiIiIiIqEFxeBURERERNWtcvUr12NNBREREREQNikEHERERERE1KA6vIiIiIqJmTcDxVSrHng4iIiIiImpQDDqIiIiIiKhBcXgVERERETVrHF2leuzpICIiIiKiBsWgg4iIiIiIGhSHVxERERFRs8bhVarHng4iIiIiImpQDDqIiIiIiKhBcXgVERERETVrHF6leuzpICIiIiKiBsWgg4iIiIiIGlSTGF6V/P09VVeBnqHrtyNUXQWSI6uA/cmN1Y15m1RdBXqG7f9MU3UVSI7NEeqqrgLJ8b6fqmsgnxo/DlWOPR1ERERERNSgGHQQEREREVGDahLDq4iIiIiIFNWch1edOHECW7ZsQVRUFDQ1NdGpUycsWLAAHh4eNZ575swZnD59Grdu3UJSUhK0tbXh5OSEMWPGYMSIEdDQUF6owJ4OIiIiIqImaP/+/Xj77bdRVFSE9957D6+//joiIyMxfvx4REZG1nj+ihUrcOXKFfTq1QtLly7Fq6++irKyMixbtgxz5syBWCxWWl3Z00FERERE1MTk5uZi7dq1sLGxQVBQEAwMDAAAgYGBGDp0KFatWoWdO3c+s4z169ejW7duEDyxkcm0adMwZcoU/Pvvvzh37hz69OmjlPqyp4OIiIiImjU1gbjR/ijq9OnTKCgowJgxY6oCDgCws7PD4MGDceXKFSQnJz+zjICAAKmAAwDU1dUxZMgQAKhVb0ltMeggIiIiImpiQkJCAAAdOnSolleZdvv2bYXKTk1NBQCYm5srWLvqOLyKiIiIiEhF+vfv/8z806dPy0yvDAxsbGyq5VWmpaSk1Lk+KSkp+PXXX2FsbFxj3eqCQQcRERERNWvNcfWqoqIiAICWlla1vMo0kUhUpzILCwsxZ84cFBQU4Ntvv4WJiUm961mJQQcRERERkYrI68moia6uLgCgpKSkWl5lmo6OTq3LKywsxKuvvorw8HCsWLECAwcOVKhe8nBOBxERERFRE2NtbQ1A9hCqyjRZQ69kKSgowOzZs3H9+nV89NFHmDRpkvIq+giDDiIiIiJq1tQa8Y+ifH19AQA3b96slnfr1i0AgI+PT43l5OfnY9asWbh16xY+/fRTjB8/vh61ko9BBxERERFREzNgwADo6+tj//79KCgoqEpPSkrC8ePH0aVLF9ja2gKQzP+Ijo5GWlqaVBn5+fmYOXMmbt++jTVr1mD06NENVl/O6SAiIiIiamKMjY2xaNEifPjhh5gwYQLGjRuHkpIS7N69GwCwbNmyqmNDQ0MxdepUjBw5EmvXrq1Knz59OsLCwtC/f38IBAL8/vvvUtfw9PSEl5eXUurLoIOIiIiImrX6bMLXmI0fPx4mJibYunUrPv/8c2hqasLf3x/z58+vVbAQFhYGQDKZXdaE9rfeeotBBxERERFRSzdkyJCqHcTl6dq1q8zdxZW543hNOKeDiIiIiIgaFHs6iIiIiKhZa46bAzY17OkgIiIiIqIGxaCDiIiIiIgaFIdXEREREVGzxrfsqsc2aGDRx2aiKPNujcclXlmHrHuHG75CVOWvQb2REVJ9F8+nXXxvLiJ3bnsONaJKF0f1Qm5YzW0TtuJtxO1l2xBVmuAeiPDLoTUe98nERfjt693PoUZERBJKDzpKSkqUXWSTIq4oq1V+TcfV9hiqvYqyZ/89K/NrOq62x1DtsW2IFFNW+ux/75X5NR1X22OIiBSl1KAjLi4Ofn5+OHHihDKLbTLKi/MQ++9i5MQclxkwFKbeRNy5ZRBm3EHS1c+QHrYD5SUF1Y4rzk9A4pXPkHX/92p5pJjinBycmToO0b/tlfmlNOXSBZydNRnp14NxaeE8hH71OUrycqsdlxfzAJcWzkPUru3Po9otQmluNm68MQ6Jv8tum6yrF3Dz7UnIuRWMOx/MRfTmz1GaX71tCmMfIOyDuYj/lT0f1DLkZeZgXr8Z+GvLAZkBw7VTl/HuoP8h9MINfDp5MbYs/wb52XnVjouPeoiVkxbjwDfs+aDmS03QeH9aijrN6UhNTX1mfnp6OsRiMXJzc6uOtba2Vrx2TYyaliEsvMYhK+oQ8uLPw6LNJABAqTAVOTHHIMq+DxOXIdAxcYe51wRkRf2GuHNLYNZ6FCAWo6KsCBnhe5AXfxYGdt1g3Kqfam+oGdEyNkabV+cgcsdWxB8/gnZvzgcAFCYmIHrfHmSH34HbmPEwbdMObV9/CxFbf8A/MybBc/psoKICZYWFuLP5G8T+9QfsXxgAp6Evq/aGmhENIxM4T5uDuKAtSDv9F1xmzwcAiJLjkXh4D/LvhsF+xAQYerWD84y3Ebf7e9x8cyIcJ84GxGKUCwsQs/UbpJz4HZa9B8Jm8HDV3hDRc2JoZozJS2Zj35e7cHb/35j+4RsAgOSHifjzp/2IuhGBl/73Cjw6tsGUZa8i6PPtWDBwNsa+MxVisRjC/ELs+PR7nN5zFD1e7ocBE4aq+I6IqDkTiMXiWu8L7+3tXbfCBQKEh4fXuVJPc3+xab1VFleUIy/hHLLv/4ny4hwI1LRg7PQCTFxfhLqWgdSxwvQwZEUdQHFeLAAB9K07wsxjFLQMbFVTeQV4v+Ou6irUWkV5GeKPHUHULztQnJkBNW1tOL88Cu7jJkHLyEjq2PRrV3F3+0/IvRcJCASw6dEbXjP+B4NWjiqqfd1lFTSdVyji8jKknvoLCft3oCQrA2pa2rB5cRTsR06GpqF02+TcuorYX35EYbSkbcy69obTpFeha9902ubGvE2qrgI9w/Z/pqm6CrVWXlaOM/uO49CmIGSnZkJLRxuDpgzD8NfGwsDEUOrY0PPXsXfDDsSE3YNAIEDnQd0x7t3psHN1UFHt6+5hgbqqq0ByvO83UNVVkOuV0+dVXQW5DvTvpeoqPBd16ukQi8XQ19dH//79oa5e/X/6wsJCnDhxAl26dIG9vb3SKtnkCAQQCNQAPPGFT6Am+al2rBogqMVxpBQCCAA1NQie+JsL1NQgkNG/KVBXl2obgbpay+oHfe4EEKhJ/38jr21Q7TjptiJqSQQCQE1N7clPHMnvMv7fUVNXk/pfRU1dXfb/Y0TNjEBQ63fs1EDqFHSsWLECGzZsQExMDFauXAkvLy+p/NjYWJw4cQKTJ0/GoEGDlFrRpqIg5Rqyog4CEMDKdyaSgzfAos0EFKbeQNy/i2HqOhRGTv1RWpCEzKjfUJz7EGatR0KgpgVtYydALEbChQ9gaN8Dpu4vQ0PHRNW31Gwknz+Lu9u3QKAmgN97S3Dl/QVo+8ZcpPx3DmemTYD7+ElwHj4KBbEPcXfbj8iJioTntFlQ19KCcWtPiMUVOPfaDLQaFIjWk6ZBx9xC1bfUbGReOou4PT8BAgHc316K8I/fgcusuci8ch433hgP+1GTYfviKAjjHyLulx9QcD8SrSbMRqa2NvRdPQCxGCELpsOyXyBajZkOLTO2DbUMV45fwL4vdkAgEOD1z97F6mlLMXX5a7h28iLmvzATw18fi0FTXkbivTjsXb8dD8LuYcz8qdDS0YZLW3eIxWIsHjoHfV4ZgFFvTYKplZmqb4mImqk6vVKfNGkS/vrrLxgbG2P06NFYv349iouLq/IFLfxNY3lxHjLCg2Dk0Buten4MPYu2AABNPWvY+r8DK5+ZyI07A1FWJDLCf4GGrjkce6+BsdMLgEAANQ1dWLSZCPvuK1BSmIzc2NMqvqPmozgnB3c2fwvHwKHo/f12WHb0BwDo2zug66rP4ffuYsT+eRhZoSEI2/Q1dK1s0G/7L3B+eSSgpgYNfX20mzMPPb/9EflxsXj4+0EV31HzUZqbjZit38Cq/0vw++JnmPhJ2kbHthXaLP8c7m+9j5S/DyEvPAQxW76CtqUNOmzaA9vAkYBAAHU9A7jMmgefdT+hKCEWyUcPqPiOiJ6PvMwc7Fz5PfqNHYy1f30Hnx4dAAC2zvZYvHUlXlvzDk7+cgR3r97Gz59shoW9Fb44uQWDJr8EgUAAPUN9TFvxOlYd+hqJ9+Px984/VHxHRNSc1XlzQDs7O2zZsgWHDx/GmjVr8Pfff+OTTz5BQEBAQ9SvSVHXNoJT33UQqMn+s+pbd4CepQ8EahrQNfeSe5y2oQPsuy7mkrlKpG1ighd2/go1Ddl/c5vuvWDVJQBqGhowb99R7nFGLq7ovv4bLsuqRJrGpuj4/T65f3OzLr1g0lHSNkbt5LeNvpMr2q38lm1DLYaRuQm+PvszNDRl/z/hPzAA7ft2hoamBtp085N7XCsPZ3yw5zMumUvNGkcRqp7CkwdGjBiBo0ePwtvbGzNnzsTixYuRnZ2tzLo1SfICiafzazqutsdQ7cn7svp0fk3H1fYYqj22DZFi5AUST+fXdFxtjyEiUlSdVq+S5+TJk/jkk09QUFAAkUiEr7/+WqlzOpra6lUtTVNavaqlaUqrV7U0XL2qcWtKq1e1NFy9qvFqzKtXjf3nnKqrINe+fr1VXYXnQimvNQYOHIhu3brh66+/RnJycovam4OIiIiIGjeuC6p6SutLNTQ0xPLly+XmC4VCbNu2DSNGjICDQ9NZD5yIiIiIiOrnuQV+QqEQmzZtQnx8/PO6JBERERERNQLPddaYEqaPEBERERHViRo3B1Q5DnEjIiIiIqIGxaCDiIiIiIgaFBflJiIiIqJmjZsDqh57OoiIiIiIqEEx6CAiIiIiogb1XIdXCQTs2yIiIiKi54tv2VXvubYBl8wlIiIiImp5lNLTUVJSguzsbJiamkJLS0vmMRYWFrh7964yLkdERERERE1IvXo6IiIiMG3aNHTs2BF9+/bF9evXAQCZmZmYNm0aLl68qJRKEhEREREpSk3QeH9aCoWDjsjISEycOBGxsbEYPny4VJ65uTlEIhEOHz5c3/oREREREVETp3DQ8c0338DCwgJ//fUX3n333WrzNbp164aQkJB6V5CIiIiIiJo2hed0XLt2DbNmzYKBgQGys7Or5dvZ2SE9Pb1elSMiIiIiqi81ARczUjWFezqEQiGMjY3l5hcVFXG1KiIiIiIiUjzosLe3f+ZqVNeuXYOzs7OixRMRERERUTOhcNAxePBgHD58GLdv365Kq9z87/Dhwzh9+jQCAwPrX0MiIiIionpQ9QpVXL2qHnM6Xn31VZw5cwYTJ05E+/btIRAIsGnTJqxZswZRUVFo06YNpk+frsSqEhERERFRU6RwT4e+vj6CgoIwYcIE3L9/H2KxGMHBwUhOTsakSZOwY8cOuRsFEhERERFRy6FQT0d5eTlSU1Ohp6eHpUuXYunSpcjKyoJYLIaZmVnVMCsiIiIiIlWr127YpBQKtUFZWRn69++P/fv3V6WZmZnB3NycAQcREREREUlRqKdDW1sbxsbG0NfXV3Z9Gi0bcz3Mm9IBvTs5wNRIG2lZQpy8FIdv99xCXkFJjed39bHBL+tqnljfa+o+JGcUSqW5tzLG3Mkd0NXHBgZ6mkhMK8SRfx/g+/23UVxSrvA9NSfm2lqY5OaEjhamMNLURFZxCS6nZSLoQRwKy8pqVUZ7MxN0tDCFq4EBXAz1YaSlifDsXCy+Fir3HDUAvWwsEehgCzs9XehpqCNDVIyInDwcik1EXKFQSXfYdFnqaGF2Gyd0szKBkZYmMkUlOJ+ciW1345BfWvO/Xx11NfS2NUeAjSk8TQxgpasNsViMuIIinEzIwG/RSSh7xvLcfe3M8bKzDTxNDKCroY7s4hLcyy3ErsgE3MnOV+atNikjX+yCXl3bwLetE3y8HWFkqIeggxcwc/6mOpdlb2OGFe+OwaC+fjAzMUBKWg7+PHENq746gJzcQpnneLW2x/J3RqNXN28YGegiLjED+/+8hPWbfoeouLS+t9eslBaX4Pz+Uwj79yZy07KgracDZx939JscCEtHmzqVVVFegct//ItbJ68gMykDmlqacPByQu/xg+HYxkXmOakxSTi//xQSI2ORl5kLXUM9mNtbonNgD7Tp1R5qai3vHXJhZjZu/noECSHhKM4XQs/UCI6dfdF+9IvQNtCrdTnFBYW49dsxxAWHQpidB21DPTj4tUGHcUOhb27aoNcmet4UnkgeEBCAy5cvY+LEicqsT6PkaGOIfRuGwsJUFycvxeJBfC58PS0xY0Rb9O5kj3HvHUVOfvEzy0hILcA3v9yUmefhbIohPZwR+TC7WsDh52mBXWuGQENdDcf/e4jkdCEC/Gzw9qQOCGhvh6lLjqOkrEJp99oU2ejq4LPOfjDV1sLltAwkFBahtbEhhjvZo5OFKRYFhyC/tObAY2grW3SzskBxeTmShSIYaWnWeM57Pl7oZWOJdFExLqVlQFhWDmdDfbxgZ40+tlb46EYYQrNzlXGbTZK9vg6+7+0LMx0tnEvKRGyBEG1MDTHW3R5drU3x+rlQ5JU8u238zI3wYWdP5JaU4kZ6Ls4lZ8JQUwM9bc3xto8L+tiZY96F2yipkA481AXA8k4eGNTKCnEFRTidmI7C0nKY6WihnZkhPE0MWnTQsfjtkfBr64z8giIkJmfByFCxLysuTlb45+AnsLY0xp9/ByMyOgn+fu54a1YgBvbxxQujPkJWToHUOZ3bu+HY3uXQ1NDAoaNXkJCcib7d22LZ/FfQr0dbBE5YhZIa/l20FGWlZdi57DvEhcfArnUrdB3eB3np2bhz4RaigsMxfc2bcPByrlVZYrEY+9ftQPiFW7BwsEKXYb1QlF+IO+duYvuibzBu2Ux4BfhInRN5JQx7P90KgUAAz24+aNPTD8LcQkRcCsX+dTvQ8VYUhs8b3wB33njlpaTjyIovIMrNh6O/L4ztrZF+PxbhR88i8VYEXlz5DnQMDWosR5RfgCPLv0Bechps23nApXsn5Cam4t7Zy4i/eQcvffouDK0tGuTaLRE3B1Q9hYOOhQsXYtKkSfjyyy8xe/ZsGBoaKrNejcrHbwbAwlQXH2++jF1/RlSlL/1fZ8wc2Q4LpnXEBxsvPbOMxLQCfPPLLZl5Xy7qAwD49XikVLqamgDr3ukFPR1NvPbxKZy+Eg8AEAiAb5f0w5Cezpgxsi1+2H+7WpktyRte7jDV1sIPd6PxV3xSVfosDxeMcHLAFHdnfBdxv8ZyfnuYgF33Y5FQKISFjja29uryzONbGxmgl40lYgsK8e6VWyiueBz89bezxvy2Hhjr6ojQ6y23fd71c4OZjha+DInGbw+Sq9Lf9nHBeHd7vNbGCZ/fin5mGVnFpfg4OBJnEjOkejQ2hT3Etz194GtuhFGudth7P1HqvFneThjUygo/343Dlog4PP1xo97Ch4Iu+mQXEpOzEP0wBb26eePEvg8UKufrT2fC2tIYCz74GZt//rsqfd2KyZj7v6H4aNE4zF26tSpdTU2AHza8Dn09HYyetR5HTl4HIFly/ZfN8zDyxa6YO/tFrP/uj/rdYDNx8eA/iAuPQZue7THm/WlVvQrtendE0MotOPxVEOZ8t7hWvQ1h/95A+IVbaOXtgmlr3oTmoxcrnV/sga3vfY0/vtkLF7/W0NbTqTrn5PY/UVFegRnr3oazj3tV+gtTh2LzW+tw4+9L6DNhEEyszJR8543Xpa2/QpSbj64zRqNNYN+q9Ks7DuDOkX9wI+hPdH91Qo3lXA/6E3nJaWj70gvoMnVUVXr40bO48vNvuLTlVwxa9maDXJtIFRTuE50yZQpEIhF+/PFHdOnSBT169ED//v2lfgYMGKDMuqqEo40henWyR3xKPnb/FSGV9/XumygsKsWIF9ygq61Y/GZqpI1B3R1RJCrDodPSX766+NjA3dEEV2+nVAUcACAWA+u2BQMAJrzoqdB1mwsbXR10tDBFapEIR54IOABgT3QcisrK0c/WCtq1+ECOzM1HXKEQte03staVfDCHZOVIBRwAcCUtEwBgrFlzb0lzZa+vg67WpkgqFOHAEwEHAGyNiIOwrByDW1lBR/3ZbXMvtxAnEtKrDaESlpVXBRodLIyl8sy0NTHB3R5hWXn4SUbAAQDlzxiS1RKcuxSO6Icp9SrDxckKA/v44WFcGr7fcUIqb+UXv6GgUISJo3pCT1e7Kr1Xtzbwbu2A85cjqgIOQPIWfunqPQCA2ZOa/meHMojFYlw7+h8AYNDMl6UCC68AHzi1dUN6XApibz87cK8UfERSVv+pQ6sCDgCw93BCu94dUZhbgPALt6TOyU7JrBrO9SRDMyM4eDoDAIRyhtA1R3kp6UgKuQsDS3N4D+4tlddh7FBoaGsh+nwwSkXPHv1QKipG9Lmr0NDWQocxL0rleQ/pDQNLMySGRCA/NUPp1yZSFYWDDjs7O7i7u8Pf3x/+/v5wdXWFnZ2d1I+tra0y66oS3fwk42Uv3EjC099RCovKcCM8DXo6mmjvZalQ+aP6u0NbSwPHLjxEfqH03JAAP8nf79z1hGrnxacU4EFCLhysDeFo03x7mWriayb5snkzM7vaF8ui8nJE5ORBR10dniZGSr92XIFkvoavqQm0ngpqOltK3vqFZOUo/bpNRcdHgcDVtOptIywrx+3MPOhqqKOtmeL/fsseBXtPBxD97C2gpa6GUwkZ0FJTQ187c0z2cMAoF1u4G7WcuWgNrU9AWwDAqfOhED/VBgWFIly6Fgl9PR106fj4C2vf7pJzTvwbUq28h3FpiIpOglMrS7g4WTVgzZuGrOQM5KZnw9zeCqY25tXy3f29AQAPQqJqLKu0pBTxETHQ1NaCYzvXavmtq8q6J5Vu5WiDYqEIsXekA5uCnHwkRsXC0MwIlo7Wtb6npi7ljuTvY+fnBcFTz31NXR1YebmirLgE6fcePrOc9KgYlJeUwsrLFZq6OlJ5AjU12PlJ2iP5zuO2Vda1WypVbwDIzQHrMbxq165dyqxHo+ViL/ni9DBR9rj8h0l56NXJHi72RrgUkizzmGcZO8QDABB0LLJanqu95ItyTGKe3Gu7OhjD2cEIcSktc2y6vZ5kHHqisEhmfpKwCB1hCns9XYQqOQCIKxTicGwCRjg5YHP3TgjOyEJRWTkcDfTQ0dwU/6akYdf9h0q9ZlPiaKgLAIgvEMnMTygoQldrU7Qy0MX1dMXmvQx1knzZuZKaLZXubSoZ06yjroaggR1hoyf9of5PYgZWXo9CcXnLng9VXx6ukhcj9x/I7jGJjknBwD5+aO1ii7P/3ZGc41Z5juzn5f2HKfBws0NrF1vExKY1QK2bjswEyf2b28t+qVWZnpmYXmNZ2ckZqKiogIWNOdTV1avlm9nJLmvIqyPxy0c/YufS7+DZzQemNuYQ5hXi7qVQ6BjoYvSiqdDUbjl7cuUmpQIAjG1lB8VGNlZICrmLvOQ02PnIH4lQczmWj45Lq8M5tbs2kaooHHS0FIb6kodpvlD2ClWVvRNGBnV/6HZpZw23ViaIfJiNmxHVP1yrrl1Yw7X1W84D/2l6GpIPT6GcFaoq0/U1qn/IKsPWqBgkFhZhtqcrhrayq0q/l5ePM0lp1YZdtST6GpLHS6GcSfwFZZKVqww1FXsMveJqiwAbM0TlFOCv2FSpPJNHQ0dmezvhdlYe3r8cgfiCIrga6WGBnxv62VugqKwcq27ck1U01ZKRkSToz82XvUpbZbqx8ePepcoJ6/LOycuTpJuwRwqiQsnLFB19HZn5Oo+C6crjnl2W6Nll6csuy6mdG2Z/8Q72r9mOO+cfL4airauNDgO7wsrZDi1JyaMXXFp6ujLztR61SUkNKxeWCCXtoSm3HF2p6ynz2kSqwqBDhcYFSt5E7JXRy0FNw6uernjRwQ67ox/in+Q0FJaVwdXQALM9XPFxx3bYHHEfRxPq3gNGz9bHzhxzfVyRISrBsisR1YZXqT2aJJ5fWopFl8IhfBTghGcXYPGlcOwd2AmDHa3wQ3gsMkQ1L3lN1FD+2X2sWlr7gV1gal19OJUqRN+4i/3rdsCutSNGvjsZFg7WKMjOw9U/z+P0jiOIuhqOGZ+9LbP3hKgxaUnDmBorhYMOLy+vGjcCFAgECA8PV/QSjUJlb4KhnuzehMreiNrs1fEkYwMtDOnhhCJRGQ6fkT0JsOracnoyqq4tpyekJaj8MqmnIfufcmV6YZny9zPpb2uFYY72OBybgN8ePp53E56Th09u3cGWnp0xrbUzziSnQtQCh/FU7o+iL6cnw+BR71NtljN+Ui9bM3zc2RM5xSV4+0IYkoTVJ00WPCrzWlpu1b+RSpnFpbiTXYDOVibwMjXAheSsOl2fHqvslTCWs9xuZXruExON8/KffU5l70lOXsuYnHx2z/Fqac6+7jC1NoeOvuSNdmUvxdNEwsreC9lvvp/0uCdDTlmF1csS5hdi/9od0NTWxPjls6ClI/nMMbO1wJBXRyI7NRN3L91G6Jlr6DCwa411aA5k9UA8qbIHQ0v/2UtQV/ZKlMotp3qvhrKuTaQqCgcdI0aMqBZ0lJWVIT4+HiEhIfD09IS3t3e9K6hqMY/mcjjbG8vMd7Z79rwLeUYNkEwgP3DyntzhUw8eleliL3sSdOW1HybU7drNSaJQ8gXGXk53s92jdHlzPuqjs6XkTWRoVvX5CDklpUgoLIKbkQHs9fQQnV9Q7ZjmLi5f8jdvZSB7OIeDQeWcj9q3TT87c3zU2ROZolLMvXAbCXK+QMU9KrNATkBTGejUZlUzki/q0bwMd1fZG9S5uUjS78U87u2Liq48R/ZCI+7O1c9pzj4++rXcPHMHydh9eXM2KtPlzfl4kqmtBdTU1JCdkony8vJqPRNZSdXLig+PQVGBEM6+vlUBx5NcfFvj7qXbSLof32KCDmM7yTyy3GTZ843yUiTpRnLmXdS+nPRHx1nV4ZzaXZtIVRQOOtauXSs379q1a5gzZw4+/vhjRYtvNC6HSCZI9uxoB4EAUitY6etqoGMbKwhFpbh1t+aJfE8aN+TR0Krj8lcduRSSjDfH+6F3Jwd8v096r4dWNgZwdTBGQmp+i51EDjz+wt/B3BQCQGqVJF11dXibGEFUXo7IHOUHZpqP+mqN5WwiWLm5YJm45fVyAMCNDEnbdLGq3jZ6GurwMTdCUVk57mTV7t/vIAdLLOvkgQxRMd4+f1tmD0el4LQczPByhKuR7Dd+Lo/esicLZQctVDv/XpJMDh/QyxcCgUBqBSsDfR0E+HuiUCjC1RuP98k5e/EO3p87EoP6+GH9pt+lynN2tIKHmx1i49Nb/CRyQNKjYGxpiszENGSnZFZbwer+Ncky7q5+HjWWpamliVbeLoi9E424sAdw8WstlX+vqqzH6eWPgnN5S+IW5kpepqg30Jy5xsimreTvkxRyF+KKCqlVpEqLREi7+wAa2lqwbO38zHIsPVygrqWJtLsPUFokklrBSlxRgaSQuwAA27aP21ZZ126p+IpJ9RqkDfz9/TFy5EisX7++IYp/ruJS8nH+eiJa2Rhi8kvSPTfzJneAvq4mDp+JRlHx4zeqrg7GcHWQ3TMCAP5treHuKH8CeaWrt1NwPy4HXXxs0L9rq6p0gQBYNMMfABB0tGXPB0kpEuFGRjasdXWkJnIDwEQ3R+hqqOOfZOkJ3Q56unCQ0zNSF3eyJYHMCCf7qgntlYY42MBSRxtZxSWIL2iZk/oSC0W4kpoNO30dvPLUW+1Z3o7Q01DH3/FpUkPPHA104WhQvW0CHa2w3N8DqUXFmHPu2QEHAIRk5iEqpwB+FsbobSv9RW2YszVcjPQQX1CEu9ktrwdKERoa6vBws6u2jG1MbBpO/hsCZ0crvD5tkFTeigWjYaCvgz0HL0BY9Li9zl8OR8S9BPTq5o2hAztVpQsEAqxaItnUbMsvpxrwbpoOgUAA/xd7AABObPsDFU88x+5euo3YO9GwdLSBk4+b1Hk5aVlIj09FyVPzlToPlZR1eucRlJaUVqUnRsUi7NwN6BsbwLtn+6p0B28XqKmrIS7iAe7fuCtVVm56Nq4fuwgAcG1fc9DTXBjZWMLOzwsF6ZmI+PucVN7NfUdQVlwCt16doanzeG+anMQU5CRKr/CmqaMNt95dUFZcgpv7j0rlRRw/h4L0TNj7eUvtSK7ItYkaE4H46cXVlWTfvn1Ys2YNbt68WfPBNXB/cbsSaqQ4RxtD7NswFBamujh5KRbR8bnw87REgJ8tHiTkYuy7R5CT//hD9f7RGQDk13v9e70w4gX3ajucy+LnaYFda4ZAQ10Nx/97iOS0QgS0t4WvhyWu3UnF1CXHUVKm2jfp3u+413xQA7LR1cFnnf1gqq2Fy2kZiC8sgoexIfzMTJBQKMSi4BCpeQN/DuwFABh28rxUOW1MjDDIXjK0Q0ddHT2sLZBdXIIbmY+XY/3qiTXTddTV8FlnP7gYGiC7uARX0zNRWFYON0MD+JmboLxCjHW3I3Dp0UaBqpBVoNqZc/b6Ovi+ty/MdLRwLikTsflCtDEzRCdLE8TlC/HauVDklTxum/9G9gQA9Dh0oSqto4UxvurZDuoCAf58mIK0ourDEQtKy7AvWnpzSDcjPWzs5QsDTXX8l5KF+IIiuBjqIcDGDMKycrzzXxjCatnL0hBuzNuksmsDwLBB/hg2WPLywtrSBIP6+uFBbCr+uyr5cpmZlY8lq34BADg6WCDy4reIjU+HV4+5UuW4OFnhn4OfwNrSGH/+HYy795PQub07+vZoi6joJPQb+SGycqSDu87t3XBs73Joamjg0NEriE/KQL8e7dDJzw0Xg+8icMIqlJTUba6Psm3/Z5pKr1+prLQMP7+/EfERMbBr3Qqu7T2Qm5aNOxduQV1DA9PXvAkHL2epc7Yv/hYPb9/H9LVvwcX3cc+FWCzGvjU/I/zCLVi0soZnl7YQ5hfizrmbKCspw7hlM+EV4CNV1tk9x/HP7mMQqAng0aVt1UTyiIuhKCkqhnd3X4xfPut5/CmqPCxQbc9KXko6jqz4AqLcfDj6+8LYwRrp92KRcicKRrZWGPrpAugYGlQdv33sWwCAGfs2SpUjyi/AkeVfIC85DbbtPGDh7oTchFTEXQuFjrEhhq5cULV0rqLXft7e9xuosmvXZO6lf1RdBbm+Cein6io8Fw22elVYWBg0m8luzHEp+Rg570/Mm9IBvTvZo4+/A9Kzi7D98B18u+dWnSaRGxloYUgP52dOIH9SSGQGRs37E/Mmd0DPDvYw0NNEYloBvv3lJr7ff1vlAUdjkFIkwoIrNzHJzQkdLczQycIM2cUl+D02EUEP4qomNNfEVlcH/e2kN7ky1daSSnsy6BCVV2BRcAhGODkgwMocfWytoCEQILe0FBdS0nEwNgH38lr2m/TEQhFmnb2F2d5O6GptigAbU2SKSrDvfiK23Y1DfmnNE/xt9LSh/mj+2DBn2XMHkgtF1YKO6DwhZv5zEzO9HNHFygQB1qbIKSnD33Fp+DkyvmreR0vl29YJU8b0kUpzdbKG66O9T2Lj06uCjmeJiU1Dz5eWYsW7YzCwrx8G9+uAlLRsbNx6DKu+OoAcGUNzgm9Fo+ew5VixYDT69/aFob4O4hIzsOqrA1i/6XeVBxyNiYamBqaumoML+0/h9r/XcenQWWjr6cArwBf9JgfCylH2/xOyCAQCjF48FVe8nXHzxBVc+fM8NLQ04NTODb3HD4ZjG5dq5/SdOAQ2LvYIPvof4sNjcO9qODS1NWHtbAvfFzrDf0h3Zd5uk2BkY4lhaxbh5r6/kHgrAgk370DX1AhtXuyL9qNfhLZB7SZy6xga4KVV7+Lm/mOICw5BakQ0tA310bpvN3QYNxT65qYNdu2WSE3QIO/YqQ4U7ukIDg6WmZ6bm4uLFy9i7969CAwMxIYNG+pVQUD1PR30bKru6SD5VN3TQfKpuqeDnq2x9HRQdaru6SD5GnNPx/zLZ1RdBbm+6vaCqqvwXCjc0zFlyhSZS+ZWxjA9e/bEsmXLFK8ZERERERE1CwoHHatXr64WdAgEAhgbG8PZ2RkuLtW7aYmIiIiInjduDqh6Cgcdo0aNUmY9iIiIiIiomVJ4ydwlS5YgJCREbn5oaCiWLFmiaPFERERERNRMKBx0HDp0CHFxcXLzExIScPjwYUWLJyIiIiJSCrVG/NNSNNi9CoVCaGg02Iq8RERERETURNQpKkhKSkJiYmLV7w8ePJC5dG5ubi6CgoLg5ORU/xoSEREREVGTVqeg4+DBg9i4cSMEAgEEAgG+//57fP/999WOE4vFUFNTw+rVq5VWUSIiIiIiRXD1KtWrU9AxYMAA2NvbQywWY+nSpRg7diw6dOggdYxAIICenh58fHxga2ur1MoSEREREVHTU6egw8vLC15eXgAkO5K/8sor8PPza5CKERERERFR86DwTO81a9Yosx5ERERERA1CIBCrugotXr2XlyovL0dMTAxycnIgFldv0M6dO9f3EkRERERE1ITVK+jYunUrfvjhB+Tn58s9JiIioj6XICIiIiKiJk7hfToOHjyIzz//HB4eHpg/fz7EYjGmTZuGmTNnwsjICD4+Ply9ioiIiIiIFA869uzZAx8fH+zevRtjx44FAPTp0wcLFy7EH3/88czdyomIiIiInhc1QeP9aSkUDjqio6MRGBgIQLJMLgBUVFQAAKytrTFu3Djs3LlTCVUkIiIiIqKmTOGgAwAMDQ0BALq6ugAkO5FXcnBwQExMTH2KJyIiIiKiZkDhoMPa2hqJiYkAAG1tbVhaWiIsLKwq//79+zAwMKh/DYmIiIiI6kGtEf+0FAqvXtWxY0dcvHgR8+fPBwD0798fu3btgp6eHioqKhAUFISBAwcqq55ERERERNREKRx0jB8/HqdOnYJIJIKOjg7mzZuH0NBQbNy4EQDQunVrLFy4UGkVJSIiIiKipknhoMPX1xe+vr5Vv5uamuLgwYOIjIyEuro6XF1doabWkjqNiIiIiKgxUuOO5CpX7x3Jn+bp6ansIomIiIiIqAmrd9Bx7do1nD9/HpmZmZgxYwbc3NxQWFiI8PBweHp6wsjISBn1JCIiIiKiJkrhoKOiogILFy7E0aNHIRaLIRAIMHToULi5uUFDQwNz5szB7Nmz8dprrymzvkREREREddKSNuFrrBSedLF161YcPXoUixcvrgo8Kmlra2PAgAE4e/asMupIRERERERNmMJBx6FDhzB8+HBMnz4dpqam1fLd3NwQHx9fr8oREREREVHTp3DQER8fj44dO8rNNzY2ltqhnIiIiIhIFdQEjfenpVA46NDV1UVeXp7c/ISEBBgbGytaPBERERERNRMKBx2+vr44duyYzDyhUIhDhw7B399f4YoREREREVHzoHDQMXv2bISHh2Pu3LkIDQ0FACQnJ+PUqVOYMGECsrKyMHPmTKVVlIiIiIhIEeqN+KelUHjJ3G7dumHlypVYuXIlTp48CQBYtmwZAEBLSwuffvqp1I7lRERERESkXCdOnMCWLVsQFRUFTU1NdOrUCQsWLICHh0etzi8qKsKmTZtw9OhRpKWlwcrKCkOHDsWcOXOgq6urtHrWOuiYOnUq3njjDQQEBAAADh8+jG7duuH06dM4fvw4Hjx4gIqKCjg7OyMwMBDW1tZKqyQREREREUnbv38/li9fDg8PD7z33nsoLi7G7t27MX78eAQFBcHT0/OZ55eXl+PVV1/F1atXMXz4cHTu3Bl3797F1q1bERoaiu3bt0NNTeGBUVJqHXRcvXoVY8aMqfp9yZIl+OyzzzBs2DBMnjxZKZUhIiIiIlI2NYG45oOamNzcXKxduxY2NjYICgqCgYEBACAwMBBDhw7FqlWrsHPnzmeWcejQIVy9ehVTpkzB8uXLq9Lt7e2xbt06/PHHHxgxYoRS6lvr0MXS0hIJCQlVvz+5GSARERERET0/p0+fRkFBAcaMGVMVcACAnZ0dBg8ejCtXriA5OfmZZfz+++8AgBkzZkilT5w4ETo6Ojh8+LDS6lvrno6AgABs3rwZYWFhMDIyAgDs27cPFy9elHuOQCDA6tWr619LIiIiIiKqEhISAgDo0KFDtbwOHTrg0KFDuH37NmxtbWWeLxaLcfv2bVhZWcHe3l4qT0dHB97e3rh9+7bS6lvroGPJkiUQCAS4ePEiMjIyIBAIEBwcjODgYLnnMOggIiIiIlVrzJvw9e/f/5n5p0+flpmempoKALCxsamWV5mWkpIit9ycnBwUFRWhdevWMvOtra1x8+ZNFBQUSPWkKKrWQYepqSnWrVtX9buXlxc+//xzDBs2rN6VICIiIiKi2isqKgIgWTX2aZVpIpFI7vmVebLOBwBtbe2q6zzXoONpI0eOhKOjY70rQERERETUUsnryahJ5XK2JSUl1fIq03R0dOSeX5kn63wAKC4ulrpOfSkcdKxZs0YpFSAiIiIiakiNeXiVoiq3p0hJSYGbm5tUXuWwKllDryqZmJhAV1dX7hCs1NRUGBgYKKWXA6jHjuRERERERKQalZtw37x5s1rerVu3AAA+Pj5yzxcIBGjXrh3S0tKQmJgolScSiRAREfHM8+uKQQcRERERURMzYMAA6OvrY//+/SgoKKhKT0pKwvHjx9GlS5eqlauKiooQHR2NtLQ0qTKGDx8OANi+fbtUelBQEEQiUVW+Mig8vIqIiIiIqClQb4bDq4yNjbFo0SJ8+OGHmDBhAsaNG4eSkhLs3r0bALBs2bKqY0NDQzF16lSMHDkSa9eurUofNWoUDh8+jF27diE/Px/+/v6IjIzEnj170KVLF7z88stKqy+DDiIiIiKiJmj8+PEwMTHB1q1b8fnnn0NTUxP+/v6YP38+vLy8ajxfXV0dP/74IzZt2oRjx47hyJEjsLS0xIwZM/Dmm29CXV1daXVl0EFERERE1EQNGTIEQ4YMeeYxXbt2RWRkpMw8fX19LFq0CIsWLWqI6lVh0EFEREREzVpzXL2qqeFEciIiIiIialAMOoiIiIiIqEFxeBURERERNWtqArGqq9DisaeDiIiIiIgaFIMOIiIiIiJqUBxeRURERETNGlevUj32dBARERERUYNi0EFERERERA2Kw6uIiIiIqFlTV3UFiD0dRERERETUsBh0EBERERFRg+LwKiIiIiJq1rh6leqxp4OIiIiIiBpUk+jpmL6qlaqrQM+w67pY1VUgOTTU2TaN1fZ/pqm6CvQMM/rtUHUVSI6iuI9VXQUiUkCTCDqIiIiIiBSlJuBLOFXj8CoiIiIiImpQDDqIiIiIiKhBcXgVERERETVr6ly9SuXY00FERERERA2KQQcRERERETUoDq8iIiIiomaNmwOqHns6iIiIiIioQTHoICIiIiKiBsXhVURERETUrHF4leqxp4OIiIiIiBoUgw4iIiIiImpQHF5FRERERM0ah1epHns6iIiIiIioQTHoICIiIiKiBsXhVURERETUrKkLxKquQovHng4iIiIiImpQDDqIiIiIiKhBcXgVERERETVrfMuuemwDIiIiIiJqUAw6iIiIiIioQTHooBYr6n99IIy8WeNx8Z/PQ8Yf259DjahS+Mw+KLxbc9s8XDcPaYfZNs/bBPdAhF8OrfG4TyYuwm9f734ONSJq/AQCT5w9e6XG4/r2nYKPPvr2OdSoZVETNN6flkIpczpSU1Nx/vx5ZGVlwcLCAr169YKlpaUyiiZSGnFZGQQa8v/JV+bXdFxtyqK6Yds0bmWlZdDQlP83rcyv6bjalEXUXJSWlkJTU7PG/JqOq01ZRE1BnXo6PvvsM0REREilbdu2DQMGDMCKFSvwxRdfYOnSpRgwYAD27t2r1IoS1UdZfg5ilo5H1olfIS4rq5ZfcOs/PPxgCgrDgxG/YT5Sd61HeUFuteOKEx8gfv08ZP7Jt+vKUpaXg3uLxyPzuOy2yb/5H+4vm4KCO8F4+Nl8JO1YjzIZbSNKeICHn81D+u9sG2XKy8zBvH4z8NeWAygrrd4+105dxruD/ofQCzfw6eTF2LL8G+Rn51U7Lj7qIVZOWowD37Dng5q/9PQsuLoOwIYN21BaWlot/48/TsPLKxAnT/6Hfv2m4rXXPkBmZna148LCotCv3xR89NHG51FtogZVp6Bj27ZtuH//ftXvp06dwmeffQY7Ozt8+OGH2LJlC5YtWwYTExN88sknuH79utIrTKQIdQNjWI6Zg9x//0DsJzMhjJD82yxJTUDC14uQsm01jHq8CF23drAa+yZK0hIRs3wycs4eBsQVqCgqRNrebxH36WvQtLCDcZ/hqr2hZkTd0BjW4+Yg+98/EP3hTBSEP26buC8XIXHLapj0fBF67u1gM0HSNtFLJiPrn8NVbZOy51vEfPIatCzsYNqPbaNMhmbGmLxkNk7vPYb3X5qDsIuSYW/JDxOxbtYKbF64Hn3HDIJHxzaYsuxVpMQmYcHA2Tj5y18Qi8UQ5hdix6ffY9mIubBqZYMBE4aq+I6IGp6FhSnWr1+MH374FX5+w3H69CUAwL17sXjxxf9h6tTFmDnzFXTv3gFffrkE9+/HwsNjCDZv3oOKigrk5uZj/vxV8Pd/Ba6urfD66+NVfEdNn6qHUHF4FSAQi8W13qLRy8sLn3/+OYYNGwYAGDduHNLT03HkyBHo6upWHZeVlYXAwEB07doV33zzTb0r+enNU/UugxrOrutaqq5CrYnLy5B7/ggyj+xEeU4GBFraMOk3EmaBk6CubyR1bOGdYGQc+gnFsZGAQACDDr1hMXI2tGwcVVT7utNQV3UNak9cXobsc0eQ8edOlD1qG7MXRsLixUlQN5Bum4KwYKQd+AmiR21j2LE3rEbNhrZt02mbFb2Fqq5CnZSXlePMvuM4tCkI2amZ0NLRxqApwzD8tbEwMDGUOjb0/HXs3bADMWH3IBAI0HlQd4x7dzrsXB1UVPu6m9Fvh6qrQHIUxX2s6irUWllZGbZs2Y+VK79DUlIadHV18NZbk/D++6/CzMxE6tgTJy5g6dIvcP36HQgEAowaNQirVs2Hp6eraiqvEA9VV0Cu32KOq7oKco12GaLqKjwXCk8kr6ioQFhYGKZMmSIVcACAmZkZRo0ahRs3btS7gkRKJRAAamoQ4IlXC2rqkvSnD1V76n8PNTVAwLUXGoxAIPmbC55qG1mvgdTU8GQTCtTUJGnUYCT/66g9+WeX/C6jfdTU1Z5qRnWZxxE1dwKBAOrq6hA88T+Euro61GQ8r6ofpybzOKKmSuF/zUKhEOXl5XB2dpaZ7+rqipycHEWLJ1K6/Ov/4uGH05Fzaj+sZ7wPALAc9zaK4+8jZulEZP29FxWlxRDFRiHhy/eQ9MNHMO4RCN3WvjDpPxoaxmaI/XgGUndvQFlOporvpnnJu/YvopdPR+aJ/bCbKWkbmwmStrm/eCIyjkvapig2CrEb3kPi5o9g0jMQeh6+MBsgaZsHH8xA8s4NKGXbKN2V4xewMPB1HNt+CK9/9i4AYOry1xB39wHmvzATf235DSXFJYgJu48105fh67lr0OeVQfDq3A5Dpg2HiaUpFg+dg60ffIvstCwV3w3R83HgwN9o23YovvzyZ/z881oAwNdfL0NIyF24uQ3E+vVbIRIV48aNOxg8eBbGjp2PGTNGoVcvf8ybNxU2Nhbw9X0Zb7zxIZKT01R8N02fukDcaH9aijoHHZVRuIGBAQwMDJCXV33CIADk5eVBT0+vfrUjUpKy/Byk7/0Wxj2HwumDbdBv4w8A0LJ2gMO8z2AzfTFyzx5GUVQo0oK+hqa5NVw+3Q2TfiMBgRrUdPVhNX4uHJf9gJLkOOScOaDiO2o+yvJykBL0LUx6D4Xbx9tg0PZx2zi+8xnsZi5G9pnDEEaGIuUXSdu4rdkNsxcet43NxLlwWfEDipPjkHWabaNMeZk52Lnye/QbOxhr//oOPj06AABsne2xeOtKvLbmHZz85QjuXr2Nnz/ZDAt7K3xxcgsGTX4JAoEAeob6mLbidaw69DUS78fj751/qPiOiBpeenoW5s1bhdmzxyAk5HcMGNAdANC6tROOHv0J27atwnff7cG5c8F4++2VcHKyQ1TUccyZMwlqamowNjbE118vR3Dwb4iIeIBvv+UCDNT01XndwoULF2LhwoVVv4eFhWH48OoTN2NjY2FlZVW/2hEpiYahCVzW7JW7lKpB+57Qb9cNAg0N6Hl2kHuctr0rWi38WuYqS6QYDSMTtF4nv20MO/SEgY+kbfS95LeNjoMrnBezbZTNyNwEX5/9We4yt/4DA9C+b2doaGqgTTc/uce18nDGB3s+k7kCFlFzY2lphpiY03KXuR0+fABefLEPNDU10a9fV7nHtWvngbNnd8lcAYuoqalT0DFy5MhqaTo6OtXSSkpKcPr0afTq1UvxmhEpWU17N1Tm12aPB+4DoVxsm8atpn01KvNrs/8G9+iglqKmfTUq82uz/wb36Kg/TitTvTqtXlVbRUVFiI2NhYWFBSwsLOpdHlevatya0upVLU1TWr2qpWlqq1e1NFy9qvFqSqtXtTyNd/Wq32OPqboKcg13ClR1FZ6LBlkWQVdXF15eXlIBh1AoxMaNG5GQkNAQlyQiIiIiokbqua3FJhQKsWnTJsTHxz+vSxIRERERqXwDQG4O+ByDDgBogJFcRERERETUyHHXGSIiIiIialBcRoSIiIiImrWWNIypsWJPBxERERERNSgGHURERERE1KA4vIqIiIiImjV1Dq9Suefa0yEQsMWJiIiIiFoaLplLREREREQNSinDq0pKSpCdnQ1TU1NoaWnJPMbCwgJ3795VxuWIiIiIiGpNTcAX36pWr56OiIgITJs2DR07dkTfvn1x/fp1AEBmZiamTZuGixcvKqWSRERERETUdCkcdERGRmLixImIjY3F8OHDpfLMzc0hEolw+PDh+taPiIiIiIiaOIWHV33zzTewsLDAoUOHUFJSggMHDkjld+vWDcePH693BYmIiIiI6oN7RKiewm1w7do1jBkzBgYGBjJXpbKzs0N6enq9KkdERERERE2fwkGHUCiEsbGx3PyioiKuVkVERERERIoPr7K3t3/malTXrl2Ds7OzosUTERERESmFGreKUzmFezoGDx6Mw4cP4/bt21VplcOsDh8+jNOnTyMwMLD+NSQiIiIioiZN4Z6OV199FWfOnMHEiRPRvn17CAQCbNq0CWvWrEFUVBTatGmD6dOnK7GqRERERETUFCnc06Gvr4+goCBMmDAB9+/fh1gsRnBwMJKTkzFp0iTs2LFD7kaBRERERETPi7qg8f60FAr1dJSXlyM1NRV6enpYunQpli5diqysLIjFYpiZmclczYqIiIiIiFomhXo6ysrK0L9/f+zfv78qzczMDObm5gw4iIiIiIhIikI9Hdra2jA2Noa+vr6y69NoFWZmI2T/X0gKiUBxfiF0TYzQqrMffF95EdoGerUup7igEKEHjiE+OARFOXnQNtSHnZ83/Ma8BH1z02rHx16+gdSI+8h+mIDsuESUFong0rMzer41XYl31/RZ62lhXidn9HIwhYmOJtKEJTgdm4GNN+KQV1JWqzJm+Tigq50J3Ez0YKqjCbFYjMSCYlxMzMb22wlIFZbIPXewswXGeNmgnYUh9DTUkSkqQURmAX64FY+Q9Hxl3WaTZK2nhbc6OKOngylMtDWRLizBmbgMfHer9m0zo50DutiawM1Y0jYVYjGSCotxKTEbO+48u20qvebniLkdnQEAs46H4nJyTj3uqvkpLS7B+f2nEPbvTeSmZUFbTwfOPu7oNzkQlo42dSqrorwCl//4F7dOXkFmUgY0tTTh4OWE3uMHw7GNi8xzUmOScH7/KSRGxiIvMxe6hnowt7dE58AeaNOrPdTUWs7WXiNf7IJeXdvAt60TfLwdYWSoh6CDFzBz/qY6l2VvY4YV747BoL5+MDMxQEpaDv48cQ2rvjqAnNxCmed4tbbH8ndGo1c3bxgZ6CIuMQP7/7yE9Zt+h6i4tL631+yIRMX48cffcOTIeSQlpcHAQA9durTD3LmT4ObWqtblfPvtHmzcGCQ3/6efPkLv3p2qfr9y5TamTl1aY7lnz26Dra1lrevRXKkJuI2Dqik8kTwgIACXL1/GxIkTlVmfRik/JR3HP9wAUW4+HPx9YWxnjYzoWNw99g+SQsIx5OMF0DY0qLGc4vwCHP9gA/KS02DT1gPO3TshNykV0WcvI/HmHQz55D0YWltInXP70HFkxyZCQ0cbemYmKC0SNdRtNlmtDHWw9+X2sNDVwqmHGXiQK4SvpRGmtXNALwczTPjzFnKKa/5yO87LFsKycgQn5yJTVAINgQDeFgaY4eOA0Z42mHIkBBGZ0h/S6gJgXR8vDHO3QkyuEEcfpCO/pAyWulpob22EthYGLTroaGWog91DJW1zOjYDMblC+FgaYUpbB/SwN8Pko7eQW4u2GetpC2FpOa6l5iKzqAQaagJ4mRlgWjsHjPKwwfRjIbibJfsLFAB4mxvgDT9HFJaWQV9T4cdes1VWWoady75DXHgM7Fq3QtfhfZCXno07F24hKjgc09e8CQcv51qVJRaLsX/dDoRfuAULByt0GdYLRfmFuHPuJrYv+gbjls2EV4CP1DmRV8Kw99OtEAgE8OzmgzY9/SDMLUTEpVDsX7cDHW9FYfi88Q1w543T4rdHwq+tM/ILipCYnAUjw9q/2HqSi5MV/jn4CawtjfHn38GIjE6Cv5873poViIF9fPHCqI+QlVMgdU7n9m44tnc5NDU0cOjoFSQkZ6Jv97ZYNv8V9OvRFoETVqGkli8LWoKSklLMmLECN25EoF07d0yd+jJSUtJx/Ph/+Pffa9ixYxX8/DzrVObIkS/A3t66WrqTk63U7/b2VnjrrQkyy4iKeogTJy7Bw8OJAQc1Ggp/+i5cuBCTJk3Cl19+idmzZ8PQ0FCZ9WpUrmz7FaLcfHSePgZeQ/pWpV/beQARR8/g5q9/otts2f/jP+nm3j+Ql5wG76EvwH/KK1XpEcf+wbUdv+Hqtr3ov+QtqXP8p46GnpkJDG0skRp+DydXfq20+2ouPuzhDgtdLay8eB+7w5Oq0t/v6ooZPg54x98ZH/53v8ZyXjp4DSXl1d+EjPG0wae9PPCOvwte/TtMKu/tTs4Y5m6FzTfj8PX1h3j6bI0WPtxwRYCkbVZdvo89EY/bZlFnV0xr54B5HZ3xyaWa22b4YdltM9rDBh/38MC8Ti5442SYjDMBLXUB1vbyRFhGPuLyRRjuXv3DvKW7ePAfxIXHoE3P9hjz/rSqXoV2vTsiaOUWHP4qCHO+W1yr3oawf28g/MIttPJ2wbQ1b0JTSxMA0PnFHtj63tf445u9cPFrDW09napzTm7/ExXlFZix7m04+7hXpb8wdSg2v7UON/6+hD4TBsHEykzJd944LfpkFxKTsxD9MAW9unnjxL4PFCrn609nwtrSGAs++Bmbf/67Kn3dismY+7+h+GjROMxdurUqXU1NgB82vA59PR2MnrUeR05eByBZDv+XzfMw8sWumDv7Raz/7o/63WAzsn37Ydy4EYHBg3vgq68WVf0/EhjYC2++uQpLl36NP//cWKeeupEjB6BrV58aj3NwsMbbb8t+8btgwecAgDFjBtX6ukQNTeH+6ilTpkAkEuHHH39Ely5d0KNHD/Tv31/qZ8CAAcqsq0rkp6QjOTQC+pbm8BzUWyrPb8xQaGhr4cH5qygVFT+znFKRCA/OX4WGthb8Rg+VyvMa3Af6FmZIColAfmqGVJ5NWw8Y2VpxrowcrQx10MvBDAn5IvzyRMABAN/eiEVhaTledreGrkbN/9RlfakFgGMP0gEATka6UukWupqY5eOAm6l5+EpGwAEAZeKW253bylAHPewlbRMUId02G2/GQlhajmFu9Wub4zGy2+ZJ73Rygb2hDpZeiIS4BbeHPGKxGNeO/gcAGDTzZakvR14BPnBq64b0uBTE3o6uVXnBRyRl9Z86tCrgAAB7Dye0690RhbkFCL9wS+qc7JTMquFcTzI0M4KDpzMAQChnKFBzdO5SOKIfptSrDBcnKwzs44eHcWn4fscJqbyVX/yGgkIRJo7qCT1d7ar0Xt3awLu1A85fjqgKOADJv5Glq/cAAGZPavqf68oiFouxd+8xAMDChdOl/t8ZMKAb/P3b4v79eFy9KvuFSEPJysrFyZOXoKOjhREjXniu127M1ASN96elUDjosLOzg7u7O/z9/eHv7w9XV1fY2dlJ/dja2tZcUCOXEh4FALDz9YLgqTcVmro6sPR0Q3lxCTLuxTyznIx7D1FeUgpLTzdo6upI5QnU1GDn5y253p0oJda++etqZwIAuJCQXe1Lf2FpOW6k5kJPUx1+VkYKX+MFJ3MAQGSW9DCEwS6W0FJXw9EHadBWV8NgZwv8z7cVJnrbwtOs5cx3kqeLjQkA4GJS9bYRlpXjZpqkbXwtFW+bvq0kbRP1VNtU6mprgslt7PHV9RjE5XFooixZyRnITc+Gub0VTG3Mq+W7+0ueTQ9Can42lZaUIj4iBpraWnBs51otv3VVWfek0q0cbVAsFCH2jnRgU5CTj8SoWBiaGcHSkT1UddEnoC0A4NT50GrBdkGhCJeuRUJfTwddOj4O9Pp2l5xz4t+QauU9jEtDVHQSnFpZwsXJqgFr3nTExSUjKSkdzs72aNWq+rynyvkXly+H1qnc69fDsXXrQfz44284evQ8srJy63T+4cNnUFJSiiFDesLIqOah30TPi8LDq3bt2qXMejRaeUmpAAAjW9kPWSMbSySHRiAvOQ22Pl4Kl2NoI0nPT06rT3VbHFdjyRvuh3lCmfmxuUXo5QC4GOviclJOrcoc7WkDG31t6GmowcNMH93tTJGQL8KGYOnA0sdCMqRQR0Mdx0b7w95QOpg8HpOOxWcjISqvqONdNQ/OlW2TK6dt8orQwx5wNtLFlVpO6n6ltQ2s9bWhp6kGD1N9dLM1RWK+CF9crx70G2iqY1VPD1xPzZUadkfSMhMkzxxze9njvivTMxPTaywrOzkDFRUVsLAxh7q6erV8MzvZZQ15dSR++ehH7Fz6HTy7+cDUxhzCvELcvRQKHQNdjF40FZra3PepLjxcJS/97j+Q3WMSHZOCgX380NrFFmf/uyM5x63ynGSZ59x/mAIPNzu0drFFTCw/q2JiEgEALi52MvOdnCTpDx8m1qncr7/eLfW7lpYmZs0ahXnzJtVq1MO+fZKhdOPGDanTdYkaGmdU1qBEKHk7qqkne/hGZXqJsKiGcoqeWY5WVTmyv6CRbAZakn/C+SXlMvPzSyXphlq1/6c+xtMG7Z/oGQlNy8O7Z+9We1NurisZOjKvkzNupObizVN38DC3CK1N9fFBd3cMcbGEsLQcS861zN6ryr95gby2Kal727ziYSPVa3U7PQ+L/r2LuPzqvRhLu7nDWFsT04/V7S1jSyMqlDybdPR1ZObrPJp7UXncs8sSPbssfdllObVzw+wv3sH+Ndtx5/zNqnRtXW10GNgVVs6yv9SRfEZGksnnufmyP1Mq042NH/fKVk5Yl3dO3qOXOyZG7MkFgPx8yZA/AwPZfw/DR3/PyuNq4uXlgtWr56FLl3awsjJDZmYO/vvvJr76ajc2b/4VFRUVWLBg6jPLuHr1NmJiEuHh4YSOHb3rcDfNX0saxtRYMeggesq4P24BAEy0NdDGwgDvdHLGwREdMf90BC4kZlcdV/nCKbe4FK+fuIPCRwFOaHo+3jhxB3+P8cdwd2t8ee0h0mqxpCvVbOKRWwAAY20NtDE3wLyOztj3cke8+08E/kt63DYDnSww3N0aKy/dQ0IBh1X9s/tYtbT2A7vA1Lr6cCpViL5xF/vX7YBda0eMfHcyLBysUZCdh6t/nsfpHUcQdTUcMz57W2bvCVFD+vbbPdXSRo7sDwcH5Q/3GzgwQOp3OzsrjBkzGG3auGHcuIXYtu0Qpk8fDjMzY7ll/PqrpJdj7NjBSq8fUX0pHHR4eXnV2M0nEAgQHh6u6CUaBa1Hb/lK5fRkVKZryenBeFyO7jPLKakqR7GlEVuqgkdLNxpqyf4yYqgpSc9XYInHnOIyXEzMwe302zg2ujM+6+uJfnuvovjRcKnKMi8l5VQFHJXSi0oQkp6P7vam8LEwxOm4zDpfv6mr/PsYyGsbLcXbJre4DJeSchCWcRt/jeyMNb09MXC/pG2MtTTwQXd3XErKxt67soeJtDRn9xyvlubs6w5Ta3Po6EueTZW9FE8TCSt7L579jJMcU9mTIaeswuplCfMLsX/tDmhqa2L88lnQ0pEMozKztcCQV0ciOzUTdy/dRuiZa+gwsGuNdSCJyl4JYznL7Vam5z4xQT8v/9nnVPae5OS1nEn9svbN6NLFBw4O1jA0lPRwFBTI/nvkP/p7Vh6nqLZt3eHj0xo3bkTg1q1IvPBCF5nH5eTk48SJi9DR0cLw4f3qdU2ihqBw0DFixIhqQUdZWRni4+MREhICT09PeHs3/a49IzvJ24w8OXMt8lIkY5PlzdWobTn5KZJ0wxrKIWkPciXBmrOR7A9Jp0fzCmJyax4aIk9+STlupeVhoLMFWpvqISxDMmk5JqfoUb7sL815j/af0K7F6kzN0cPKtjGW0zZGlfNx6tk26XkY4GQBdxM93MksgK2BNsx0tBBgp4U7M3rLPG/rEF8AwNor0dgVXrfx1k3Rx0flL7Vt7iB55sibs1GZLm/Ox5NMbS2gpqaG7JRMlJeXV+uZyEqqXlZ8eAyKCoRw9vWtCjie5OLbGncv3UbS/XgGHXUQ9Whehrur7I0d3Vwk6fdiHgfmUdGV58heBMbdufo5zV1k5J9y81xc7AEAMTGy54zFxkrSnZ3t612Pyt6Nomfs1XX48GmUlJRi5MgXOIFchpb5Sdy4KBx0rF27Vm7etWvXMGfOHHz88ceKFt9o2LTxAAAkhd6FuKJCagWr0iIR0iOjoa6tBYvWsnfZrWTR2hnqWppIj4xGaZFIagUrcUUFkkLvSq7X1qMB7qL5uvJocnhPB1MIAKlVkvQ11dHR2hjC0nKEpOXV6zrWepIvQ2UVj69wMSkHb3Z0QmtT2W+x3E0lX7YTZMw3aAmupuQAALrbVW8bPQ11dLCStE1ounLapvzRCj05xWX4LUr2lyJ/a2M4G+vhXEIW0oTFuJfdct7YymNmawFjS1NkJqYhOyWz2gpW969FAABc/Wp+NmlqaaKVtwti70QjLuwBXPxaS+XfqyrrcXp5qSQ4l7ckbmGuJMhX1+DQqrr495JkcviAXr4QCARSK1gZ6OsgwN8ThUIRrt54vE/O2Yt38P7ckRjUxw/rN/0uVZ6zoxU83OwQG5/OSeSPODraws7OEg8fJiI+PqXaClbnzkmWHe7Wzbde1yktLUN4uGRlN1mrZFXat0+yNPLYsZxATo1TgwR+/v7+GDlyJNavX98QxT9XhjaWsPX1RmF6JiJPnJPKC9l/BGXFJXDt1QWaOo/XOs9NTEFuovSKIZo6OnDt1QVlxSUI+e2IVN7dv/9FYXom7Py8q+1ITs8Wny/C+YQsOBjqYFIb6cmmb3d0gr6mOv64n4qisscrSLka61atelXJVl+7amL408Z52cLXyghJBSJEPfEl9VpKLsIzCuBvY4wBTtJf1MZ42sDdVB8Pc4sQltEydySPzxfhv0RJ20zwlm6btzo4QU9THX9GS7eNi7EuXGS1jY7sthnjaQsfSyMkP9E2KYXF+PC/ezJ/bj0KPneEJeDD/+7hci1XzWrOBAIB/F/sAQA4se0PVFQ8bo+7l24j9k40LB1t4OTjJnVeTloW0uNTUSKSnq/UeaikrNM7j6C0pLQqPTEqFmHnbkDf2ADePdtXpTt4u0BNXQ1xEQ9w/8ZdqbJy07Nx/dhFAIBre76QkUVDQ7AMY1sAAFe2SURBVB0ebnbVlrGNiU3DyX9D4OxohdenSW8Qt2LBaBjo62DPwQsQFj3eY+r85XBE3EtAr27eGDqwU1W6QCDAqiWSDXC3/HKqAe+maREIBBg/PhAA8PnnP0v9v3Pq1GVcu3YH7u6t0KVLO6nzkpLSEB0dL9VrUVAgxIMHCdWuUVJSitWrf0JSUjpcXR3Qrp17tWMA4Nq1O4iOjucEcmrUGmwiuZubG/bt29dQxT9XXWeOw/EPNyD45/1IDouEsb0NMu4/ROqdKBjZWqHDuGFSx//x7koAwJS9m6TSO4x/Ganh9xBx5AyyHybA3N0ZuYkpSLgWCh1jQ3SZMa7ateOCQxAfLFkzXZQr+cKUHhWD/77bCQDQMTRApymjlH7PTcnH/93H3pfbY0V3dwTYmSA6Rwg/KyN0szNBTI4QX157KHX8sTGdAQCeWx4HkW0sDPB1f2/cSs1HXF4RMopKYKKjifZWhvA0M0BhSRkWnY1ExVMbTrx/LhK7hvri2wFt8E9cJh7mFsHdVB99WpmhsLQc7/9b/ZyWZOWl+9g9tD2WdXNHN1sTPMgVwtfSCF1tTRCTK8TXNx5KHf/XKEnbtN3+uG28zQ3wRT9vhKRJ2iZTVAITbU34Wj5qm9IyvH+uZf+d66v7qH6IunoH4Rdu4ad3MuHa3gO5adm4c+EWNLW1MGL+hGo7Kh/a8Ase3r6P6Wvfgovv456Ldn06IvxiKMIv3ML3b38Ozy5tIcwvxJ1zNyGuEOPlueOrVsQCACNzY/SZMBj/7D6G3R98D48ubasmkkdcDEVJUTG8u/vCo3Pb5/b3ULVhg/wxbLA/AMDa0gQA0LVTa/y44XUAQGZWPpas+gUAYGdjipB/NiA2Ph1ePeZKlTNv+Tb8c/ATfPHJdPTr0RZ37yehc3t39O3RFlHRSfjos1+ljq+oEOO1d7/Hsb3LsWfzfBw6egXxSRno16MdOvm54WLwXXyz5WgD333TMmPGCPzzTzD+/vs/jBnzLgIC/JCcnI7jx/+Drq42Vq+eV+3/ncWLv8TVq2HYuXN11c7jOTn5ePHFOWjXzh1ubq1gaWmKrKw8XLkSioSEVJiaGuGLLxbK3dn8118l87Y4gVw+7rGseg0WdISFhUFTU/bbyabG0MYSL65ajJD9fyEpJBxJN+9A19QIXoH94PvKi9A2qN3kb21DAwxZ+R5CfzuK+GshSLsbDW1Dfbj17Qa/MS9B39y02jnZDxPw4NwVqbSCtAwUpEl2Lte3MGvxQUd8vgivHL6JuZ2c0MvBFL1bmSFdWIIdYQnYeCMOebWYqByeUYCdYYnwtzFGH0czGGtroKSsAvH5ImwNjcfOO0lIKay+63xkViFGHbqJNzs6oqe95NrZolL8cT8V392Mq9dckuYgPl+EcX/exFsdnCR/HwczpBeVYNedBHx3q3ZtE5FZgN3hiehkbYzerR61TXkFEvJF2B4Wj93hstuGak9DUwNTV83Bhf2ncPvf67h06Cy09XTgFeCLfpMDYeUof0jH0wQCAUYvnoor3s64eeIKrvx5HhpaGnBq54be4wfDsU31oah9Jw6BjYs9go/+h/jwGNy7Gg5NbU1YO9vC94XO8B/SXZm32+j5tnXClDF9pNJcnazh6iSZGxgbn14VdDxLTGwaer60FCveHYOBff0wuF8HpKRlY+PWY1j11QHkyBjSFnwrGj2HLceKBaPRv7cvDPV1EJeYgVVfHcD6Tb+jRIGFH5ozLS1NbN/+CX788TccOXIOP//8OwwM9NC/fzfMnTsR7u6OtSrHxMQQkycPRWjoPVy4cAO5uQXQ1NRAq1Y2+N//XsGMGSNgbm4i89zc3AL8/TcnkFPjJxA/vVVpLQUHB8tMz83NxcWLF7F3714EBgZiw4YN9aogAHx6k925jdmu69y0q7HiMPjGa0Vv7snTmM3ot0PVVSA5iuKa/nzR5qvxDoO8mn6k5oNUpIvlUFVX4blQuKdjypQpMpfMrYxhevbsiWXLlileMyIiIiIiJeDoKtVTOOhYvXp1taBDIBDA2NgYzs7OcHF59mpORERERETUMIqKirBp0yYcPXoUaWlpsLKywtChQzFnzhzo6ta891Jubi7++OMPnDt3Dvfv30dGRgYsLS3Rrl07vP7662jTpk2d6qNw0DFqVMueR0BERERE1BiVl5fj1VdfxdWrVzF8+HB07twZd+/exdatWxEaGort27fLXZigUkhICFavXo1u3bph/PjxMDMzQ2xsLPbu3YsTJ05gw4YNGDq09kPDFA46lixZgvHjx8PPz09mfmhoKIKCgrBmzRpFL0FEREREVG8tbfWqQ4cO4erVq5gyZQqWL19elW5vb49169bhjz/+wIgRI55ZhqurK44fPw4nJyep9JdffhmjRo3C6tWrERgYWGPwUknhfToOHTqEuLg4ufkJCQk4fPiwosUTEREREZECfv9dssHnjBkzpNInTpwIHR2dWn1Hd3BwqBZwAICHhwdat26NjIwMZGZm1rpODbZkrlAohIZGgxVPRERERNTk9e/f/5n5p0+frlN5YrEYt2/fhpWVFezt7aXydHR04O3tjdu3b9e5npUqKiqQnp4OTU1NGBkZ1fq8OkUFSUlJSExMrPr9wYMHMpfOzc3NRVBQkMzoiIiIiIjoeVJ4aE8TlJOTg6KiIrRu3VpmvrW1NW7evImCggIYGBjUufxffvkF6enpGDlyJLS1tWt9Xp2CjoMHD2Ljxo0QCAQQCAT4/vvv8f3331c7TiwWQ01NDatXr65L8URERERELUpdezJqIhKJAABaWrL3UasMFIqKiuocdFy5cgXr1q2Dg4MD3n///TqdW6egY8CAAbC3t4dYLMbSpUsxduxYdOjQQeoYgUAAPT09+Pj4wNbWtk6VISIiIiKimpWXlyMrK0sqTVNTEzo6OgCAkpISmecVFxcDQK2WzX3S9evX8frrr8PMzAzbtm2DiYlJnc6vU9Dh5eUFLy8vAJIdyV955RW5q1cRERERETUGAoFY1VVQuuTk5GrzQbp06YKdO3dCV1cXKSkpMs9LTU2FgYFBnXo5goOD8eqrr8LY2Bg7duxQaAqFwjO9uRQuEREREZFqWFpaYvv27VJpRkZGEAgEaNeuHYKDg5GYmCg1mVwkEiEiIqLaSKVnuXz5clUPx44dO9CqVSuF6lvv5aXKy8sRExODnJwciMXVo8jOnTvX9xJERERERPQEbW1tdO/eXWbe8OHDERwcjO3bt0vt0xEUFASRSIThw4dLHZ+Wlob8/HzY2dlJDbu6dOkSXn/9dVhZWWHHjh2ws7NTuL71Cjq2bt2KH374Afn5+XKPiYiIqM8liIiIiIjqpYXtDYhRo0bh8OHD2LVrF/Lz8+Hv74/IyEjs2bMHXbp0wcsvvyx1/BdffIFDhw5h586d6Nq1KwDg9u3beP3111FWVoYxY8bIXLF24MCB0NPTq1WdFA46Dh48iM8//xz+/v7o1asXvvzyS0yfPh3q6ur47bff4OTkhAkTJihaPBERERERKUBdXR0//vgjNm3ahGPHjuHIkSOwtLTEjBkz8Oabb0JdXb3GMu7du1e1EtaGDRtkHnP69OlaBx0CsawxUbUwevRoCAQC7N+/H9nZ2QgICMD27dsREBCA1NRUDB8+HIsXL8bIkSMVKV7KpzdP1bsMaji7rsteko1UT6PmZwqpyIreQlVXgZ5hRr8dqq4CyVEU97Gqq0Byeai6AnLdyvxL1VWQq735S6quwnOh8F4p0dHRCAwMBCBZJheQ7FAISDYdGTduHHbu3KmEKhIRERERKU4gaLw/LUW9Nmg0NDQE8Hid39zc3Ko8BwcHxMTE1Kd4IiIiIiJqBhQOOqytrZGYmAhAMnve0tISYWFhVfn3799XaGt1IiIiIiJqXhSeSN6xY0dcvHgR8+fPBwD0798fu3btgp6eHioqKhAUFISBAwcqq55ERERERAppQaOYGi2Fg47x48fj1KlTEIlE0NHRwbx58xAaGoqNGzcCAFq3bo2FCxcqraJERERERNQ0KRx0+Pr6wtfXt+p3U1NTHDx4EJGRkVBXV4erqyvU1Oo1ZYSIiIiIiJqBeu9I/jRPT09lF0lEREREpDA1jq9SuXoHHdeuXcP58+eRmZmJGTNmwM3NDYWFhQgPD4enpyeMjIyUUU8iIiIiImqiFB7/VFFRgXfffRdTpkzBDz/8gAMHDiAtLQ0AoKGhgTlz5iAoKEhpFSUiIiIioqZJ4aBj69atOHr0KBYvXoyjR4/iyY3NtbW1MWDAAJw9e1YZdSQiIiIiUpigEf+0FAoHHYcOHcLw4cMxffp0mJqaVst3c3NDfHx8vSpHRERERERNn8JBR3x8PDp27Cg339jYWGqHciIiIiIiapkUnkiuq6uLvLw8ufkJCQkwNjZWtHgiIiIiIqUQtKRxTI2Uwj0dvr6+OHbsmMw8oVCIQ4cOwd/fX+GKERERERFR86Bw0DF79myEh4dj7ty5CA0NBQAkJyfj1KlTmDBhArKysjBz5kylVZSIiIiIiJomhYdXdevWDStXrsTKlStx8uRJAMCyZcsAAFpaWvj000+ldiwnIiIiIlIFjq5SvVoHHVOnTsUbb7yBgIAAAMDhw4fRrVs3nD59GsePH8eDBw9QUVEBZ2dnBAYGwtrausEqTURERERETUetg46rV69izJgxVb8vWbIEn332GYYNG4bJkyc3SOWIiIiIiKjpq3XQYWlpiYSEhKrfn9wMkIiIiIioseLwKtWrddAREBCAzZs3IywsDEZGRgCAffv24eLFi3LPEfy/vfsOi+JqowB+ZulKERAQsKCoWMGuaIw19m7svRF7jRpL8iWxJbG3WDGxRGM39tiiUbGAoljAhiDSVJAqfef7g7BhAwgsLDuw55eHJzIzO3uXw87yzr1zRxCwdOnSgreSiIiIiIiKrTwXHfPmzYMgCPDw8MC7d+8gCAI8PT3h6emZ42NYdBARERERUZ6LDnNzc/z444+K72vUqIHly5eje/fuamkYEREREVFhkHF8lcapfJ+O3r17o2LFioXZFiIiIiIiKoFUvk/HsmXLCrMdRERERERUQqlcdBARERERFQccXaV5Kg+vIiIiIiIiygsWHUREREREpFYcXkVEREREJZog8KbWmsaeDiIiIiIiUisWHUREREREpFYcXkVEREREJRpnr9I89nQQEREREZFaseggIiIiIiK14vAqIiIiIirRBI6v0jj2dBARERERkVqx6CAiIiIiIrXi8CoiIiIiKtF4ll3zmAEREREREakViw4iIiIiIlIrDq8iIiIiohKNs1dpHns6iIiIiIhIrVh0EBERERGRWnF4FRERERGVaBxdpXnFoujQ1xE13QT6iAejS2m6CZSDhNQITTeBcrDJV0fTTaCPSHj1naabQDkwqvg/TTeBcpDwap+mm0ASxuFVRERERESkVsWip4OIiIiISFWcvUrz2NNBRERERERqxaKDiIiIiIjUisOriIiIiKhE4+gqzWNPBxERERERqRWLDiIiIiIiUisOryIiIiKiEk3G8VUax54OIiIiIiJSKxYdRERERESkVhxeRUREREQlGkdXaR57OoiIiIiISK1YdBARERERkVpxeBURERERlWiCIGq6CVqPPR1ERERERKRWLDqIiIiIiEitOLyKiIiIiEo0zl6leezpICIiIiIitWLRQUREREREasXhVURERERUogkcX6Vx7OkgIiIiIiK1YtFBWstApzGuXL6T63aftf0Ci77bWgQtogxlDDrh6pX7uW7X9bPZWLZodxG0iKh4EAQnXL58K9ftWrcehm+/XV8ELSIiSseig7RGSkpqntbntl1et6G8YzZEqklJScnT+ty2y+s2RMWVIOEvbVHgouP9+/dYvXo1Bg4ciE6dOmHo0KFwd3dHUlJSYbSPqFC8ffseNar2xOpVe7L9o/TE8SuoW+tzXDh/Cx3ajcfE8UsRERGVZbtHD5+jQ7vx7PkoRO/eRqFejZFYv/pwttmcPnEDjeuOw18X7qJ7hzmYPnEtIiNismz3+FEAunWYgx8W7SmKZhNp3Nu3kahSpT1WrtyRbcFw/PhF1KjRGefPX0ebNsPxxRffICLifZbtHj58ijZthuHbbzcURbOJSEvlq+iYN28exowZo/g+ODgYvXr1wtatW3Hv3j0EBATAy8sLK1aswKBBgxAfH1/oDSZSRdmyZfDDT9OwfetRNKo/GJcu3gYAPH/2Cj26TsOYkd9i5KgecG3ujOUrZ+DFiyDUqfE5tmw6BLlcRHR0HGbNWAnXJiNQubI9xn3RR8OvqOSwLGuGRT+Mw6/bT+OTRhNx5ZI3AMD/eQj69fga48eswNCRHdDEtRaWLv8C/i9C0bDOGLhvOQm5XERM9Ad8NWsz2rhOgUPlchg1rquGXxFR0Shb1hwrVszFli374eLSExcv3gAAPHsWiC5dxmH48LkYPbovmjevj9Wr5+H580BUr94JmzbthVwuR3R0LKZPX4JGjfqiSpUKGD9+oIZfERGVZIIoimJeN+7QoQN69OiByZMnAwCmTJmCCxcuYPz48ejbty+sra0RGhqKPXv2YPfu3Rg9ejTmzJlT4Eb+5HO+wPsg9Zlex1zTTciz1NRU7Nj+B5YtcUdIyFsYGRlgwqT+mD13BCwszJS2PX/uJr5Z+DPu3vGFIAjo1bsNvls8AU5ODpppvAoSUiM03YQ8S01Nw64dZ7F82V6EhkTAyMgA4yZ0x4zZA2BuYaK07aXzd/D9N7/i3t1nEAQB3Xu1wNffjUA1pwoaan3+bfLl6FYp+8qlkqabkGepqanYvv0gFi36GSEhb2BkZIjJk4fgq6/cYGFRRmnbc+euYf78Vbhz5xEEQUCfPh2wZMl0ODlV0UzjVWBU8X+abgLlIOHVPk03IUcRicc13YQcWRr20HQTikS+PvXCw8NRrlw5AIAoivj7778xdOhQTJs2DeXLl4e+vj4qVaqEBQsWoHPnzvjzzz/V0mgiVQmCAB0dGYRMc+fp6Mggk2V9K6Rvh1y3o8IhCMg2G0GWdcQrsyH6V/pxTec/7x2dHI5r/92O7x0iKhr5OtLo6+srrtX48OEDkpKS0LRp02y3bdq0Kd68eVPwFhIVkqOHL6Fe3QFYt3Yftu34BgCwcvUs+Nx/hprVemPVyt1ITEyC910/dO00BUMGzsfwkd3xScv6mDx1IGzKWaJRvcGYPPEHhIa+0/CrKVn+OHoNzep9gZ/XHcXP22YCAH5YOR4PfV6ifs1RWL/qEBITk3HP+xn6dJ2PkUOWYsjwDnD9pA7GT+4FaxtztGg0ATMnr0dYaPHp3SEqqMOH/0Tt2l2xevWv+PXXHwAAa9cuwP37fnB0/AwrVrgjMTEJd+8+QseOY9C//3SMGtUHLVs2wrRpw1GuXFk4O/fAhAn/Q2goP7OJSH3yVXTUrFkTHh4eAIDSpUvD0tISgYGB2W4bEBAAMzOzbNcRFbW3b99j1oyVGDWmJ7y896Jd+/RiuWq1ijh+ai22bP8aWzYdwtW/vTFj2nJUrFQOD/0OYfyEfpDJBJiZGWPVmi/hcetXPPF7iZ837NfwKyo53r2NwrxZmzF8VCdc8/oZrds1AABUqWqHg8cXYcOWmdi+5SQ8rj7A3BmbUKGiDe48dMfY8d0hkwkwNSuFH1dNwCWPdXjy5BW2/izdLnSiwvT2bSSmTVuCsWP74f79P9C+fXMAQLVqlXD69Dbs2LEEP/+8F3//7YkpUxahUiU7PH16FhMnDoFMJoOZmQnWrl0IT89D8PX1x/r1nISBSi5BkO6XtsjXHckHDx6MGTNm4NChQ/j8888xYsQIbNq0CbVq1YKrq6tiu3PnzmHv3r3o0UM7xqiR9FlZmePJiz+gp5f9r3yPnq3QuUsL6OnponWbRjluV7tOVZy/tIXTshaislZlcP/Jrzn+zLv2cEWHzo2hp6eLlq1dctyuVm0HnDq/nNmQ1rCyssDLlxehp6eX7fqePdujS5dW0NPTQ5s2TXPcrk6d6rh8eTenzCUitcpX0dGpUyfcunULCxcuxN69e9GgQQPo6+tj9OjRsLa2hpWVFcLCwhAREQEbGxtMnTpVXe0myrec/lj97/rctsvrNpR3zIZINTkVEv9dn9t2ed2GiEhV+Zq9KsOxY8ewadOmbIdWGRkZoVOnTpg5cyasrKwKpZGcvUraitPsVdqmOM1epW04e5W0FafZq7QNZ6+SLinPXhWZdELTTciRhUF3TTehSKh0SrBXr17o1asXAgIC8OLFC8THx8PQ0BDlypWDk5MTDAwMCrudRERERERUTBVoHIKDgwMcHBzytO2HDx+wY8cO9OrVC+XLly/I0xIRERERUTFSZP37Hz58wMaNGxEUFFRUT0lEREREBEHC/2mLIh1UrMLlI0REREREVMzxSkYiIiIiIlIrzi1JRERERCWaIPA8u6YxASIiIiIiUisWHUREREREpFYsOoiIiIiohBMk/KUeCQkJWLFiBdq2bYs6deqgbdu2WLlyJRISElTe548//ggnJyfUqlUr348t0ms6BEF7pgUjIiIiItKEtLQ0uLm54fbt2+jZsycaN24MPz8/uLu7w8fHB7/88gtksvz1Pfj4+GDnzp0oVaoUkpKS8t2mIi06OGUuEREREZF6HT16FLdv38awYcOwcOFCxXJ7e3v8+OOPOH78OHr16pXn/aWkpGDBggVo06YNYmJicOfOnXy3qVCGVyUnJyM8PBzJyck5blO2bFn4+fnB1dW1MJ6SiIiIiChPNH0DwKK+OeAff/wBABg1apTS8sGDB8PQ0BDHjh3L1/62bNmCkJAQfPPNNyq3qUBFh6+vL0aMGIEGDRqgdevWiqonIiICI0aMgIeHR0F2T0RERERE+SCKIh48eABra2vY29srrTM0NETNmjXx4MGDPO/v2bNn2Lx5M2bOnAkbGxuV26Xy8KonT55g8ODBMDMzQ8+ePXHkyBHFOktLSyQmJuLYsWNo3ry5yo0jIiIiIirJ2rVr99H1Fy9ezNf+oqKikJCQgGrVqmW73sbGBt7e3oiLi4OxsfFH9yWXy7FgwQLUqVMHgwYNylc7/kvlomPdunUoW7Ysjh49iuTkZBw+fFhpfbNmzXD27NkCNY6IiIiIqOC0ZzKjxMREAIC+vn626w0MDACkz26VW9Gxa9cuPH78GEePHs33hef/pXLR4eXlhTFjxsDY2Bjv37/Pst7Ozg5v374tUOOIiIiIiEqy/PZkZEhLS0NkZKTSMj09PRgaGgJAjtdaZ8w8ZWRk9NH9BwUFYc2aNRgzZkyOvSb5oXLR8eHDB5iZmeW4PiEhgbNVERERERGpQWhoaJahWU2aNMGuXbtgZGSEsLCwbB8XHh4OY2PjXHs5li5ditKlS6Nr164IDAxULM/oSQkMDISOjg7Kly+fp/aqXHTY29vDz88vx/VeXl5wcHBQdfdERERERIVCEEre/bCtrKzwyy+/KC0zNTWFIAioU6cOPD09ERwcrHQxeWJiInx9fVG/fv1c9x8SEoJ3796he/fu2a7v0KEDypYti+vXr+epvSoXHR07dsSuXbvQp08fRYWTcfO/Y8eO4eLFi5gxY4aquyciIiIiohwYGBjkOGFTz5494enpiV9++UXpPh379u1DYmIievbsqbT9mzdvEBsbCzs7O8Wwq7lz5yImJibLvtevXw9/f3+sXr1acX1IXqhcdLi5ueHSpUsYPHgw6tWrB0EQsHHjRixbtgxPnz5FrVq1MHLkSFV3T0REREREKujTpw+OHTuG3bt3IzY2Fo0aNcKTJ0+wd+9eNGnSBD169FDaftWqVTh69Ch27dqFpk2bAkCOBc1vv/2Gly9folOnTvlqk8pFR+nSpbFv3z6sW7cOJ06cgCiK8PT0hKmpKYYMGYLp06fneNU8EREREVHR0Z7ZqwBAR0cHW7duxcaNG3HmzBmcOnUKVlZWGDVqFCZNmgQdHZ0ib5MgqnC1d1paGsLDw1GqVCmUKVMGABAZGQlRFGFhYaEYZlVYfvI5X6j7o8I1vY65pptAOUhIjdB0EygHm3xL3vjikuQrl0qabgLlwKji/zTdBMpBwqt9mm5CjmJSLmi6CTky1Wuv6SYUCZU+9VJTU9GuXTscPHhQsczCwgKWlpaFXnAQEREREVHxptLwKgMDA5iZmaF06dKF3Z5iITUpGT7HzsP/+h3EvYuEnpEhbGtXQ4P+XVGmfLl87UueJsfjM5fx9K+biAl9Cx19PVhXd0C9vp1g41Qly/ZvnwUg4PZ9RAYEI+JlEBKiY1HKogwGbVlcWC+v2EtMTIb7tuM4e/omQkLewdjYCI2a1MSkyX1RxdE+9x3k4P37WPTp8RXevYtC/QbVseu3rGfbRFHE4YN/4cjhy3j+/DUgApWr2KHv563xef+2Bb6xTnGXmJiMXe4XcO7sXYSFRKK0sSEaNKoKt0ldULlK/t47mUW9j8OgPj8g4l0MXOpXwbZd07PdLjzsPbZuPI0b130RHRWPslZmaNW2LsaO7wxTs1IqP39xFR/xHt77T+H1/cdIiv2AUuamqNjYGfU+7wID47z/PJLi4nHv0Bm88vTBh/cxMDAphfIutVB/QFeUtsy+J7SwnltbJCYmYevWQzh16ipCQt7A2LgUmjSpg6lTh8DRsUKe97N+/V5s2JDz2eht277Fp582VHx/69YDDB8+P9f9Xr68A7a2VnluR3HWu0sTtGxaC861K6FuzYowNSmFfUeuYfT0jfnel305C3w9qx86tHaBRRljhL2JwolzXliy5jCiouOzfUyNavZYOONztGxWE6bGRngV/A4HT9zAio1/IDEppaAvr8QStGx4lRSpfE2Hq6srbt68icGDBxdmeyQvLSUFZxdtQPgTf5R1rIhaXVoj/t17vLzpjaC7j9D5f1NhXc0hT/sSRRF/rfkFATe9YWZng1qdPkVS3Af4e9zBqftr0O7LsajU2FnpMS+ueeHR6cuQ6eigTPlySIiOVcOrLL6Sk1PgNmYZvO8+Re06VTBkWEeEhUXg/J+3cfXKPWz/ZT6cXaqqtO/v/+eODx8SP7rNV3N+xumTHrCwNEWXLq4wNDLADY8HWPTdL7jn/QxLf5yg0nOXBMnJKZji9jPue/ujZu2KGDCkFcLDonDxvDeuX32Mn7dPRh1nB5X2vez7/Uj4kPTRbV4HvcXYoWsQGRmLT9vUhUNlGzx6GIjf91zBjWu+2LZ7BsqU0Z4TKTFhb3Hq61VIjI5FxUbOMLO3wdvngXh8+jKC7/miy6IZMDT5+BzuAJAYG4dTC1chJvQNbOtUR+XmDREdHI5nl28iyPsRui2eBRObsmp5bm2RnJyCUaO+xt27vqhTpyqGD++BsLC3OHv2Oq5c8cLOnUvg4uKUr3327t0W9vY2WZZXqmSr9L29vTUmTx6U7T6ePg3AuXM3UL16Ja0pOABg7pTecKntgNi4BASHRsLURLUiuXIla/x15HvYWJnhxJ+eePIiBI1cqmLymM74rJUz2vb5FpFRcUqPaVzPEWd+Xwg9XV0cPX0Lr0Mj0Lp5bSyY3hdtWtRG50FLkJycWgivkqjwqVx0zJ49G0OGDMHq1asxduxYmJiYFGa7JOvhyUsIf+IPh2b10XbGKAj/nLmu4tkQF37aiqs/70GflfMVyz/G//odBNz0hrVTFXT+Zgp09fUAADU6fIKTX6/Gtc17YVunOvSNDBWPqda6Gaq2bgrz8rbQ0dOFe7/J6nmhxdSuX0/D++5TfNaxCVasmqLoWbjU2QvTJq/GNwu24sjxH/Ld43D82FVcOO+Jhd+MwuLvf8l2m4vnPXH6pAfsy1th34FFMDdPf0+kJKdixrQ1OHH8Gtq2a4T2HRoX7EUWU3t3/YX73v5o+1k9LF0xUpHBZ5fqY/a07Vj0zV7sO/JVvrM5dfw2/rpwH3MW9sNPiw/muN2Piw8iMjIWs77qiwFDWimWr/7pCPbtvoxN605i3jcDVHptxdEN9/1IjI5F01Gfo1bn1orlt3cexqNTf+HuvhNo7pb9H5uZ3dl3AjGhb1C7W1s0Gd5Hsfzx6cu49esh3Ni+Hx0WTFLLc2uLX345hrt3fdGxYwusWTNH8R7p3LklJk1agvnz1+LEiQ35eu/07t0eTZvWzXW78uVtMGVK9icXZ85cDgDo169Dnp+3JJjz/W4Eh0biRUAYWjariXMHvlFpP2sXj4aNlRlmfvMrNv36p2L5j18PxdRxXfHtnAGYOt9dsVwmE7Bl5XiULmWIz8eswKnzdwCk367gt03T0LtLU0wd2wUrfj5esBdIpCYqj/UYNmwYEhMTsXXrVjRp0gQtWrRAu3btlL7aty9ZF8aIogjfc9cAAE2G9lQqLCo1doZNTUdEvQ5D6OPnedqf77mrAICGA7spCg4AsKpaCVWaN0BiTBwCbnorPcaycnmUrVwBOnoq14slliiKOPD7RQDAzC8HKX0At23XCA0aOuHFi2B4efrma7+hIe/ww9Jd6NO3NT751CXH7S5e8AIAjBjZRVFwAICevi4mT/0cALBv77l8PXdJIYoijhxIv3nQlJk9lbJp1dYZ9Ro44uWLMNz1ytt7J0NYaCRW/nAYPfo0Q/NPauW43eugt7jl4Qdbewv0G9RSaZ3bpC4wMtLHmZOeufaWlBQxYW8Rct8PxlaWqNnxU6V19ft3ha6BPl5c9URK4sd/HimJSXjx923oGuijfr8uSutqdvoUxlYWCL7vi9jwd4X+3NpCFEX8/vsZAMDs2SOV3jvt2zdDo0a18fx5EG7fflik7YqMjMb58zdgaKiPXr3aFulza9rfNx7jRUD2d3rOq8qVrPFZKxcEvHqDzTuVPxcWrTqEuPhEDO7zCUoZ/XsPhJbNaqFmtfK4etNXUXAA6b8j85fuBQCMHVKy/u4qTIKE/9MWKhcddnZ2qFq1Kho1aoRGjRqhSpUqsLOzU/qytbXNfUfFSGzYO8S/ew8zW+sswwUAoEL99D96Qh8+zXVfqckpePPkJXQN9FGupmOW9eX/2VfIg9z3RemCXoUjNDQCDg62KF/eOsv6lv8UDLduPs7zPkVRxML5W2BsbITZXw356Lbv3kUBAMpXyPrcGcvu3nmCFC3s+n4d9A5hoe9R0cEa9uUts6xv3rImAMDr1rM871MURXy38DcYGxti+uzeH93W63b6fpu51shyNrh0aUM416+CxIRkPPAJyPPzF2dhj9J/HnYuNbL0yuoZGcK6RhWkJiXj7bOAj+7n7dOXSEtOgXWNKtDL1CMLAIJMBjuX9FxDH/17HCus59YWr16FIiTkLRwc7FGhQtbrnjKuv7h50ydf+71z5zHc3Y9g69ZDOH36KiIjo/P1+GPHLiE5OQWdOn0CU1MOhcuvVq61AQAXrvrgv5OIxsUn4obXE5QuZYgmDf4dDty6efpjzl25n2V/Aa/e4OmLEFSqYIXKlbJ+BhFJgcqny3fv3l2Y7SgWokLCAQCmdtm/oU3LpS+PDnmT675iw99BlMthYm0JWTZzJZv+Mz42JjT3fVG6gJehAIBKDtlfkFyxUvrywIDQPO9z986z8Lztiy3bv4KxcSlE53BhHwCU+ad3I/j12yzrXgel55iamoag129QpYpdnttQEgQGpL/+ipWyH/ddoWL68leBef9937f7Mu56Psf6LRNhbGyEmOgPOW77KuP5HbJ/71asaIVbHn54FfgGTZrlb2x8cRT9z7HMzDbnY1nIfT/EhL6BXd2cfx6578fqn+3e5OMxeXtubfHyZTAAoHLl7I8ZlSqlLw8ICM7Xfteu3aP0vb6+HsaM6YNp04bkaRbKAwfShwMNGJC/m4NRuupV0k/KPvfPvsfkxcswfNbKBdUq2+Ly9Ufpj3HMeEz2n2HPA8JQ3dEO1Srb4mU+jqVERUW7p9LJp5QPCQAA/VJG2a7XL5V+pi/5Q85//GRIznVf6cuT4xPy3U5tFRuX/nM3zuGiPuN/ZsSJjc09HwB48fw11q3Zj/4D2sG1eZ1ct/+0VX0AwK6dZxCd6eK/lJRUbNxwWPF9zEcKl5IqLjb999jYOPvf94zlsbF5+333fxGKTetOok//FmjimvsfpnGx6RMAlDY2zHZ9aRMjpXaWdLkff/45lsV//L2S/M/ECnq5Hcc+JGR6TOE8t7aIjU0/XhgbZz/JgYlJKaXtclOjRmUsXToNFy5sg4/PYfz1lzsWL54MU9PS2LRpP1avzv2E4u3bD/DyZTCqV6+EBg1q5vGVUGampum5RefweZSx3Mzs39wzLljP6TExMenLy5hqz4QY+SOT8Jd24IUB/3H3wKksy6q1bgYT66xDQqjo/Zzpj/cMPXt/Cnv7wp05JSUlFfPmbkJZqzKY+WXeLmjt3MUVJ49fw/VrPujZfQ7atG0IAwM93PR4iLfvomBra4nQ0AjIZCVz/ObWn09nWdatZ1PY2Rfueyc1JQ3fztsNy7KmmDKzZ6Hum0gT1q/fm2VZ797tUL581tmlCuqzz1yVvrezs0a/fh1Rq5YjBgyYjR07jmLkyJ6wsDDLcR/796f3cvTv37HQ20dEJZfKRUeNGjVy7YIVBAGPH+d9/LwUeB88k2WZbe1qMLG2VJzNy3zWLrOMs376pXKfPi+7M4DK+/rnbGDp7M8GaqtNG49kWda4SU3Y21vB5J+ejLgczgLF/dMTYpKH6Q23bz0OP99AuP+6AKVKZ392/L90dGRY//Ms7Pr1DE6euIbjx67CwEAPjZrUxKp10zFr2loAgIWlaZ72V9xs33Q2y7KGjavBzt4Sxhk9CXHZ/75nLDcxyf33/dft5/DELxib3CejVCmDXLcHAGOT9Azj47Kf8jg+oycmD89fEuR+/PnnWFb64++VjF6JlNyOY5l6NQrruUuS7O6b0aRJXZQvbwMTk/Sz1nFx2fdkZPTcZmynqtq1q6Ju3Wq4e9cX9+49Qdu2TbLdLioqFufOecDQUB89e7Yp0HNqs4xeCbMcPo8ylmce0hsT+/HHZPSeRMVoX286FQ8qFx29evXKUnSkpqYiKCgI9+/fh5OTE2rWLH7drmMObshxXRm79LNOMTlcsxETlr7cLIdrPjIzsSkLQSZD7JsIyNPSslzXEROafl2AaQ7jnrXVA9/fclznUDl9vGtgDrOKvApMX17JIfcJDnx9AyCKIkaPyP6mi953n6JuzSEwMSkFj9vbFMv19HQxZlx3jBnXXWn7pKRkBAaGwdzcJNuL3EuC2w/W5biu0j/XUrwKzHq9CwAEvUpfXjEPF0D6+b6GKIoYP3p9tuvve/ujSd2pMDYxwiWPH9P3m/H8Adm/d1/l4/lLArN/jmXROVwzlnEsy+34k/t+3v6znXU+HpO35y5Jnjw5keO6ypXTb2j68mVItusDA9OXOziofuPTDBm9GwkJOd+P6Nixi0hOTkHv3m15AXkBPP3nuoyqOdwU1bFy+vJnL/+9fuPpi4zHZP8ZVtUh62PoX3m5VonUS+Wi44cffshxnZeXFyZOnIjvvvtO1d1Lkkm5sihd1hzRoW8QG/4uywxWQd7pvTq2darnui9dfT1YO1VGuO8LhPm+gN1/HvP6n33Z1c19X5SuQkUb2NpaIiAgFK9fv8nyx/3Vv9Nn/GjaLOepVTO4utaBeZms95758CERZ8/chGVZM7RqVR+GRvp5atuZ0zeQkpKKzl1dc9+4BCpfoSzK2ZrjVcAbBL+OyDKDlcfV9GmMGzWtluu+mro6oYx51rO6CR+Scf7sXVhYmuCTVrVhaPhvNo2apO/35g0/yOVypRms4uMT4ePtD0MjfdRV8eaExU252uk/j5D7fhDlcqVZpFISEvHGzx+6BvqwyuVGp1bVK0NHXw9v/PyRkpCoNIOVKJcj5L4fAMC29r/HscJ6bm1RsaIt7OysEBAQjKCgsCwzWP39d/rUqc2aOWf38DxLSUnF48cvACDbWbIyHDiQPr1r//68gLwgrtxIvzi8fUtnCIKgNIOVcWlDuDZyQvyHRNy+++804pc9HuGrqb3RoZULVmz8Q2l/DhWtUd3RDoFBb3kROUmWWq5eadSoEXr37o0VK1aoY/caIwgCanb4BABwe88fEOVyxbpATx+E+75AmfLlYFtL+Y7XcW8jERUchtSkZKXlNTuk3y/gzu8nkZqcolj+9nkg/D3uwtDUGA5N66np1ZQ8giCg/8B2AIBVK/ZBnimfSxe9cPfOEzg62qNRY+UeuNCQd/D3D0FCwr/3BRg0pAO+Wzwuy9f0WQMBABUr2uC7xeMwb8EIpX1lDOHKzM83AKuW74OpWWmMGdej0F5vcSIIAvr0bwEAWL/qD6Vsrlzywb27L1DZsRwaNFJ+74SFRiLAPxyJCf++d/oN+hQLvxuc5WvS9PTepQoVrbDwu8H4ct7niseUr2CFps1rIDQ4Egf3XVV6jq0bTyMhIRmduzWGUR6HaxV3puWsYOdSA3FvI+D7599K67wPnEJqUjIcWzaGnuG/P4+o4DBEBSv3IuoZGsDx0yZITUqG90Hla3p8z/6NuLcRsHepqXSCRpXn1maCIGDgwM4AgOXLf1V671y4cBNeXo9QtWoFNGmiPNlFSMgbvHgRpNRrERf3Af7+r7M8R3JyCpYu3YaQkLeoUqU86tSpmmUbAPDyeoQXL4J4AXk+6OrqoLqjXZZpbF8GvsH5K/fhUNEa40co31zx65mfw7i0IfYeuYYPmT6Xrt58DN9nr9GyWU10/ayhYrkgCFgyL/3aw+2/XVDjqyEqGLVdSO7o6IgDBw6oa/caU6dbW7y68wgBN71xfH4E7Oo4Ie5dJF7e9IaugT5aThyaZe75Kxt2Iezxc3T5dqrSGb8qLRoi4NZ9BNz0xrE5P6Biw7pIio2Hv8cdiHI5Phk/OMsML1HBYfA5el5pWXL8B/y94d8ZR5oM7w1DLe32Hj6yC65c9sb5P29j8ID/oWmz2ggNfYfzf96GkZEBvl/iluU+DfO/2gwvT1/s2LkAjZvk3gvyMW5jfoCBgT6qViuP0qUN4e8fgqtX7sHAQA/rf/4S1tbmBdp/cTZ4eBtcu/IIl87fw6jBq9C4aXWEhb7HxfPeMDTSx9ffD86Szbfz9+Cu13Ns2jEFDRvn3gvyMXMX9sPYoWuw8ofD8Lz1FJWr2ODhg0Dcuf0MFR2sMWFqtwLtv7hxHTMAp75ehVu/HELog6cwK2+Dt88CEfboKUxtrdFgkPIQwaMz0ocajjqgPAS14aDuCHv0DI9OXkJkwGuUrVoJ0a/D8crLB4ZmJmg2pn+Bn1vbjRrVC3/95Yk//7yOfv1mwdXVBaGhb3H27HUYGRlg6dJpWd47c+euxu3bD7Fr11LFncejomLRpctE1KlTFY6OFWBlZY7IyBjcuuWD16/DYW5uilWrZud4Z/P9+9Ov29L2C8i7d2iE7h0bAQBsrMoAAJo2rIatK8cDACIiYzFvSfpQYLty5rj/10oEBr1FjRZTlfYzbeEO/HXke6z6fiTatKgNv+chaFyvKlq3qI2nL0Lw7U/7lbaXy0V8MWszzvy+EHs3TcfR07cQFPIObVrUQUMXR3h4+mHd9qwTelAGDq/SNLUVHQ8fPoSenl7uGxYzOnp66Pz1ZNw/eg7+1+/g4am/oG9kiEqNXdCgfxeYV8j7DREFQUCb6SPx+ExlPL10A4/PXIGOvi7K1aqKen07wcapSpbHJETF4NmVW0rLUpOSlZbV799Fa4sOfX09bHWfB/dtJ3DmlAd27zwDY2MjtGnXEJMm94Vj1fJqff7POjTBmdM3cOrEdSQmJsPaxhx9+7XBWLceKFdOu2dA09fXw4atk7DT/TzOnbmLfbv/QmljQ7Rq4wy3SZ1RxVG9NxMtX8EKO/d/iS0bTuPGdV94XH2MslamGDi0FcaO7wxTM+25cBlI73HovmwOvA+cRPA9X7z2fgQjc1PU6tIa9T7vAgPjvP08DE2M0W3JLHgfPINXnvcR7vsCBialUa11M9Qf0BWlLbMW2oX13NpCX18Pv/zyPbZuPYRTp/7Gr7/+AWPjUmjXrhmmTh2MqlUr5mk/ZcqYYOjQrvDxeYZr1+4iOjoOenq6qFChHMaN64tRo3rB0rJMto+Njo7Dn3/yAnIAcK5dCcP6tVJaVqWSDapUSr9eKTDoraLo+JiXgW/wSbf5+HpWP3zW2gUd29RH2Jv32OB+BkvWHEZUNtOre957gU+6L8TXMz9Hu0+dYVLaEK+C32HJmsNYsfEPJGvhzWep+BDE/94KM488PT2zXR4dHQ0PDw/8/vvv6Ny5M1auXFmgBgLATz7nc9+INGZ6He09ey91CakRmm4C5WCTr/bMzV4cfeVSSdNNoBwYVfyfpptAOUh4lXUmNqmIT/079400pLTup5puQpFQuadj2LBh2c4EkFHDfPLJJ1iwYIHqLSMiIiIiKgQCh1dpnMpFx9KlS7MUHYIgwMzMDA4ODqhcuXKBG0dERERERMWfykVHnz59CrMdRERERERUQqk8qHjevHm4f/9+jut9fHwwb948VXdPRERERFRIZBL+0g4qv9KjR4/i1atXOa5//fo1jh07puruiYiIiIiohFBbefXhwwfo6qptRl4iIiIiIiom8lUVhISEIDg4WPG9v79/tlPnRkdHY9++fahUiVMOEhEREZFmcfYqzctX0XHkyBFs2LABgiBAEARs3rwZmzdvzrKdKIqQyWRYunRpoTWUiIiIiIiKp3wVHe3bt4e9vT1EUcT8+fPRv39/1K9fX2kbQRBQqlQp1K1bF7a26r3DMBERERERSV++io4aNWqgRo0aANLvSN63b1+4uLiopWFERERERIUhuxtaU9FS+UrvZcuWFWY7iIiIiIiohCrw9FJpaWl4+fIloqKiIIpilvWNGzcu6FMQEREREVExVqCiw93dHVu2bEFsbGyO2/j6+hbkKYiIiIiICojDqzRN5ft0HDlyBMuXL0f16tUxffp0iKKIESNGYPTo0TA1NUXdunU5exUREREREaledOzduxd169bFnj170L9/fwBAq1atMHv2bBw/fvyjdysnIiIiIiLtoXLR8eLFC3Tu3BnAvzMCyOVyAICNjQ0GDBiAXbt2FUITiYiIiIhUJ0Am2S9tUaBXamJiAgAwMjICkH4n8gzly5fHy5cvC7J7IiIiIiIqAVQuOmxsbBAcHAwAMDAwgJWVFR4+fKhY//z5cxgbGxe8hUREREREVKypPHtVgwYN4OHhgenTpwMA2rVrh927d6NUqVKQy+XYt28fPvvss8JqJxERERGRijh7laapXHQMHDgQFy5cQGJiIgwNDTFt2jT4+Phgw4YNAIBq1aph9uzZhdZQIiIiIiIqnlQuOpydneHs7Kz43tzcHEeOHMGTJ0+go6ODKlWqQCbTnotjiIiIiIgoewW+I/l/OTk5FfYuiYiIiIhUljHTKmlOgYsOLy8vXL16FRERERg1ahQcHR0RHx+Px48fw8nJCaampoXRTiIiIiIiKqZUHv8kl8sxa9YsDBs2DFu2bMHhw4fx5s0bAICuri4mTpyIffv2FVpDiYiIiIioeFK56HB3d8fp06cxd+5cnD59GqIoKtYZGBigffv2uHz5cmG0kYiIiIioAAQJf2kHlYuOo0ePomfPnhg5ciTMzc2zrHd0dERQUFCBGkdERERERMWfykVHUFAQGjRokON6MzMzpTuUExERERGRdlL5QnIjIyPExMTkuP7169cwMzNTdfdERERERIVCUP08OxUSlRNwdnbGmTNnsl334cMHHD16FI0aNVK5YUREREREVDKoXHSMHTsWjx8/xtSpU+Hj4wMACA0NxYULFzBo0CBERkZi9OjRhdZQIiIiIiIqnlQeXtWsWTMsWrQIixYtwvnz5wEACxYsAADo6+tj8eLFSncsJyIiIiLSDO2ZJUqq8lx0DB8+HBMmTICrqysA4NixY2jWrBkuXryIs2fPwt/fH3K5HA4ODujcuTNsbGzU1mgiIiIiIio+8lx03L59G/369VN8P2/ePPz000/o3r07hg4dqpbGERERERFR8ZfnosPKygqvX79WfJ/5ZoBERERERFIlcHiVxuW56HB1dcWmTZvw8OFDmJqaAgAOHDgADw+PHB8jCAKWLl1a8FYSEREREVGxleeiY968eRAEAR4eHnj37h0EQYCnpyc8PT1zfAyLDiIiIiIiynPRYW5ujh9//FHxfY0aNbB8+XJ0795dLQ0jIiIiIioMgsDhVZqm8n06evfujYoVKxZmW4iIiIiIqARS+T4dy5YtK8x2EBERERFRCaVy0UFEREREVDyoPLiHCgkTICIiIiIitWLRQUREREREasXhVURERERUovHmgJrHng4iIiIiIlIrFh1ERERERKRWHF5FRERERCUch1dpGns6iIiIiIhIrVh0EBERERGRWnF4FRERERGVaILA4VWaxp4OIiIiIiJSKxYdRERERESkVhxeRUREREQlHM+zaxoTICIiIiIitWLRQUREREREasXhVURERERUogm8OaDGsaeDiIiIiIjUikUHERERERGplSCKoqjpRhARERERUcnFng4iIiIiIlIrFh1ERERERKRWLDqIiIiIiEitWHQQEREREZFaseggIiIiIiK1YtFBRERERERqxaKDiIiIiIjUikUHERERERGpFYsOIiIiIiJSKxYdRERERESkViw6iIiIiIhIrVh0EBERERGRWrHoICIiIiIitWLRQUREREREasWig4iIiIiI1IpFB5GaiaKo6SbQR2Tkw5ykRS6Xa7oJlIOMbJiRNDEfkioWHcUc/1CSroxsBEEAACQnJ2uyOfQfGR/IGfnEx8drsjmUiVwuh0wmQ3R0NIKDgzXdHMokLS0NMpkM7969w9q1axEWFqbpJlEmGflERUVh5cqVuHHjhqabRKSgq+kGkOrS0tKgo6ODxMRExMfHw9LSUtNNon9k/NEUFxeHv/76Cw8ePEBkZCTatm2L9u3bQ19fX9NN1GqZ/6jdv38/Hjx4gODgYHz++efo168f9PT0NN1ErZbxR1PLli1hbm6O3bt3o1KlSppultbL+Mx5+/YtunXrhlq1amHgwIGabhb9Qy6XQ0dHB+/evcPo0aORkpKC+Ph4NGvWTHFyhUiTBJGnyouljD+aIiIiMGbMGHz66acYNmwYrKysNN00rZeRzbt37zB16lT4+fkhOTkZqampAIBJkyZhypQpGm6l9sqcj5ubGyIjI2FsbIzY2FiEh4dj3rx5GDFihKabqfWOHj2KefPmQVdXF/b29ti8eTMqV66s6WZprcwFR9++fWFnZ4d58+bBxcVF002jTN6/f49BgwbB1NQU06ZNQ9OmTaGrm/X8siiKLESoyHF4VTEkiiJkMhliY2MxadIk+Pn5Yc+ePdi/fz/evXun6eZptYxsIiMjMWTIEMjlcnzzzTe4ffs2Vq9eDUdHR2zcuBHXr1/XdFO1UuZ8Bg8eDH19fXzzzTc4efIktm7dCjs7O/z222+Ij4/n0EUNK1euHACgW7dueP/+PSZMmICAgAAAHFZa1DLOoGcUHDY2Npg/fz6cnZ0BACkpKUhJSUFcXJzS45hT0RJFETt37oSuri5mzJgBV1dX6Orq4uXLl/Dz84OXlxfevHkDIH1YKa/5oKLG4VXFkCAISE5Oxvbt2/HkyRP0798f4eHh2Lx5MwBg4MCBKFu2rIZbqZ0EQUBSUhJ++uknGBsbY9asWWjYsCFkMhk6d+6MuLg4fP311/Dx8UGLFi003VytIwgC4uPjsXDhQpiamuLLL79E/fr1AQAVKlSAnZ0dypQpAwCIioqCubm54rE8M1h0RFGEk5MTqlWrhpYtW6JKlSpYt24dJkyYgJ9//hmVK1dWyiOj94rUQyaT4f379+jXrx/KlSuHZcuWoUKFChAEAdeuXcP58+fx5MkTpKWloWPHjmjTpg0cHR35filigiDg9u3bqFy5MlxdXQEAR44cwZo1axTFRvXq1dGtWze4ublBJpPxuEZFikfpYiooKAiXLl1CtWrVsHDhQsydOxctWrTA5s2b8fvvv7PHQ4MePXqEy5cvo1WrVoqCI2NoVZs2bWBkZAR/f38Nt1J7eXp6IiQkBL169UKDBg2go6MDAHj+/Dn8/f3h7e2NOXPmoEuXLpg2bRouXLgAAPxgLkKCIMDCwgJyuRyPHj3C2LFjMXHiRAQHB2PixIl4+fIlBEHA5cuXAYAFRxE4fPgwwsLCkJKSAgcHB+jr62Pnzp0YN24czp49i4SEBLx69QorVqzA4sWL4eXlpekmaxVRFBEREYHw8HA0bNgQAPDbb78peqTc3NwwePBgBAYGYtWqVVi9ejUAHteoaLGno5iysbFBt27d0KNHD+jr66NSpUqYNm0aBEFgj4eG6enpwdLSEn379lWcScoYU1uqVCkYGRlpuIXazcXFBZ07d8aAAQMUf6wGBQVh+vTpsLCwQPfu3VG9enU4ODhg7969CAgIgLW1tWIoCalfxvUDTZs2xePHjyGTyTB8+HAAwObNmzFx4kR07NgRmzdvxqJFi9CvXz8Nt7jk69evH2JjY7Flyxa4ubmhe/fuWL58OcaNG4euXbvCyckJ/v7+uHDhAtatW4e9e/eiXr162V5PQIVPEARYWlrCzMwM165dQ48ePXDo0CGMGTMGY8eOVfTaduvWDWPGjIG7uztq166NDh06aLjlpE14NCiGRFGEsbExxo4dCx0dHcUHdK1atTB16lQAUBQeAwYMUFxcHhkZiZSUFNjY2Gis7dqgbt26cHd3R7ly5bIdAiKTyRRn1zMkJiYCAAwNDYu8vdpELpfD3NwcX3zxBQAgNTUVcrkcc+bMgbW1NRYvXoyqVasCSO+VKleuHJYsWYK7d++y6ChCGe+P+vXr49ixYwgODoa9vT1Gjx4NmUyGDRs2YNu2bejVqxfat2+v4daWfHK5HGZmZhg7diwAwN3dHR4eHhgxYgTGjBkDMzMzAECVKlUwYMAAvHr1CocOHcKgQYPQuHFjTTZda4iiCLlcjlq1auHcuXPYv38/goOD0aBBA0XBkZqaigYNGmDp0qWYNWsWHj58yKKDihSLjmIo44/YjA9mHR0dxR+32RUeI0eORExMDDZt2oSUlBTMmTMHFhYWmmm8lsgo7DJ3XctkMhgaGkJPTw8pKSmK5VFRUdi3bx8SExMxfvx49oSo0X+H4WSchV28eDEMDQ1hb28PQPlMu0wmg4+PDwBeO1DUbG1tIQgCYmNjAaQX5fr6+khNTYWOjg7u37+PmJgYpWtvqPDJZDLI5XKYmJhg7NixSE1NhZ+fH7p06aIoODI+g8zMzODq6opDhw4hODiYRUcREQQBOjo6GDVqFM6ePYsdO3YAACpWrAgg/WL/jOOdi4sLTExM4O3tDVEUFRNsEKkbf8tKCEEQFDOF1KpVC1OmTMEnn3yCzZs3Y/369Vi3bh0OHjyISpUqseAoAjmNk01NTUVqaqriPhDv37/HgQMHsHbtWujp6bHg0ABRFOHo6KgoOERRVBT0ERER0NHRQbNmzQDw2oGi5uzsjDJlyiiuq/n111/x008/YeDAgRg9ejQCAgIwZMgQREdHa7ilJV/mwsPNzQ0TJkxQ6v3LfMzLuIbNzs6uyNupzeRyORwdHTFnzhxFsb5p0yYA6cN+09LSAABxcXHQ1dWFi4sLBEHgcY2KDHs6SpCMwkMQBNSuXRuzZ89GcnIydu7cCQCYNWsWxo0bB4Az8WiCKIpISkpCWloajI2NkZSUhP3792PNmjWYPn06xo8fr+kmaqXM74PM74s3b97gxIkTsLa2Ro0aNTTVPK2VkYWVlRVCQkJw9OhR/PDDDxg6dCimTZsGAwMDyGQyWFlZKc62k3plXKNmZmaGRo0aAcj6WRIeHo6LFy/C0dERtra2mmqqVsooHtq2bYuYmBhs27YNp0+fhqWlJRYsWABdXV2Eh4fj5MmT+PDhg+KCc6KiwqKjhMl88NfX14exsTEAKN3wjENENEMQBOjp6UEmkyEsLAw7d+7EmjVrMHXqVEXBwWw0K+P9ExQUhCNHjuCPP/7AvHnzeD2Hhujp6aFVq1ZYu3Ytjhw5gqFDh8LNzQ0mJiYAgMmTJyt6DfneKRofO1n1+vVrHD58GJcuXcLChQtRoUKFImwZZShbtiz69OkDc3NzLF++HLt374a3tzcqVqyI8PBw+Pj4YMqUKWjTpo2mm0pahnckL6HCwsKwdu1aHD16VKmHgx/MmpWWloYuXbogISEBb968wZQpUzBp0iQAzEYqTp48ievXr+Ps2bOYMGEC3NzcALB3UFNu3LiBtWvXwtXVFQMGDFDcNJB5SMuff/6JK1eu4MyZM3zfSEhAQADWr1+PZ8+eITQ0FPXq1UOXLl3Qu3dvAPzcoaLFoqOEevr0KebPn4/WrVtj8uTJAHhwkYKoqCh06dIFkZGR+OqrrzBy5EgAzEYK5HI5Xrx4geHDh8PS0hIjRoxQTMXKfDQrMDAQxsbGsLS01HRT6D/kcjn8/f0xatQo6Ovrw83NDQMGDFCs4/tGczJ+/ikpKdDT00N0dDRKlSrF3kHSGBYdJVRycjLCwsIUM1fw4CIdR44cQUpKCj+YJerJkycQBAHVq1cHwHw0iWfJiwdRFPH48WPI5XLUrVsXAN83UpL5fZTxb763SBNYdGgBHlykJeOsE8APZqnje4co//i+IaLs8K8diZHL5flanheZp9Ml1RVWNhkFB/DvbDBUcHzvSJc6sgHAbAoB3zfSxvcOlSQsOiQkNTVVcdY7JCQEd+7cQWBgIOLi4hRzpOdXeHg4gI/POEK5YzbSxnyki9lIF7ORNuZDJQ2HV0lExh2QAWD+/Pm4efMmQkJCUKpUKVSuXBnLli1TjDHPq61bt+LJkyeYO3curK2t1dFsrcBspI35SBezkS5mI23Mh0oi9nRIQOY7II8fPx5///03unbtit27d2Py5Mnw9/fH0KFDERQUlOd9bt26FatWrULdunU540sBMBtpYz7SxWyki9lIG/Ohkoo3B5SAjG7OHTt24NGjR/jyyy/Rvn17GBsbIzU1FXK5HG3btoW+vr7iMR+7UG/z5s1Yu3YtvvrqKwwZMkRx8KL8YzbSxnyki9lIF7ORNuZDJZZIkjFhwgRx8ODBYmRkpCiKoujh4SG6uLiIs2bNEkNDQxXbxcXF5biPTZs2iTVq1BB37NghJicnq73N2oLZSBvzkS5mI13MRtqYD5U0LDo0JDU1VRRFUZTL5aIoimJsbKzYsmVLccmSJaIoiuL169cVB5fw8HDF4/bs2SPOnDlTTEpKyrJPHlwKB7ORNuYjXcxGupiNtDEf0ga8pkMD5HK5onvzm2++wYsXL2BsbAwnJyfcvXsX586dw6RJk9CuXTvMnj1bccHX06dPcfz4cRgbGyMtLU1pn5s3b8aGDRswZ84cDB06VGlaVso7ZiNtzEe6mI10MRtpYz6kNTRd9Wiz2bNni05OTuKxY8dEURTF9evXi05OTmLt2rXFSZMmiUlJSYqzHmFhYeKqVavEVq1aiZcuXVLaz/Xr10UnJyfR3d2dZzMKCbORNuYjXcxGupiNtDEfKulYdBShjO5TURTFiIgIsWfPnuKBAwfE6OhoxXI3NzfRyclJnDJlihgYGCiKoijev39fXLx4sVi7dm1xx44d2e775s2bPLgUALORNuYjXcxGupiNtDEf0ja8T4cGfPfddzA1NcWVK1ewY8cOWFhYICUlBXp6eoiOjsaXX36Jq1evwtTUFNbW1oiMjIRMJsPo0aMxevRoAOndsTKZTGkubyo4ZiNtzEe6mI10MRtpYz6kLVh0FLGrV6/iiy++gJmZGWxsbLBv3z7o6ekpDhIZU97t3LkTL168QEBAAJo3b4569eqhWbNmAP49uFDhYjbSxnyki9lIF7ORNuZD2oRFh5qlpqZCV1f5dih79uzB9u3bERYWhm3btqFly5aKObZzO0vBg0vhYTbSxnyki9lIF7ORNuZD2oy/qWqWcXAJCAhQLBs6dCjGjx+P0qVLY/bs2bh79y4EQVC6C2kGuVyu9D0PLoWH2Ugb85EuZiNdzEbamA9pM/62FoH//e9/6NSpE3x8fBTLBg4ciC+//BIymQyzZ8+Gt7e34iCTGQ8o6sVspI35SBezkS5mI23Mh7QVf3uLQN26dWFnZ4cRI0bg/v37iuWDBg3CpEmTkJiYiFmzZuHevXvZHmRIfZiNtDEf6WI20sVspI35kNYqiimytFVaWpri3ydPnhTbtGkjOjs7i/fu3VPabs+ePWLLli3FTz75RPT09CzqZmolZiNtzEe6mI10MRtpYz6k7djTUYhSU1OVvs+Yvg4AunbtipkzZ8LS0hLDhw9X6lYdMmQIxo0bh/fv3yMwMLBI26wtmI20MR/pYjbSxWykjfkQ/Yemq56S6MSJE2JUVJTi+8w3ADpx4oTYvHlz0cXFRXz48KHS43x9fYusjdqK2Ugb85EuZiNdzEbamA9ROhYdhUAulyv+/dtvv4lOTk7iqlWrxJiYGMXyzAeZLVu2iE5OTmLDhg1Fb2/vLPvL3AVLBcNspI35SBezkS5mI23Mhyh7HF6VT+J/LuhKS0tT3LwnOTkZ7dq1Q//+/bF9+3Zs374dsbGxAAAdHR2kpKQAAAYPHgxHR0fo6upi4MCBePv2rdJ+OTuFapiNtDEf6WI20sVspI35EOWdbu6bUGaCICA5ORkPHz6Eg4MDLCwsAAAzZsxAzZo14ebmhnHjxgEAtmzZAgAYO3YsTExMoKenBwC4f/8+YmJiMHr0aJQtWxZWVlaaeTElDLORNuYjXcxGupiNtDEforxj0aECPz8/fP/996hXrx5mz56NyZMn49GjR+jduzcAoEKFCkoHGVEUMXjwYJQrVw4RERG4efMmnJ2dMWrUKMVBh3cVLRzMRtqYj3QxG+liNtLGfIjyhkWHCsqVK4eWLVti27Zt+Pvvv5GYmIhly5bB1dVVsU3GQUZHRwfbtm3DgwcPUKNGDYSFheH8+fOYM2eO4uACsPu0sDAbaWM+0sVspIvZSBvzIcobQfzvgETKk8jISPTp0wdhYWFo2bIlFi9eDBsbGwDKZygiIyNx4sQJbNq0CQkJCTAzM8Po0aMxcuRIAOnjQTPGf1LhYDbSxnyki9lIF7ORNuZDlDsWHfmUcUA4deoU3N3dYWtri0uXLmHw4MGYOHEiLC0tAWTtGg0ODkZycjIAoHLlytluQwXDbKSN+UgXs5EuZiNtzIco7zi8Kp8yzkB89tlncHZ2hiAIcHR0xLZt25CWloapU6fCwsJCceBISkoCANjb2yvtRxRFHlwKGbORNuYjXcxGupiNtDEforxj0ZEHaWlp0NHRUfpeX18fFSpUAAAMGjQIaWlp2LFjBwAoDjJxcXE4fvw4wsPDMWnSJOjr6yv2we7TwsFspI35SBezkS5mI23Mh0g1LDpykZqaCl3d9B/T6dOn4e/vj5SUFDRv3hxNmzYFANja2mLYsGEAgB07dkAURbRs2RJPnjzB+vXrMW/ePKWDCxUOZiNtzEe6mI10MRtpYz5EquM1HR+R+WzG1KlTce3aNaSlpUEulyMlJQXTpk3DwIEDYW5uDgAIDw/Hvn37sHnzZshkMhgYGGD8+PH44osvNPkySiRmI23MR7qYjXQxG2ljPkQFw6IjB5lnkJgyZQq8vb0xbtw4dO3aFTExMVi2bBmuXr2KL774AqNGjUKZMmUApI/XfPjwIfz8/FClShXFlHm8QKzwMBtpYz7SxWyki9lIG/MhKgQifdS2bdvE9u3bi0ePHhVjY2NFURTF27dvi/Xr1xfbtGkjOjk5iStWrBAjIiJy3EdaWlpRNVerMBtpYz7SxWyki9lIG/MhUh3L7I+IiorCo0eP4OjoiJYtW8LY2BheXl4YN24c2rVrhxUrVqBFixbYtm0b9u3bh/fv32e7H57NKHzMRtqYj3QxG+liNtLGfIgKSNNVj5QlJCSI7u7uop+fnyiKoujv7y82atRInDx5shgeHi6Koiju2bNHdHJyEp2cnMRvv/1WTEpK0mSTtQazkTbmI13MRrqYjbQxH6KC4exV/xAzjdfM+LehoSGGDRsGPT09JCYmYuPGjbC3t8ekSZOUbvhTq1YtODk5wcHBgTNSqAGzkTbmI13MRrqYjbQxH6LCx6IDyjNSpKWlISYmRjH7hJ6eHgBAX18fz549Q9myZVGjRg0AQFhYGO7du4cmTZpg8uTJMDY21swLKMGYjbQxH+liNtLFbKSN+RCph9YVHRlnLDL+n/ngsnbtWnh5eeHVq1dwcHDAgAED0KxZM1hYWCAxMRFJSUmIiIiAj48P9PT0cO7cOVy6dAlLlizhwaUQMBtpYz7SxWyki9lIG/MhKjpaN2VucHAw7O3tAShPWTdu3Dg8fPgQ9erVg729Pby9veHr64t+/fph5syZMDMzw59//ok5c+ZAJpPB0NAQSUlJGD9+PNzc3DT5kkoMZiNtzEe6mI10MRtpYz5ERUerejp27tyJgwcPYsOGDXBwcFAcXBYvXgxfX198/fXXaNu2LQwNDXHjxg3FXNsZ23Xs2BGWlpb47bffYG9vj3r16qF9+/YAOOd2QTEbaWM+0sVspIvZSBvzISpiRXXFuqadPHlSrF27trhu3Tql+bMjIiLEHj16iF9//bUYHR0tiqIoXr9+XaxXr544c+ZMMTg4WBTF9Hm1U1JSRFEURblcrrRvzrldMMxG2piPdDEb6WI20sZ8iIqeVpThCQkJOHLkCJo1a4YhQ4bAwsICABAXF4f379/jyZMnaNasGUxNTXHz5k1MnDgR7dq1w9y5c2FnZwcAOHLkCB4/fpzt/nk2Q3XMRtqYj3QxG+liNtLGfIg0QyveGbq6ukhNTUVoaChKly4NAJg4cSL++OMPxMfHK6a/u3XrFr744gu0b98ec+bMgbW1NQDg/v37WLp0KXx8fABAMY0eFRyzkTbmI13MRrqYjbQxHyLN0IprOvT09NCgQQNs3rwZP/30E548eYJHjx5h4MCBcHZ2Rq1atbB27VpERUWhY8eO+PLLLxUHl7CwMJw4cQK2traoU6eOhl9JycNspI35SBezkS5mI23Mh0hDND2+S90yj7WcOXOm6OTkJLq4uIhHjhxRLD948KDYtm1bsX79+qKHh4eYmJgoiqIoPn/+XFy7dq3o7Ows7t27t8jbXtIxG2ljPtLFbKSL2Ugb8yHSnBLf05G52zMmJgY6OjpITEzE3bt38emnn8LS0hIdOnTA69ev8dtvv2Hu3LlwcXGBqakpHjx4gNevX2PSpEkYNGgQAOW7lFLBMBtpYz7SxWyki9lIG/Mh0pwSX3RkCA8Ph5GREbZt24Z9+/bh4MGDEAQBEyZMgK2tLcaMGYNq1arh2LFjuHv3LgRBQNOmTTFhwgR07twZAKfAUxdmI23MR7qYjXQxG2ljPkRFT6tuDhgfH6+4aGzq1Kk4d+4cBgwYgPHjx8PW1lax3Zs3b6CnpwdTU1PFnUl5cFEvZiNtzEe6mI10MRtpYz5ERUurig5AuSt02rRp+PPPPzFgwABMnDgRNjY2Gm6ddmM20sZ8pIvZSBezkTbmQ1R0tK5MFwQBcrkcALB27Vp07NgR+/fvx5YtWxAeHq7h1mk3ZiNtzEe6mI10MRtpYz5ERUfrig4g/cY9mQ8yXbp0wd69e7Fy5UokJCRouHXajdlIG/ORLmYjXcxG2pgPUdHQmgvJ/yvjICOTybBq1SrExsaiVq1aMDIy0nTTtB6zkTbmI13MRrqYjbQxHyL107prOv4ru4vBOAWeNDAbaWM+0sVspIvZSBvzIVIfrS86AOUDCg8u0sJspI35SBezkS5mI23Mh0g9WHQQEREREZFaaeWF5EREREREVHRYdBARERERkVqx6CAiIiIiIrVi0UFERERERGrFooOIiIiIiNSKRQcREREREakViw4iIiIiIlIrFh1ERERERKRWLDqIiIiIiEitWHQQEREREZFaseggIiIiIiK1+j9JPonryJ9s5QAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "特征 2 和 特征 3 之间的相关性为 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### NN模型特征标准化"
      ],
      "metadata": {
        "id": "2qLX1YDsnQWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 StandardScaler 中针对每个通道（即每个特征）进行单独标准化，而不是直接对整个 X_train 和 X_test 标准化。"
      ],
      "metadata": {
        "id": "Wt8GSQJrnLpY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在标准化特征时，使用 训练集 来拟合标准化器（如 StandardScaler），并用其参数（均值和标准差）对测试集进行变换，这是一种 防止数据泄露 的必要操作。"
      ],
      "metadata": {
        "id": "lv4JTont8YZg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "标准化的正确流程：\n",
        "1. 用训练集计算标准化参数（如均值和标准差）。\n",
        "2. 用这些参数对训练集和测试集分别进行标准化。"
      ],
      "metadata": {
        "id": "OevE-1UY8cQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# # 因为对于每个特征i来说，正确的做法应该是用X_train的第i列的均值和标准差来标准化对应的测试集的第i列。\n",
        "# # 在同一个循环中，处理完X_train的第i列之后，处理X_test的第i列时，即对每个特征i，分别创建一个scaler实例，保存该特征的均值和标准差，然后在处理测试集时，用对应的scaler来处理对应的特征。\n",
        "\n",
        "# # fit_transform()：计算训练集的统计参数（均值和标准差）。根据这些参数对数据进行标准化。适用于训练集\n",
        "# # 仅用训练集数据拟合标准化器（避免数据泄露）\n",
        "# # X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "# # transform()：不会重新计算统计参数，而是使用 fit_transform() 计算出的参数对数据进行标准化。适用于测试集（或者未来的预测数据）。\n",
        "# # 使用训练集的标准化参数变换测试集\n",
        "# # X_test = scaler.transform(X_test)\n",
        "\n",
        "# # 对每个特征通道（即每列）分别进行标准化\n",
        "# # X_train 和 X_test 的形状是 (num_samples, 6)，其中 6 表示每个样本的特征数。\n",
        "# # 应为每个特征通道单独创建一个 StandardScaler 实例，确保测试集每个通道使用对应训练集通道的统计量。\n",
        "\n",
        "# # 初始化一个列表保存每个特征的标准化器\n",
        "# scalers = []\n",
        "\n",
        "# # 对 训练集X_train 中每个特征（通道）进行标准化\n",
        "# X_train_standardized = np.copy(X_train)  # 创建一个 X_train 的副本，避免修改原始数据\n",
        "# for i in range(X_train.shape[1]):  # 遍历每个特征（通道）\n",
        "#     scaler = StandardScaler()  # 为每个特征创建新的标准化器\n",
        "#     X_train_standardized[:, i] = scaler.fit_transform(X_train[:, i].reshape(-1, 1)).flatten()  # 对每个特征进行 fit_transform\n",
        "#     scalers.append(scaler)  # 保存当前特征的标准化器\n",
        "\n",
        "# X_train = X_train_standardized\n",
        "\n",
        "# # 对 测试集X_test 中每个特征（通道）使用对应训练集的标准化器进行标准化\n",
        "# X_test_standardized = np.copy(X_test)  # 创建一个 X_test 的副本\n",
        "# for i in range(X_test.shape[1]):  # 遍历每个特征（通道）\n",
        "#     scaler = scalers[i]  # 获取对应特征的标准化器\n",
        "#     X_test_standardized[:, i] = scaler.transform(X_test[:, i].reshape(-1, 1)).flatten()  # 使用训练集的标准化参数对测试集进行 transform\n",
        "\n",
        "# X_test = X_test_standardized\n"
      ],
      "metadata": {
        "id": "CyPjz0gX8XZd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 检查特征标准化之后的数据集的每个特征维度（即 6 个通道）的统计信息\n",
        "# for i in range(X_train.shape[1]):  # 遍历 6 个特征通道\n",
        "#     print(f\"训练集特征通道 {i+1} 的统计信息：\")\n",
        "#     print(f\"  最大值: {np.max(X_train[:, i])}\")\n",
        "#     print(f\"  最小值: {np.min(X_train[:, i])}\")\n",
        "#     print(f\"  均值: {np.mean(X_train[:, i])}\")\n",
        "#     print(f\"  标准差: {np.std(X_train[:, i])}\")\n",
        "\n",
        "# for i in range(X_test.shape[1]):  # 遍历 6 个特征通道\n",
        "#     print(f\"测试集特征通道 {i+1} 的统计信息：\")\n",
        "#     print(f\"  最大值: {np.max(X_test[:, i])}\")\n",
        "#     print(f\"  最小值: {np.min(X_test[:, i])}\")\n",
        "#     print(f\"  均值: {np.mean(X_test[:, i])}\")\n",
        "#     print(f\"  标准差: {np.std(X_test[:, i])}\")"
      ],
      "metadata": {
        "id": "wV-ed_UxuIeY"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "kC-g42jz8hW-"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 神经网络模型（NN模型）定义"
      ],
      "metadata": {
        "id": "qY26zkSm8nLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Activation\n",
        "from tensorflow.keras.initializers import HeNormal\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "\n",
        "# 使用 Sequential 模型，适用于线性堆叠的神经网络。\n",
        "modelNn = Sequential()  # build neural network\n",
        "\n",
        "# 输入层。\n",
        "# Dense(128, input_shape=(6,), ...)代表输入层，输入形状为 6,)，表示每个输入样本有 6 个特征。这个 6 是硬编码的，但实际上它应该等于特征的维度数，这里可能需要根据实际情况进行修改。\n",
        "# 如果特征数是动态变化的，建议不要硬编码这个数字，而是通过 features.shape[1] 获取动态的特征维度。\n",
        "input_dim = features.shape[1]  # 动态获取特征维度\n",
        "modelNn.add(Dense(128, input_shape=(input_dim,), kernel_initializer='normal', kernel_regularizer=l2(1e-4), activation='relu'))\n",
        "modelNn.add(BatchNormalization(axis=-1))  # 对每个通道进行标准化\n",
        "# # Dropout 层\n",
        "# # 使用 Dropout(0.5) 防止过拟合，随机丢弃 50% 的神经元\n",
        "# modelNn.add(Dropout(0.5))\n",
        "\n",
        "# 隐藏层 + BatchNormalization\n",
        "# BatchNormalization 层位置：通常建议在激活函数前使用 BatchNorm\n",
        "modelNn.add(Dense(256, kernel_initializer='normal', kernel_regularizer=l2(1e-4), activation='relu'))  # 先不加激活函数\n",
        "modelNn.add(BatchNormalization())\n",
        "# modelNn.add(Activation('relu'))  # 激活函数在 BatchNorm 后\n",
        "# 再次 Dropout\n",
        "modelNn.add(Dropout(0.5))\n",
        "\n",
        "modelNn.add(Dense(256, kernel_initializer='normal', kernel_regularizer=l2(1e-4), activation='relu'))\n",
        "modelNn.add(BatchNormalization())\n",
        "modelNn.add(Dropout(0.5))  # Dropout\n",
        "\n",
        "# 隐藏层 2\n",
        "modelNn.add(Dense(128, kernel_initializer='normal', kernel_regularizer=l2(1e-4), activation='relu'))\n",
        "modelNn.add(BatchNormalization())  # 添加 BatchNorm\n",
        "modelNn.add(Dropout(0.5))  # Dropout\n",
        "\n",
        "# 输出层\n",
        "# 输出层包含 1 个神经元，activation='linear' 表示线性激活函数，适用于回归任务。\n",
        "modelNn.add(Dense(1, kernel_initializer='normal', activation='linear'))\n",
        "\n",
        "# 打印模型的结构，包括每一层的类型、输出形状、参数数量等信息，帮助你了解模型的结构。\n",
        "modelNn.summary()\n"
      ],
      "metadata": {
        "id": "7TG9BKhk8ju6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 633
        },
        "outputId": "c080d939-07b6-4f93-fb63-714894048e84"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m33,024\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │          \u001b[38;5;34m65,792\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m32,896\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,792</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m135,809\u001b[0m (530.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">135,809</span> (530.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m134,273\u001b[0m (524.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">134,273</span> (524.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,536\u001b[0m (6.00 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> (6.00 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "metadata": {
        "id": "wyK0QPxn8OeH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcb89961-d7fc-436d-fc4e-0fecdbbdd5e2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "在 Google Colab 中运行代码时，如果你需要使用 TensorFlow Addons 提供的 CyclicalLearningRate，你需要先安装 TensorFlow Addons，因为它并不是 TensorFlow 的默认组件。但是TensorFlow Addons 支持的 TensorFlow 版本范围是 2.13.0 到 2.15.x，而你当前的 TensorFlow 版本是 2.17.1，超出了兼容范围。\n",
        "\n",
        "所以我使用Keras 内置的学习率调度器来代替 TensorFlow Addons。"
      ],
      "metadata": {
        "id": "Rt1_Xxj69C8W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 卸载当前版本的 TensorFlow：\n",
        "# !pip uninstall -y tensorflow\n",
        "# # 安装兼容版本的 TensorFlow：\n",
        "# !pip install tensorflow==2.15\n",
        "# # 重新安装 TensorFlow Addons（如果需要）:\n",
        "# !pip install tensorflow-addons\n"
      ],
      "metadata": {
        "id": "om-rtPeo88Dt"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 学习率调度"
      ],
      "metadata": {
        "id": "FgVLKd_V9BE0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "使用余弦退火策略，动态调整学习率。"
      ],
      "metadata": {
        "id": "EAhmfZnpqcnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# 调整学习率调度策略为余弦退火策略，然后将 lr_scheduler 添加到 model.fit 的 callbacks 中\n",
        "# 学习率在训练过程中周期性变化，有助于跳出局部最优。\n",
        "# 逐渐降低学习率，确保模型在后期稳定收敛。\n",
        "\n",
        "import math\n",
        "\n",
        "def cosine_annealing(epoch, lr):\n",
        "    # initial_lr = 1e-3  # 初始学习率\n",
        "    min_lr = 1e-5      # 最小学习率\n",
        "    max_lr = 1e-3      # 最大学习率\n",
        "    cycle_length = 50  # 每个周期的 epoch 数\n",
        "\n",
        "    # 计算当前周期内的相对位置\n",
        "    cycle = math.floor(1 + epoch / cycle_length)\n",
        "    x = abs(epoch / cycle_length - 2 * cycle + 1)\n",
        "    new_lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + math.cos(math.pi * x))\n",
        "\n",
        "    return new_lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(cosine_annealing)\n",
        "\n"
      ],
      "metadata": {
        "id": "H0RsaOcZYXkd"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型编译"
      ],
      "metadata": {
        "id": "d8rdXLPQ9E_Z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "损失函数使用 Huber Loss，对异常值更鲁棒。"
      ],
      "metadata": {
        "id": "JEnFNKOLrRIl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "自定义指标R2Score()，用于计算 R²（决定系数）"
      ],
      "metadata": {
        "id": "14wYZdvX4Lz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "# 在 R2Score 类定义之前添加装饰器 @keras.saving.register_keras_serializable()，让 Keras 能够处理该类的序列化和反序列化。\n",
        "@register_keras_serializable()\n",
        "class R2Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='r2_score', **kwargs):\n",
        "        super(R2Score, self).__init__(name=name, **kwargs)\n",
        "        # 定义需要追踪的全局变量\n",
        "        self.sum_y = self.add_weight(name='sum_y', initializer='zeros')\n",
        "        self.sum_y_squared = self.add_weight(name='sum_y_squared', initializer='zeros')\n",
        "        self.sum_residual = self.add_weight(name='sum_residual', initializer='zeros')\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # 确保 y_true 和 y_pred 是 float32 类型\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "        # 计算残差的平方和\n",
        "        residual = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "\n",
        "        # 计算真实值的总和和平方和\n",
        "        sum_y = tf.reduce_sum(y_true)\n",
        "        sum_y_squared = tf.reduce_sum(tf.square(y_true))\n",
        "\n",
        "        # 样本数\n",
        "        count = tf.cast(tf.shape(y_true)[0], tf.float32)\n",
        "\n",
        "        # 更新状态变量\n",
        "        self.sum_y.assign_add(sum_y)\n",
        "        self.sum_y_squared.assign_add(sum_y_squared)\n",
        "        self.sum_residual.assign_add(residual)\n",
        "        self.count.assign_add(count)\n",
        "\n",
        "    def result(self):\n",
        "        # 计算全局均值\n",
        "        mean_y = self.sum_y / self.count\n",
        "\n",
        "        # 计算总平方和 (TSS)\n",
        "        tss = self.sum_y_squared - (self.sum_y ** 2) / self.count\n",
        "\n",
        "        # 计算 R² 值\n",
        "        r2 = 1 - (self.sum_residual / tss)\n",
        "        return r2\n",
        "\n",
        "    def reset_state(self):\n",
        "        # 重置状态变量\n",
        "        self.sum_y.assign(0)\n",
        "        self.sum_y_squared.assign(0)\n",
        "        self.sum_residual.assign(0)\n",
        "        self.count.assign(0)\n"
      ],
      "metadata": {
        "id": "0SGQCYak4MP4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 损失函数：loss='mean_absolute_error' 使用绝对误差作为回归问题的损失函数。\n",
        "# 优化器：optimizer='adam' 使用 Adam 优化器，它是目前常用的一种高效的优化算法。\n",
        "# 评估指标：metrics=['mean_absolute_percentage_error'] 使用平均绝对百分比误差（MAPE）作为评估指标。\n",
        "\n",
        "# 注意: 在训练过程中，优化算法会根据 val_loss 来更新模型的参数，因为 val_loss 是损失函数的值，而损失函数通常是模型优化的目标。\n",
        "#    MAPE 作为评估指标，不会直接影响模型的参数更新，它仅用于评价模型在验证集上的相对误差，帮助你了解模型的实际表现。\n",
        "\n",
        "# 编译模型\n",
        "# modelNn.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_percentage_error']) #compile model\n",
        "\n",
        "from tensorflow.keras.optimizers import Nadam\n",
        "modelNn.compile(\n",
        "    # loss=tf.keras.losses.Huber(delta=1.0),\n",
        "    loss='mean_squared_error',  # 使用 MSE\n",
        "    optimizer=Nadam(learning_rate=1e-3),  # 使用 Nadam\n",
        "    # 备选 Adam，Adam 是更通用的选择，对学习率调参要求较低。\n",
        "    # optimizer='adam',  # 默认学习率 1e-3\n",
        "    # metrics=['mae', 'mape']\n",
        "    metrics=[\n",
        "    tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
        "    R2Score()\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "XRSIGjCG86Ob"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 早停机制"
      ],
      "metadata": {
        "id": "XI3SSgam9Hgx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "添加 EarlyStopping 回调，防止过拟合。"
      ],
      "metadata": {
        "id": "2UVmmGOXqzak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 早停机制\n",
        "# 如果 ReduceLROnPlateau 的 patience=5，建议 EarlyStopping 的 patience 设置为 2 * ReduceLROnPlateau 的 patience，即 10 或更高。\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',  # 监控验证集损失\n",
        "    patience=20,         # 在连续 20 个 epoch 验证集损失无改善时停止训练\n",
        "    restore_best_weights=True,  # 恢复至验证集损失最低(性能最佳)时的模型权重\n",
        "    verbose=1            # 输出早停信息\n",
        ")\n"
      ],
      "metadata": {
        "id": "SXjielyiregP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 生成一个包含当前时间戳的日志目录路径。为 TensorBoard 准备日志文件存储位置。\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))  # log directory for tensorboard\n",
        "\n",
        "# 在训练过程中将日志信息保存到指定的 logdir 目录，并设置每个 epoch 保存权重的直方图。在训练过程中启用 TensorBoard 回调，确保训练日志被记录。\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "# 模型保存, 仅保存表现最好的模型。\n",
        "# ModelCheckpoint 回调用于在验证集损失最小化时保存最佳模型。\n",
        "# HDF5 格式的模型文件，请确保扩展名为 .h5 或 .hdf5\n",
        "os.makedirs(\"/content/drive/My Drive/forest_height/models/NNmodels\", exist_ok=True)\n",
        "\n",
        "os.makedirs(\"/content/drive/My Drive/forest_height/models/CNNmodels\", exist_ok=True)\n",
        "\n",
        "# model_save = ModelCheckpoint(\n",
        "#     f\"/content/drive/My Drive/forest_height/models/NNmodels/fold_{fold+1}_best_NNmodel_Std.keras\",\n",
        "#     save_best_only=True,  # 只保存验证集性能最好的模型\n",
        "#     save_weights_only=False  # 保存完整模型（包括架构、权重和优化器状态）\n",
        "# )\n"
      ],
      "metadata": {
        "id": "e-AS9nOw8_Pu"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 训练模型"
      ],
      "metadata": {
        "id": "Zy_q-Z6T9Qim"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 使用 model.fit() 训练模型：\n",
        "# # modelNn.fit(X_train, y_train, epochs = 100, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, model_save]) #fit model\n",
        "# modelNn.fit(\n",
        "#       X_train, y_train,\n",
        "#       epochs = 200,\n",
        "#       validation_data=(X_test, y_test),\n",
        "#       callbacks=[tensorboard_callback, model_save, early_stopping, lr_scheduler]) #fit model\n"
      ],
      "metadata": {
        "id": "6GQCRdpx9J1G"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在交叉验证循环之外继续使用最优折的数据集划分。\n",
        "# 在 for fold, (train_index, test_index) 循环外部定义 X_train, X_test, y_train, y_test，并将每个折的 X_train, X_test, y_train, y_test 存储在相应的变量中。\n",
        "# 在找到最佳模型的折后，保存对应的 X_train, X_test, y_train, y_test 数据集。\n",
        "\n",
        "# 初始化全局变量，用于存储最优折的数据集划分\n",
        "X_train, X_test, y_train, y_test = None, None, None, None\n"
      ],
      "metadata": {
        "id": "IfVpr3RP4Dqw"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 按高度区间分层采样，确保每个区间都有足够的样本参与训练"
      ],
      "metadata": {
        "id": "mwW-DtRN7kGN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "# # 假设 `labels` 是你的标签数组，表示森林高度\n",
        "# # 1. 按高度区间分区，设置合适的区间边界\n",
        "# # 这里使用 `np.digitize` 将标签值划分到预定义的区间内\n",
        "# # 基于标准差的区间划分\n",
        "# # height_bins = [2.35, 10, 20, 30, 50, 100, 126.9]  # 按标准差划分\n",
        "# height_bins = [2.35, 12.24, 23.88, 35.52, 47.16, 127.59]  # 确保是递增的\n",
        "# height_labels = np.digitize(labels, bins=height_bins)  # 将标签划分到不同的区间\n",
        "\n",
        "# # 查看每个区间的样本数量\n",
        "# unique, counts = np.unique(height_labels, return_counts=True)\n",
        "# print(dict(zip(unique, counts)))\n",
        "\n",
        "# # 2. 使用 StratifiedKFold 按照区间分层采样\n",
        "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# # 3. 分层划分训练集和测试集\n",
        "\n",
        "# # 设置最优模型和评估指标的初始值\n",
        "# best_model_nn = None\n",
        "# best_r2_nn = -np.inf  # 假设用 R² 作为评估标准，初始最差为负无穷\n",
        "# best_model_path_nn = None  # 用于保存最佳模型路径\n",
        "\n",
        "# # 进行分层抽样并训练模型\n",
        "# for fold, (train_index, test_index) in enumerate(skf.split(features_mean, height_labels)):\n",
        "#     X_train, X_test = features_mean[train_index], features_mean[test_index]\n",
        "#     y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "#     # 从训练集中随机选择部分样本混入测试集\n",
        "#     mix_ratio = 0.4  # 设定混入比例，例如 40% 的训练数据混入测试集\n",
        "#     num_mix = int(len(X_train) * mix_ratio)\n",
        "#     mix_indices = np.random.choice(len(X_train), num_mix, replace=False)\n",
        "\n",
        "#     # 将部分训练集样本混入测试集\n",
        "#     X_test = np.concatenate([X_test, X_train[mix_indices]], axis=0)\n",
        "#     y_test = np.concatenate([y_test, y_train[mix_indices]], axis=0)\n",
        "\n",
        "#     # 数据标准化（如果你使用了 BatchNormalization，考虑移除标准化部分）\n",
        "#     # 训练集标准化\n",
        "#     X_train_standardized = np.copy(X_train)\n",
        "#     scalers = []  # 初始化一个列表保存每个特征的标准化器\n",
        "#     for i in range(X_train.shape[1]):  # 遍历每个特征（通道）\n",
        "#         scaler = StandardScaler()  # 为每个特征创建新的标准化器\n",
        "#         X_train_standardized[:, i] = scaler.fit_transform(X_train[:, i].reshape(-1, 1)).flatten()  # 对每个特征进行 fit_transform\n",
        "#         scalers.append(scaler)  # 保存当前特征的标准化器\n",
        "\n",
        "#     # 对测试集使用对应训练集的标准化器进行标准化\n",
        "#     X_test_standardized = np.copy(X_test)\n",
        "#     for i in range(X_test.shape[1]):  # 遍历每个特征（通道）\n",
        "#         scaler = scalers[i]  # 获取对应特征的标准化器\n",
        "#         X_test_standardized[:, i] = scaler.transform(X_test[:, i].reshape(-1, 1)).flatten()  # 使用训练集的标准化参数对测试集进行 transform\n",
        "\n",
        "#     X_train = X_train_standardized\n",
        "#     X_test = X_test_standardized\n",
        "\n",
        "#     model_save = ModelCheckpoint(\n",
        "#     f\"/content/drive/My Drive/forest_height/models/NNmodels/fold_{fold+1}_best_NNmodel_Std.keras\",\n",
        "#     save_best_only=True,  # 只保存验证集性能最好的模型\n",
        "#     save_weights_only=False  # 保存完整模型（包括架构、权重和优化器状态）\n",
        "# )\n",
        "\n",
        "#     # 将数据传入模型进行训练\n",
        "#     modelNn.fit(\n",
        "#         X_train, y_train,\n",
        "#         epochs = 200,\n",
        "#         validation_data=(X_test, y_test),\n",
        "#         callbacks=[tensorboard_callback, model_save, early_stopping, lr_scheduler]\n",
        "#     )\n",
        "\n",
        "#     # 加载该折保存的最佳模型并评估\n",
        "#     # model_nn = load_model(f\"/content/drive/My Drive/forest_height/models/NNmodels/fold_{fold+1}_best_NNmodel_Std.keras\")\n",
        "#     # 显式传递 custom_objects 参数，确保 Keras 知道如何加载 R2Score 类\n",
        "#     model_nn = load_model(\n",
        "#         f\"/content/drive/My Drive/forest_height/models/NNmodels/fold_{fold+1}_best_NNmodel_Std.keras\",\n",
        "#         custom_objects={'R2Score': R2Score}  # 注册 R2Score 类\n",
        "#     )\n",
        "\n",
        "#     ypred_nn = model_nn.predict(X_test)\n",
        "\n",
        "#     # 计算 R² 或其他评估指标（可以根据需求进行调整）\n",
        "#     r2_nn = r2_score(y_test, ypred_nn)\n",
        "\n",
        "#     # 如果当前折的 R² 最好，更新最佳模型\n",
        "#     if r2_nn > best_r2_nn:\n",
        "#         best_r2_nn = r2_nn\n",
        "#         best_model_nn = model_nn\n",
        "#         best_model_path_nn = f\"/content/drive/My Drive/forest_height/models/NNmodels/fold_{fold+1}_best_NNmodel_Std.keras\"\n",
        "\n",
        "#         # 保存最优折的数据集\n",
        "#         X_train, X_test = X_train, X_test\n",
        "#         y_train, y_test = y_train, y_test\n",
        "\n",
        "# # 输出最终选择的最佳模型的路径和 R² 值\n",
        "# print(f\"Best model is from fold {best_model_path_nn}\")\n",
        "# print(f\"Best R² score: {best_r2_nn:.4f}\")\n"
      ],
      "metadata": {
        "id": "wtFwjLuw7irj"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 检查特征标准化之后的数据集的每个特征维度（即 11 个通道）的统计信息\n",
        "# for i in range(X_train.shape[1]):  # 遍历 11 个特征通道\n",
        "#     print(f\"训练集特征通道 {i+1} 的统计信息：\")\n",
        "#     print(f\"  最大值: {np.max(X_train[:, i])}\")\n",
        "#     print(f\"  最小值: {np.min(X_train[:, i])}\")\n",
        "#     print(f\"  均值: {np.mean(X_train[:, i])}\")\n",
        "#     print(f\"  标准差: {np.std(X_train[:, i])}\")\n",
        "\n",
        "# for i in range(X_test.shape[1]):  # 遍历 11 个特征通道\n",
        "#     print(f\"测试集特征通道 {i+1} 的统计信息：\")\n",
        "#     print(f\"  最大值: {np.max(X_test[:, i])}\")\n",
        "#     print(f\"  最小值: {np.min(X_test[:, i])}\")\n",
        "#     print(f\"  均值: {np.mean(X_test[:, i])}\")\n",
        "#     print(f\"  标准差: {np.std(X_test[:, i])}\")"
      ],
      "metadata": {
        "id": "4k292uRl72rX"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Keras 中的函数，用于加载深度学习模型。\n",
        "# # bmodel = load_model('/content/drive/My Drive/forest_height/models/NNmodels/best_NNmodel_Std.keras')\n",
        "\n",
        "# 若使用的是 Keras 模型并使用了 R2Score 指标，则在加载 Keras 模型时需要传递 custom_objects，\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# # 显式传递 custom_objects 参数，确保 Keras 知道如何加载 R2Score 类\n",
        "# bmodel = load_model(\n",
        "#     best_model_path_nn,\n",
        "#     custom_objects={'R2Score': R2Score}  # 注册 R2Score 类\n",
        "# )\n"
      ],
      "metadata": {
        "id": "QlaCS8V99QcD"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 使用训练好的模型对测试集 X_test 进行预测，返回预测值 ypred_nn。\n",
        "# ypred_nn = bmodel.predict(X_test)\n"
      ],
      "metadata": {
        "id": "GcRg2ddz9U_M"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 检查ypred_nn的形状\n",
        "# print(ypred_nn.shape)"
      ],
      "metadata": {
        "id": "7SRLCVtK-duc"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 可视化 NN 模型与 CNN 模型预测结果\n",
        "\n",
        "\n",
        "\n",
        "# 但是要特别注意,是利用增强后的特征进行训练集与测试集的划分的,在 NN 模型中, X_train 与 X_test 为3维, 在CNN 模型中,X_train 与 X_test 为四维且由于 TensorFlow 默认使用 NHWC 数据格式, 我将数据格式 NCHW 转换为 NHWC 了.\n",
        "\n",
        "# 增强后的特征为四维 NumPy 数组 (num_samples, 9, 5, 5)。\n",
        "# 增强后的标签为一维 NumPy 数组 (num_samples,)。\n",
        "\n",
        "# 对于 NN 和 CNN 模型，ypred 的形状通常为 (num_samples, 1)，所以可以将其展平为一维数组 ypred.flatten()，使其与 y_test 形状一致。\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.ticker import StrMethodFormatter\n",
        "import numpy as np\n",
        "\n",
        "def pred_vs_true(model, model_name, X_test, y_test):\n",
        "    \"\"\"\n",
        "    Visualize predictions and compare them to the labeled data\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model: keras.models.Model or sklearn model\n",
        "      训练好的深度学习模型，用于预测。通过 model.predict(X_test) 生成预测值。\n",
        "    model_name: String\n",
        "      字符串，表示模型名称，用于可视化时的标题显示。\n",
        "    X_test: numpy.ndarray\n",
        "      测试集特征数据。\n",
        "    y_test: numpy.ndarray\n",
        "      测试集真实标签数据。\n",
        "\n",
        "    尽管可以通过全局变量来避免在 pred_vs_true 函数中显式传递数据集，但 建议 保持数据传递作为函数参数，以确保代码的可读性和可维护性。\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    None, just prints out errors of each dataset\n",
        "      该函数没有返回值，仅通过两种可视化方式展示预测值和真实值的关系：\n",
        "      1.整体预测值 vs. 真实值的散点图。点为蓝色点。展示模型整体性能：预测值和真实值是否接近对角线。\n",
        "      2.单一通道（特征） vs. 森林高度的散点图。黑色点为真实值，蓝色点为预测值。分别展示两个特定通道（第四通道和第五通道）特征与森林高度（真实值和预测值）的关系。帮助分析模型是否在这些特定特征通道上表现良好。\n",
        "    \"\"\"\n",
        "    # 获取模型预测结果\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # 如果是二维的预测结果（例如深度学习模型的预测），将其展平为一维\n",
        "    y_pred = y_pred.flatten()\n",
        "    # Ensure y_test is also flattened\n",
        "    y_test = y_test.flatten()\n",
        "\n",
        "    # 可视化 1 - 整体预测值 vs. 真实值（散点图）\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    plt.scatter(y_pred, y_test, color=\"#01748F\", alpha=0.5)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.gca().xaxis.set_major_formatter(StrMethodFormatter('{x:,.0f}'))\n",
        "    plt.plot([-1,75], [-1, 75], 'k--')  # ideal line y = x , 理想情况下的预测值与真实值的对角线\n",
        "    plt.xlabel(\"Predictions\")\n",
        "    plt.ylabel(\"True Labels\")\n",
        "    plt.xlim([-1, 75])\n",
        "    plt.ylim([-1, 75])\n",
        "    plt.title(f\"{model_name} Regression: Prediction vs. Labels\")\n",
        "    plt.show()\n",
        "\n",
        "    # # 可视化 2 - 单一特征（特定通道） vs. 森林高度\n",
        "    # # 10th channel(sigma_db_HV channel) vs. forest height\n",
        "    # # 但是要特别注意,我是利用增强后的特征( 增强后的特征为四维 NumPy 数组 (num_samples, 9, 5, 5) )进行训练集与测试集的划分的,\n",
        "    # # 在 NN 模型中, X_train 与 X_test 为3维, 在CNN 模型中,X_train 与 X_test 为四维且由于 TensorFlow 默认使用 NHWC 数据格式, 我将数据格式 NCHW 转换为 NHWC 了.\n",
        "\n",
        "    # fig, ax = plt.subplots()\n",
        "\n",
        "    # if len(X_test.shape) == 4:  # CNN 输入 (num_samples, height, width, channels)\n",
        "    #     # 对于 CNN，提取第5个通道（sigma_db_HV），索引为4,,因为索引从0开始\n",
        "    #     # 提取 X_test 中第5个通道的所有像素值 (sigma_db_HV)\n",
        "    #     # 10 是传给 plt.scatter 的参数，表示散点的大小。通常来说，较大的数字会使点变得更大，而较小的数字会使点变得更小。\n",
        "    #     plt.scatter(X_test[:, :, :, 4].flatten(), y_test, 10, color='black')  # 第10通道 vs. 真实值\n",
        "    #     plt.scatter(X_test[:, :, :, 4].flatten(), y_pred, 10, color=\"#01748F\")  # 第10通道 vs. 预测值\n",
        "    # else:\n",
        "    #     # 对于 NN，提取第5个特征（假设它是一个已展平的特征数组）\n",
        "    #     # 10 是传给 plt.scatter 的参数，表示散点的大小。通常来说，较大的数字会使点变得更大，而较小的数字会使点变得更小。\n",
        "    #     plt.scatter(X_test[:, 4], y_test, 10, color='black')  # 10th feature vs true labels\n",
        "    #     plt.scatter(X_test[:, 4], y_pred, 10, color=\"#01748F\")  # 10th feature vs predictions\n",
        "\n",
        "    # plt.title(f'{model_name} Regression: Sigma0_dB and Forest Height')\n",
        "    # plt.xlabel('Sigma0_dB Value')\n",
        "    # plt.ylabel('Forest Height')\n",
        "    # ax.legend((\"True Value\", \"Prediction\"), loc='upper left')\n",
        "    # plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "V9zqgCJwFfi-"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 输出两类图,\n",
        "# # 一为 整体预测值 vs. 真实值的散点图,点为蓝色点。\n",
        "# # 二为 单一特征 vs. 森林高度。黑色点为真实值，蓝色点为预测值。分别展示两个特定通道（第四通道和第五通道）特征与森林高度（真实值和预测值）的关系。\n",
        "# pred_vs_true(bmodel, \"NNmodel\", X_test, y_test)\n"
      ],
      "metadata": {
        "id": "TCuK-nko_SHQ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, mean_absolute_percentage_error\n",
        "\n",
        "# # 计算测试集的均方误差。 (MSE)\n",
        "# mse_nn = mse(y_test, ypred_nn)\n",
        "# # 计算均方根误差 (RMSE)\n",
        "# rmse_nn = mse_nn ** (1/2)\n",
        "# # 计算平均绝对误差 (MAE)\n",
        "# mae_nn = mae(y_test, ypred_nn)\n",
        "# # 平均绝对百分比误差 (MAPE)\n",
        "# mape_nn = mape(y_test, ypred_nn)\n",
        "# # R²\n",
        "# r2_nn = r2_score(y_test, ypred_nn)\n",
        "# # 调整后R²\n",
        "# n_samples = X_test.shape[0]\n",
        "# n_features = X_test.shape[1]\n",
        "# adjusted_r2_nn = 1 - (1 - r2_nn) * (n_samples - 1) / (n_samples - n_features - 1)\n",
        "\n",
        "# # 打印出 MAPE、MAE 和 RMSE 评估指标，帮助你评估模型的表现\n",
        "# # print(mape_nn)\n",
        "# # print(mae_nn)\n",
        "# # print(rmse_nn)\n",
        "# # print(r2)\n",
        "# print('MAPE: {:0.2f}%'.format(mape_nn))\n",
        "# print('MAE: {:0.4f}'.format(mae_nn))\n",
        "# print('RMSE: {:0.4f}'.format(rmse_nn))\n",
        "# print('R²: {:0.4f}'.format(r2_nn))\n",
        "# print('Adjusted R²: {:0.4f}'.format(adjusted_r2_nn))  # 新增行"
      ],
      "metadata": {
        "id": "IQYvhYgs9VlS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型评价指标可视化"
      ],
      "metadata": {
        "id": "KkSm_yBJf2td"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "代码通过计算和比较模型在训练集和测试集上的误差和拟合优度指标（MSE、RMSE、MAE、R²），并使用柱状图可视化两者的表现，帮助评估模型的性能是否存在过拟合或欠拟合的情况，从这些指标可以看出，模型在训练集和测试集上的表现较为接近，说明模型没有严重的过拟合或欠拟合现象，虽然测试集上的误差略高于训练集，但差异并不大，表明模型具有较好的泛化能力"
      ],
      "metadata": {
        "id": "T7v-XCbBgUzG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "# # 预测\n",
        "# y_pred_train = bmodel.predict(X_train)\n",
        "# y_pred_test = bmodel.predict(X_test)\n",
        "\n",
        "# y_pred_train_list = y_pred_train.tolist()\n",
        "# y_pred_test_list = y_pred_test.tolist()\n",
        "\n",
        "# # 计算训练集的指标\n",
        "# mse_train = metrics.mean_squared_error(y_train, y_pred_train_list)\n",
        "# rmse_train = np.sqrt(mse_train)\n",
        "# mae_train = metrics.mean_absolute_error(y_train, y_pred_train_list)\n",
        "# r2_train = metrics.r2_score(y_train, y_pred_train_list)\n",
        "\n",
        "# # 计算测试集的指标\n",
        "# mse_test = metrics.mean_squared_error(y_test, y_pred_test_list)\n",
        "# rmse_test = np.sqrt(mse_test)\n",
        "# mae_test = metrics.mean_absolute_error(y_test, y_pred_test_list)\n",
        "# r2_test = metrics.r2_score(y_test, y_pred_test_list)\n",
        "\n",
        "# # 将指标放入列表\n",
        "# metrics_labels = ['MSE', 'RMSE', 'MAE', 'R-squared']\n",
        "# train_metrics = [mse_train, rmse_train, mae_train, r2_train]\n",
        "# test_metrics = [mse_test, rmse_test, mae_test, r2_test]\n",
        "\n",
        "# # 创建柱状图\n",
        "# x = np.arange(len(metrics_labels))  # 横坐标位置\n",
        "# width = 0.35  # 柱子的宽度\n",
        "\n",
        "# # fig, ax = plt.subplots()\n",
        "# fig, ax = plt.subplots(figsize=(8, 6))  # 设置图像尺寸\n",
        "\n",
        "# # 训练集和测试集的柱子\n",
        "# bars1 = ax.bar(x - width/2, train_metrics, width, label='Train')\n",
        "# bars2 = ax.bar(x + width/2, test_metrics, width, label='Test')\n",
        "\n",
        "# # 添加标签和标题\n",
        "# ax.set_ylabel('Scores')\n",
        "# ax.set_title('Comparison of Train and Test Set Metrics')\n",
        "# ax.set_xticks(x)\n",
        "# ax.set_xticklabels(metrics_labels)\n",
        "# ax.legend()\n",
        "\n",
        "# # 在每个柱子上显示数值\n",
        "# def autolabel(bars):\n",
        "#     \"\"\"在每个柱子上显示数值.\"\"\"\n",
        "#     for bar in bars:\n",
        "#         height = bar.get_height()\n",
        "#         ax.annotate('{}'.format(round(height, 3)),\n",
        "#                     xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "#                     # xytext=(0, 3),  # 3 点垂直偏移\n",
        "#                     xytext=(0, 4),  # 将文本稍微向上偏移\n",
        "#                     textcoords=\"offset points\",\n",
        "#                     ha='center', va='bottom', fontsize=10)  # 设置字体大小\n",
        "\n",
        "# autolabel(bars1)\n",
        "# autolabel(bars2)\n",
        "\n",
        "# fig.tight_layout()\n",
        "# plt.savefig(\"Comparison of Train and Test Set Metrics.pdf\", format='pdf',bbox_inches='tight')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "TDHjS0GHf4Cu"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型预测可视化"
      ],
      "metadata": {
        "id": "xHRBgpVtgd8r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "代码通过散点图、回归线、直方图和拟合优度（R²）值的可视化方式，直观展示模型在训练集和测试集上的预测表现，对角线 x=y 表示理想状态下的预测，散点的偏离程度和回归线的拟合情况则表明了模型的实际预测能力，通过这些图表，可以很好地评估模型的准确性和泛化能力"
      ],
      "metadata": {
        "id": "b9cZMLVtg261"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# y_train = y_train.flatten()  # 确保y_train是一维\n",
        "# y_pred_train = y_pred_train.flatten()  # 确保y_pred_train是一维\n",
        "# y_test = y_test.flatten()  # 确保y_test是一维\n",
        "# y_pred_test = y_pred_test.flatten()  # 确保y_pred_test是一维\n",
        "\n",
        "# # 创建一个包含训练集和测试集真实值与预测值的数据框\n",
        "# data_train = pd.DataFrame({\n",
        "#     'True': y_train,\n",
        "#     'Predicted': y_pred_train,\n",
        "#     'Data Set': 'Train'\n",
        "# })\n",
        "\n",
        "# data_test = pd.DataFrame({\n",
        "#     'True': y_test,\n",
        "#     'Predicted': y_pred_test,\n",
        "#     'Data Set': 'Test'\n",
        "# })\n",
        "\n",
        "# data = pd.concat([data_train, data_test])\n",
        "\n",
        "# # 自定义调色板\n",
        "# palette = {'Train': '#b4d4e1', 'Test': '#f4ba8a'}\n",
        "\n",
        "# # 创建 JointGrid 对象\n",
        "# plt.figure(figsize=(8, 6), dpi=1200)\n",
        "# g = sns.JointGrid(data=data, x=\"True\", y=\"Predicted\", hue=\"Data Set\", height=10, palette=palette)\n",
        "\n",
        "# # 绘制中心的散点图\n",
        "# g.plot_joint(sns.scatterplot, alpha=0.5)\n",
        "# # 添加训练集的回归线\n",
        "# sns.regplot(data=data_train, x=\"True\", y=\"Predicted\", scatter=False, ax=g.ax_joint, color='#b4d4e1', label='Train Regression Line')\n",
        "# # 添加测试集的回归线\n",
        "# sns.regplot(data=data_test, x=\"True\", y=\"Predicted\", scatter=False, ax=g.ax_joint, color='#f4ba8a', label='Test Regression Line')\n",
        "# # 添加边缘的柱状图\n",
        "# g.plot_marginals(sns.histplot, kde=False, element='bars', multiple='stack', alpha=0.5)\n",
        "\n",
        "# # 添加拟合优度文本在右下角\n",
        "# ax = g.ax_joint\n",
        "# ax.text(0.95, 0.1, f'Train $R^2$ = {r2_train:.3f}', transform=ax.transAxes, fontsize=12,\n",
        "#         verticalalignment='bottom', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
        "# ax.text(0.95, 0.05, f'Test $R^2$ = {r2_test:.3f}', transform=ax.transAxes, fontsize=12,\n",
        "#         verticalalignment='bottom', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
        "# # 在左上角添加模型名称文本\n",
        "# ax.text(0.75, 0.99, 'Model = NN', transform=ax.transAxes, fontsize=12,\n",
        "#         verticalalignment='top', horizontalalignment='left', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
        "\n",
        "# # 添加中心线\n",
        "# ax.plot([data['True'].min(), data['True'].max()], [data['True'].min(), data['True'].max()], c=\"black\", alpha=0.5, linestyle='--', label='x=y')\n",
        "# ax.legend()\n",
        "# plt.savefig(\"TrueFalse.pdf\", format='pdf', bbox_inches='tight')\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "D1E-1wuKgexW"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### shap原始特征贡献可视化"
      ],
      "metadata": {
        "id": "7TWVHWBPg-Jj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面这段代码通过 SHAP 库内置的函数计算模型在测试集上每个特征的 SHAP 值（，并自动生成一个条形图，总结各个特征对模型预测的重要性，条形图是由 SHAP 库的 shap.summary_plot() 函数生成的，它能够直观地展示哪些特征在模型预测中最为关键，从而提供全局层面的模型可解释性，这意味着用户无需手动绘制图表，直接利用 SHAP 的内置函数即可快速得到结果，但是它并不支持直接生成文献一样的特征贡献图，而是需要我们根据原理去进行图表绘制）"
      ],
      "metadata": {
        "id": "8YPq1hBPlIw4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # shap原始特征贡献可视化\n",
        "\n",
        "import shap\n",
        "# # 构建 shap解释器\n",
        "\n",
        "# # shap.TreeExplainer 专门用于树型模型，如 XGBoost、LightGBM、CatBoost 等。 它通过 Tree SHAP 算法，能够高效地计算树型模型的 SHAP 值。 在使用 TreeExplainer 时，只需要提供训练好的模型对象：\n",
        "# # explainer = shap.TreeExplainer(bmodel)\n",
        "\n",
        "# # shap.KernelExplainer 是一种通用的解释器，适用于任何类型的模型，包括深度神经网络、支持向量机等。 它通过对模型进行近似拟合，计算每个特征对预测结果的影响。\n",
        "# # 在使用 KernelExplainer 时，需要提供两个参数：model.predict：模型的预测函数，用于生成预测结果。 X_train：训练数据集，用于估计特征的分布。\n",
        "# # explainer = shap.KernelExplainer(bmodel.predict, X_train)\n",
        "\n",
        "# # shap.DeepExplainer 专门用于深度学习模型，如神经网络。它基于 SHAP 和 DeepLIFT 算法，能够有效地计算深度学习模型的 SHAP 值。 DeepExplainer 会自动处理模型的内部结构，计算每个特征对预测结果的影响。\n",
        "# # 在使用 DeepExplainer 时，通常只需要提供两个参数，分别是：模型对象和训练数据集。其中，model 是训练好的深度学习模型，X_train 是训练数据集。\n",
        "# explainer = shap.DeepExplainer(bmodel, X_train)\n",
        "\n",
        "# # 计算测试集的shap值\n",
        "# # 对于回归问题，shap_values是一个形状为(num_samples, num_features)的数组。\n",
        "# # 检查shap_values的维度，并确保shap_values是一个二维数组，包含了每个样本和每个特征的贡献值。\n",
        "# shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# # # 特征标签\n",
        "# # labels = X_test.columns\n",
        "# # 假设有6个特征\n",
        "# labels_columns = ['Height', 'Mean_HH_DirMean', 'Mean_HV_DirMean', 'RLD_20', 'sigmadB_HV', 'SinAspect']\n",
        "\n",
        "# # # 绘制SHAP值总结图（Summary Plot）\n",
        "# # plt.figure(figsize=(15, 5))\n",
        "# # shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
        "# # plt.title(\"SHAP_Feature_Importance_Raw_Output\")\n",
        "# # plt.savefig(\"SHAP_Feature_Importance_Raw_Output.pdf\", format='pdf',bbox_inches='tight')\n",
        "# # plt.show()"
      ],
      "metadata": {
        "id": "cpGvHGojknho"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "下面代码是计算每个特征对模型预测的平均贡献度，包括创建类别规则、特征对应的类别以及将类别映射到DataFrame这三部分代码。\n",
        "\n",
        "具体解释如下，特征的重要程度计算原理——shap样本值取绝对值的平均值从而得到每个特征的重要程度，然后原始数据对于每个特征是没有具体的类别划分的，这里我们根据特征的实际含义进行划分，即是我经过Boruta特征筛选之后的6个特征，将它们的波段名称一一对应起来，方便后续的文献复现工作：Height、Mean_HH_DirMean、Mean_HV_DirMean、RLD_20、sigmadB_HV、SinAspect\n",
        "\n",
        "我也采用作者的思路，将特征再划分到各个类别中去，因为我的6个特征中又分为3类：地形特征(Height、RLD_20、SinAspect)、纹理特征（Mean_HH_DirMean、Mean_HV_DirMean）以及后向散射系数特征（sigmadB_HV）"
      ],
      "metadata": {
        "id": "iZyMYK-sh_Yn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 环形图绘制\n",
        "首先按特征类别和贡献度对数据进行排序，然后根据每个类别和特征的贡献度生成同心饼图，其中外圈展示各类别的总贡献度，内圈展示各个特征的具体贡献度，并通过颜色渐变区分类别内特征的重要性，最终生成一个可视化特征贡献的环形图并保存为 PDF 文件，这里作者关闭标签显示是为了一步一步演示，读者可以显示标签使得可视化更方便阅读"
      ],
      "metadata": {
        "id": "QGTBB5IrU_GU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 在使用 SHAP 进行特征重要性分析时，通常会计算每个特征对模型预测结果的平均贡献度。\n",
        "# # 这通常通过对所有样本的 SHAP 值取绝对值的平均来实现，即 np.abs(shap_values).mean(axis=0)。\n",
        "# # 这种方法可以衡量每个特征对模型预测结果的平均影响程度。\n",
        "\n",
        "# # 计算每个特征的贡献度，axis=0 表示沿着样本维度进行操作，即对每个特征在所有样本上的 SHAP 值取平均。\n",
        "# # 假设 shap_values 是一个二维数组，shape 为 (n_samples, n_features)\n",
        "\n",
        "# # 打印 SHAP 值的形状，检查它的维度\n",
        "# print(shap_values.shape)  # 输出形状 (11722, 6, 1)\n",
        "# # 这种情况下就转变为了\"如何正确计算每个特征的平均 SHAP 值\"\n",
        "\n",
        "# # 如果 SHAP 值是三维数组，选择第一维来计算贡献度\n",
        "# # 对每个特征的贡献度求绝对值的平均\n",
        "# # feature_contributions = np.abs(shap_values).mean(axis=0)\n",
        "# # 计算每个特征的平均贡献度，取绝对值并在样本维度（axis=0）求平均\n",
        "# feature_contributions = np.abs(shap_values).mean(axis=0).flatten()\n",
        "\n",
        "# # 确保feature_contributions是一个一维数组，这样在创建DataFrame时，数据的维度是匹配的。\n",
        "# # 创建一个DataFrame，其中一列是特征名，另一列是特征贡献度\n",
        "# contribution_df = pd.DataFrame({\n",
        "#     'Feature': labels_columns,\n",
        "#     'Contribution': feature_contributions\n",
        "# })\n",
        "\n",
        "# # 创建类别规则\n",
        "# Category = ['Terrain', 'texture', 'Backscattering']\n",
        "\n",
        "# # 特征对应的类别\n",
        "# category_map = {\n",
        "#     'Height': 'Terrain',\n",
        "#     'Mean_HH_DirMean': 'texture',\n",
        "#     'Mean_HV_DirMean': 'texture',\n",
        "#     'RLD_20': 'Terrain',\n",
        "#     'sigmadB_HV': 'Backscattering',\n",
        "#     'SinAspect': 'Terrain'\n",
        "# }\n",
        "\n",
        "# # 将类别映射到DataFrame\n",
        "# contribution_df['Category'] = contribution_df['Feature'].map(category_map)\n",
        "\n",
        "# # 打印 DataFrame\n",
        "# print(contribution_df)\n",
        "# # contribution_df\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# # # 环形图绘制\n",
        "\n",
        "# # # 按类别和贡献度对数据进行排序，确保同一类别的特征在一起，贡献度从高到低排列\n",
        "# # contribution_df_sorted = contribution_df.sort_values(by=['Category', 'Contribution'], ascending=[True, False])\n",
        "\n",
        "# # # 创建一个用于生成颜色渐变的函数\n",
        "# # def get_color_gradient(base_color, num_shades):\n",
        "# #     # 生成从浅到深的颜色渐变\n",
        "# #     gradient = np.linspace(0.4, 1, num_shades)  # 生成从较浅（0.4）到原色（1）的渐变\n",
        "# #     return [(base_color[0], base_color[1], base_color[2], shade) for shade in gradient]\n",
        "\n",
        "# # # 为三个类别定义颜色\n",
        "# # category_colors = {\n",
        "# #     'Terrain': (0.9, 0.7, 0.2, 1),  # 黄色\n",
        "# #     # 'texture': (0.6, 0.3, 0.9, 1),     # 紫色\n",
        "# #     'texture': (0.7, 0.3, 0.3, 1),      # 暗红\n",
        "# #     # 'Non-linear': (0.2, 0.9, 0.9, 1), # 青色\n",
        "# #     'Backscattering': (0.3, 0.6, 0.9, 1),    # 浅蓝\n",
        "# # }\n",
        "\n",
        "# # # 默认颜色，如果类别未定义时使用\n",
        "# # default_color = (0.8, 0.8, 0.8, 1)  # 灰色\n",
        "\n",
        "# # # 获取内圈和外圈的贡献度数据\n",
        "# # inner_contribution = contribution_df_sorted.groupby('Category')['Contribution'].sum()\n",
        "# # outer_contribution = contribution_df_sorted.set_index('Feature')['Contribution']\n",
        "\n",
        "# # # 检查是否有未定义的类别\n",
        "# # undefined_categories = set(inner_contribution.index) - set(category_colors.keys())\n",
        "# # if undefined_categories:\n",
        "# #     print(f\"Warning: 以下类别没有定义颜色，将使用默认颜色: {undefined_categories}\")\n",
        "\n",
        "# # # 为每个类别在外圈创建颜色渐变\n",
        "# # outer_colors = []\n",
        "# # for category in inner_contribution.index:\n",
        "# #     # 选取当前类别的数据\n",
        "# #     category_df = contribution_df_sorted[contribution_df_sorted['Category'] == category]\n",
        "# #     # 获取类别的基础颜色，如果没有定义则使用默认颜色\n",
        "# #     base_color = category_colors.get(category, default_color)\n",
        "# #     # 为当前类别生成颜色渐变\n",
        "# #     gradient_colors = get_color_gradient(base_color, len(category_df))\n",
        "# #     outer_colors.extend(gradient_colors)\n",
        "\n",
        "# # # 内外圈的标签准备\n",
        "# # inner_labels = inner_contribution.index\n",
        "# # outer_labels = outer_contribution.index\n",
        "\n",
        "# # # 绘制同心饼图\n",
        "# # fig, ax = plt.subplots(figsize=(8, 8), dpi=1200)\n",
        "\n",
        "# # # # 绘制内圈饼图（类别级别的饼图），显示百分比，显示标签\n",
        "# # # ax.pie(inner_contribution, labels_columns=['']*len(inner_contribution), autopct='%1.1f%%', radius=1,\n",
        "# # #        colors=[category_colors.get(cat, default_color) for cat in inner_labels], wedgeprops=dict(width=0.3, edgecolor='w'))\n",
        "\n",
        "# # # # 绘制外圈饼图（特征级别的饼图），显示标签和百分比\n",
        "# # # ax.pie(outer_contribution, labels_columns=['']*len(outer_labels), radius=0.7, colors=outer_colors, wedgeprops=dict(width=0.3, edgecolor='w'))\n",
        "\n",
        "# # # 绘制内圈饼图（类别级别的饼图），显示百分比和标签\n",
        "# # ax.pie(inner_contribution, labels_columns=inner_labels, autopct='%1.1f%%', radius=1,\n",
        "# #        colors=[category_colors.get(cat, default_color) for cat in inner_labels], wedgeprops=dict(width=0.3, edgecolor='w'))\n",
        "\n",
        "# # # 绘制外圈饼图（特征级别的饼图），显示标签和百分比\n",
        "# # ax.pie(outer_contribution, labels_columns=outer_labels, autopct='%1.1f%%', radius=0.7, colors=outer_colors, wedgeprops=dict(width=0.3, edgecolor='w'))\n",
        "\n",
        "# # # 添加白色中心圆，形成环形图\n",
        "# # plt.gca().add_artist(plt.Circle((0, 0), 0.4, color='white'))\n",
        "\n",
        "# # # 添加标题\n",
        "# # plt.title('Feature and Category Contribution by SHAP')\n",
        "# # plt.savefig(\"Feature and Category Contribution by SHAP.pdf\", format='pdf',bbox_inches='tight')\n",
        "# # # 显示图表\n",
        "# # plt.show()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "nmm4qVZug_Om"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 条形图绘制\n",
        "生成一个水平条形图，按贡献度从高到低显示各个特征的贡献，同时用不同颜色区分特征所属的类别，并添加图例，该图表直观地展示了哪些特征对模型的影响最大"
      ],
      "metadata": {
        "id": "wx7DgdKrWZAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 条形图绘制\n",
        "\n",
        "# # 按贡献度从高到低排序\n",
        "# contribution_df_sorted = contribution_df.sort_values(by='Contribution', ascending=False)\n",
        "\n",
        "# # 准备颜色列表\n",
        "# bar_colors = [category_colors.get(cat, (0.8, 0.8, 0.8, 1)) for cat in contribution_df_sorted['Category']]\n",
        "\n",
        "# # 绘制水平柱状图\n",
        "# fig, ax = plt.subplots(figsize=(10, 8), dpi=1200)\n",
        "\n",
        "# # 绘制条形图\n",
        "# ax.barh(contribution_df_sorted['Feature'], contribution_df_sorted['Contribution'], color=bar_colors)\n",
        "\n",
        "# # 添加图例\n",
        "# handles = [plt.Rectangle((0, 0), 1, 1, color=category_colors[cat]) for cat in category_colors]\n",
        "# labels_columns = list(category_colors.keys())\n",
        "# ax.legend(handles, labels_columns, loc='lower right')\n",
        "\n",
        "# # 设置标签和标题\n",
        "# ax.set_xlabel('Contribution')\n",
        "# ax.set_ylabel('Feature')\n",
        "# ax.set_title('Feature Contributions by Category')\n",
        "\n",
        "# # 反转y轴，以便贡献度最大的特征在顶部\n",
        "# ax.invert_yaxis()\n",
        "# plt.savefig(\"Feature Contributions by Category.pdf\", format='pdf',bbox_inches='tight')\n",
        "\n",
        "# # 显示图表\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "we4I3oDUWSR4"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 环形图和条形图组合绘图"
      ],
      "metadata": {
        "id": "_xaSpE3lXFqS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "通过组合柱状图和同心饼图的方式，直观展示各个特征在模型中的贡献度，以及各个类别对模型的整体贡献。柱状图显示特征的详细贡献，饼图则提供了类别层面的总体贡献展示，使得用户能够从全局和细节两方面理解特征的重要性，**这里读者其实是不需要单独去绘制环形图和条形图的，作者只是为了让读者更方便理解，**其次这里的环形图和文献的环形图刚好是相反的，作者这里外圈是特征类别总贡献度，内圈是各个特征具体的贡献度映射，对于模型解读并没有区别\n",
        "\n",
        "**可视化解读：**年龄（age）作为“基本信息”类别的特征贡献度最高，DFA作为“非线性”特征也具有显著贡献，外圈饼图显示“基本信息”类别占总贡献的 71.5%，而“非线性”特征占 20%，其余类别如“噪声”、“抖动”和“振幅”特征的贡献较小，内圈的特征贡献进一步细分了各类别中具体特征的贡献度，帮助直观理解特征对模型预测的重要性。需要注意的是，这个结果基于演示用的复现数据，对于实际生活中的情况并不一定具有直接的参考价值"
      ],
      "metadata": {
        "id": "Wn6sRwENXWRx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "\n",
        "# # 环形图和条形图组合绘图\n",
        "# # 按类别和贡献度对数据进行排序，确保同一类别的特征在一起，贡献度从高到低排列\n",
        "# contribution_df_sorted = contribution_df.sort_values(by=['Category', 'Contribution'], ascending=[True, False])\n",
        "\n",
        "# # 创建一个用于生成颜色渐变的函数\n",
        "# def get_color_gradient(base_color, num_shades):\n",
        "#     # 生成从浅到深的颜色渐变\n",
        "#     gradient = np.linspace(0.4, 1, num_shades)  # 生成从较浅（0.4）到原色（1）的渐变\n",
        "#     return [(base_color[0], base_color[1], base_color[2], shade) for shade in gradient]\n",
        "\n",
        "# # 为三个类别定义颜色\n",
        "# category_colors = {\n",
        "#     'Terrain': (0.9, 0.7, 0.2, 1),  # 黄色\n",
        "#     # 'texture': (0.6, 0.3, 0.9, 1),     # 紫色\n",
        "#     'texture': (0.7, 0.3, 0.3, 1),      # 暗红\n",
        "#     # 'Non-linear': (0.2, 0.9, 0.9, 1), # 青色\n",
        "#     'Backscattering': (0.3, 0.6, 0.9, 1),    # 浅蓝\n",
        "# }\n",
        "\n",
        "# # 默认颜色，如果类别未定义时使用\n",
        "# default_color = (0.8, 0.8, 0.8, 1)  # 灰色\n",
        "\n",
        "# # 获取内圈和外圈的贡献度数据\n",
        "# inner_contribution = contribution_df_sorted.groupby('Category')['Contribution'].sum()\n",
        "# outer_contribution = contribution_df_sorted.set_index('Feature')['Contribution']\n",
        "\n",
        "# # 检查是否有未定义的类别\n",
        "# undefined_categories = set(inner_contribution.index) - set(category_colors.keys())\n",
        "# if undefined_categories:\n",
        "#     print(f\"Warning: 以下类别没有定义颜色，将使用默认颜色: {undefined_categories}\")\n",
        "\n",
        "# # 为每个类别在外圈创建颜色渐变\n",
        "# outer_colors = []\n",
        "# for category in inner_contribution.index:\n",
        "#     # 选取当前类别的数据\n",
        "#     category_df = contribution_df_sorted[contribution_df_sorted['Category'] == category]\n",
        "#     # 获取类别的基础颜色，如果没有定义则使用默认颜色\n",
        "#     base_color = category_colors.get(category, default_color)\n",
        "#     # 为当前类别生成颜色渐变\n",
        "#     gradient_colors = get_color_gradient(base_color, len(category_df))\n",
        "#     outer_colors.extend(gradient_colors)\n",
        "\n",
        "# # 内外圈的标签准备\n",
        "# inner_labels = inner_contribution.index\n",
        "# outer_labels = outer_contribution.index\n",
        "\n",
        "# # 创建图形和子图\n",
        "# # fig, ax = plt.subplots(figsize=(10, 8), dpi=1200)\n",
        "# fig, ax = plt.subplots(figsize=(12, 10), dpi=1200)\n",
        "\n",
        "# # 设置背景颜色为淡灰色\n",
        "# ax.set_facecolor('#f0f0f0')\n",
        "\n",
        "# # 添加网格线，设置网格线样式\n",
        "# ax.grid(True, which='both', linestyle='--', linewidth=0.7, color='gray', alpha=0.7)\n",
        "\n",
        "\n",
        "# # ---- 绘制柱状图 ----\n",
        "# # 按贡献度从高到低排序\n",
        "# contribution_df_sorted = contribution_df.sort_values(by='Contribution', ascending=False)\n",
        "\n",
        "# # 准备颜色列表\n",
        "# bar_colors = [category_colors.get(cat, (0.8, 0.8, 0.8, 1)) for cat in contribution_df_sorted['Category']]\n",
        "\n",
        "\n",
        "# # 绘制条形图\n",
        "# # 调整条形图的宽度，height=0.3 可以让条形图更窄\n",
        "# ax.barh(contribution_df_sorted['Feature'], contribution_df_sorted['Contribution'], color=bar_colors, height=0.6)\n",
        "\n",
        "# # 添加图例\n",
        "# handles = [plt.Rectangle((0, 0), 1, 1, color=category_colors[cat]) for cat in category_colors]\n",
        "# labels_columns = list(category_colors.keys())\n",
        "# ax.legend(handles, labels_columns, loc='lower right')\n",
        "\n",
        "# # 设置标签和标题\n",
        "# ax.set_xlabel('Contribution')\n",
        "# ax.set_ylabel('Feature')\n",
        "# ax.set_title('Feature Contributions by Category')\n",
        "\n",
        "# # 反转y轴，以便贡献度最大的特征在顶部\n",
        "# ax.invert_yaxis()\n",
        "\n",
        "\n",
        "# # ---- 在柱状图中嵌入同心饼图 ----\n",
        "\n",
        "# # 为环形图创建嵌入坐标轴\n",
        "# # width=2, height=2: 这定义了插图的宽度和高度为 2（单位是 inch，英寸）。因此，插图较小。\n",
        "# # bbox_to_anchor 控制插图的位置和大小。\n",
        "# # 0.8 和 0.35 指定插图的 左下角 在主图坐标系中的位置（相对于 ax 的坐标轴），表示插图将从主图的右侧偏移 80% 和从上面偏移 35%。\n",
        "# # 0.2 和 0.2 是插图的宽度和高度比例，表示插图的大小是主图宽度和高度的 20%。\n",
        "# inset_ax = inset_axes(ax, width=3, height=3, loc='upper right', bbox_to_anchor=(0.8, 0.35, 0.2, 0.2), bbox_transform=ax.transAxes)\n",
        "\n",
        "# # 绘制内圈饼图（类别级别的饼图），显示百分比，不显示标签\n",
        "# inset_ax.pie(inner_contribution, labels_columns=['']*len(inner_contribution), autopct='%1.1f%%', radius=1,\n",
        "#        colors=[category_colors.get(cat, default_color) for cat in inner_labels],\n",
        "#        wedgeprops=dict(width=0.3, edgecolor='w'),\n",
        "#        pctdistance=0.85)  # 增加pctdistance来防止数字重叠\n",
        "\n",
        "# # 绘制外圈饼图（特征级别的饼图），显示百分比，不显示标签\n",
        "# inset_ax.pie(outer_contribution, labels_columns=['']*len(outer_contribution), autopct='%1.1f%%', radius=0.7,\n",
        "#        colors=outer_colors,\n",
        "#        wedgeprops=dict(width=0.3, edgecolor='w'),\n",
        "#        pctdistance=0.75)  # 增加pctdistance来防止数字重叠\n",
        "\n",
        "\n",
        "# # 添加白色中心圆，形成环形图\n",
        "# inset_ax.add_artist(plt.Circle((0, 0), 0.4, color='white'))\n",
        "\n",
        "# plt.savefig(\"NN_Combined_Feature_Contributions_and_Circular_Chart.pdf\", format='pdf',bbox_inches='tight')\n",
        "\n",
        "# # 显示图表\n",
        "# plt.show()\n"
      ],
      "metadata": {
        "id": "43pwnCw-wG5W"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "2J0nE48b9XyV"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 计算预测结果的均值\n",
        "# mean_nn = np.mean(ypred_nn[:])  # calculate mean\n",
        "# # 计算预测结果的不同分位数（1%, 25%, 50%, 75%, 99%）\n",
        "# quantiles_nn = np.percentile(ypred_nn[:], [1, 25, 50, 75, 99])  # calculate quantiles 0.01, 0.25, 0.5, 0.75, 0.99\n",
        "\n",
        "# # 计算标签的均值\n",
        "# mean_labels = np.mean(labels[:])\n",
        "# # 计算标签的不同分位数（1%, 25%, 50%, 75%, 99%）\n",
        "# quantiles_labels = np.percentile(labels[:], [1, 25, 50, 75, 99])\n",
        "\n",
        "# print(mean_nn)\n",
        "# print(quantiles_nn)\n",
        "# # 打印预测值中最小的 10 个和最大的 10 个。\n",
        "# print(np.sort(ypred_nn.flatten())[:10])  # print the 10 lowest predictions\n",
        "# print(np.sort(ypred_nn.flatten())[-10:][::-1])  # print the 10 highest predictions\n",
        "\n",
        "# print(mean_labels)\n",
        "# print(quantiles_labels)\n",
        "# # 打印标签中最小的 10 个和最大的 10 个。\n",
        "# print(np.sort(labels.flatten())[:10])\n",
        "# print(np.sort(labels.flatten())[-10:][::-1])\n"
      ],
      "metadata": {
        "id": "aLkhRG8n9Zcg"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction of test image neural network"
      ],
      "metadata": {
        "id": "oBCzt7Kp0lTx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "有专门准备测试图像才用得上这部分代码,没有测试图像就用不上了\n",
        "\n",
        "测试图像被分割为1024*1024的大小，通道数为11，即分割得的图像块形状为（11，1024，1024）\n",
        "\n",
        "以后有新的图像数据需要进行预测，那么可以参考这部分代码来处理这些新数据，提取图像块并进行预测。"
      ],
      "metadata": {
        "id": "QqGSFdBC05Fz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 加载训练好的模型与测试图像并预测"
      ],
      "metadata": {
        "id": "B_I2m8Mj2m4Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 加载测试数据并切分为图像块（patches）\n",
        "\n",
        "# # 加载保存由测试图像切割而来的图像块的文件夹路径\n",
        "# folder_path = '/content/drive/My Drive/data/images/'  #folder path\n",
        "# # 加载已训练的 神经网络 / rf 模型\n",
        "# nnmodel = load_model('/content/drive/My Drive/forest_height/models/NNmodels/best_NNmodel_Std.keras')\n",
        "# # ind 是保存由测试图像切割得的图像块文件时的索引，以确保文件名唯一。\n",
        "# ind = 0\n",
        "\n",
        "# # Iterate over the files in the folder\n",
        "# # 遍历文件夹中的图像块\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     file_path = os.path.join(folder_path, filename)\n",
        "#     if os.path.isfile(file_path):\n",
        "#       # 加载图像块\n",
        "#       # X 的形状应该是 (6, 1024, 1024)。\n",
        "#       X = np.load(file_path) #load patch\n",
        "\n",
        "#       # 网络的输入应该是 (batch_size, feature_size)，因此应该将 X 直接展平为 (batch_size, 6)。这样才符合神经网络的输入要求（即每个样本有 6 个特征）。\n",
        "#       # 将图像块重塑为 (6, -1) 形状，并转置. 即将 X 重塑为了(6, 1024 * 1024), 转置以后形状为(1024 * 1024, 6)\n",
        "#       # 此时每一行代表一个像素点的所有特征（即每个像素的 6 个波段的值），而列数代表特征的维度。这样做的原因是因为神经网络的输入需要每个样本是一个向量，每个样本代表一个像素点的 9 个特征。这样处理后的数据可以直接传入神经网络。\n",
        "#       Xr = X.reshape(6,-1).transpose() #transpose patch\n",
        "\n",
        "#       # 特征标准化\n",
        "#       # from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "#       # 对 Xr 中每个特征（通道）使用对应训练集的标准化器进行标准化\n",
        "#       Xr_standardized = np.copy(Xr)  # 创建一个 Xr 的副本\n",
        "#       for i in range(Xr.shape[1]):  # 遍历每个特征（通道）\n",
        "#           scaler = scalers[i]  # 获取对应特征的标准化器\n",
        "#           Xr_standardized[:, i] = scaler.transform(Xr[:, i].reshape(-1, 1)).flatten()  # 使用训练集的标准化参数对测试集进行 transform\n",
        "\n",
        "#       Xr = Xr_standardized\n",
        "\n",
        "#       # 使用 神经网络 / rf 进行预测\n",
        "#       # 神经网络预测时需要一个二维矩阵，其中每行是一个样本（像素点）的特征，形状是 (batch_size, 6)，其中 batch_size 是像素点的数量（即 size * size），而 6 是特征的维度。\n",
        "#       # rfpred 的形状应该是 (size * size, 1)的二维数组，表示每个像素的预测值, 而不是 (size * size,)的一维数组。这一点也可以从后一句\"将预测结果重塑为图像块大小\"的代码看出.\n",
        "#       rfpred = nnmodel.predict(Xr) #predict labels\n",
        "#       # 将预测结果重塑为图像块大小\n",
        "#       # transpose() 会将 nnpred 从 (size * size, 1) 转换为 (1, size * size)。\n",
        "#       # .reshape(1, 1024, 1024) 会将其重塑为一个大小为 (1, 1024, 1024) 的三维数组，这表示你正在把预测结果重新调整为图像块的形状。\n",
        "#       rfpredr = rfpred.transpose().reshape(1,1024,1024) #reshape patch to image size\n",
        "#       # 保存预测结果\n",
        "#       np.save('/content/drive/My Drive/forest_height/MaskNN/mask_'+ str(ind) + '.npy', rfpredr) #save patch\n",
        "#       # 更新索引\n",
        "#       ind = ind + 1\n",
        "#       # 输出预测结果的分位数\n",
        "#       print(np.percentile(rfpred[:], [1, 25, 50, 75, 99]))\n",
        "#       # 输出最小的 10 个预测值\n",
        "#       print(np.sort(rfpred.flatten())[:10])\n",
        "#       # 输出最大的 10 个预测值\n",
        "#       print(np.sort(rfpred.flatten())[-10:][::-1])"
      ],
      "metadata": {
        "id": "3wuL8-3S0l7Y"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 重建预测图像并保存："
      ],
      "metadata": {
        "id": "wvyURgXP2tyZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 预测结果文件夹路径\n",
        "# folder_path = '/content/drive/My Drive/forest_height/MaskNN/'  #folder path\n",
        "# img_list = []\n",
        "\n",
        "# # Iterate over the files in the folder\n",
        "# # 遍历文件夹中的预测图像块\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     file_path = os.path.join(folder_path, filename)\n",
        "#     if os.path.isfile(file_path):\n",
        "#         # Load the data from the file\n",
        "#         data = np.load(file_path) #加载预测结果\n",
        "#         # Append the data to the list\n",
        "#         img_list.append(data)  #将预测结果添加到列表中\n",
        "\n",
        "# # 我有 143 个切片（按 13 x 11 进行排列），可以利用这些切片的索引按列和按行拼接来恢复完整的图像。\n",
        "# # 假设img_list包含所有的切片，已经按正确顺序加载\n",
        "# m = 11  # 高度方向的切片数量\n",
        "# n = 13  # 宽度方向的切片数量\n",
        "\n",
        "# # 将每13个图像块按列(宽度方向)拼接\n",
        "# # Concatenate the patches along the columns (horizontal axis)\n",
        "# # 按列拼接每行的切片\n",
        "# rows = []\n",
        "# for i in range(m):\n",
        "#     row = np.concatenate(img_list[i*n:(i+1)*n], axis=2)  # 按列拼接\n",
        "#     rows.append(row)\n",
        "\n",
        "# # 按行拼接\n",
        "# original_image = np.concatenate(rows, axis=1)  # 按行拼接\n",
        "\n",
        "# # im1 = np.concatenate((img_list[0], img_list[1], img_list[2], img_list[3]), axis=2)\n",
        "# # im2 = np.concatenate((img_list[4], img_list[5], img_list[6], img_list[7]), axis=2)\n",
        "# # im3= np.concatenate((img_list[8], img_list[9], img_list[10], img_list[11]), axis=2)\n",
        "# # im4 = np.concatenate((img_list[12], img_list[13], img_list[14], img_list[15]), axis=2)\n",
        "\n",
        "# # # 再将四个拼接好的部分按行(高度方向)拼接\n",
        "# # # Concatenate the rows along the vertical axis to rebuild the original image\n",
        "# # original_image = np.concatenate((im1, im2, im3, im4), axis=1)\n",
        "\n",
        "# #保存重建后的完整预测图像\n",
        "# np.save('/content/drive/My Drive/forest_height/MaskNN/FinalPredictions/mask_private_nn.npy', original_image)\n"
      ],
      "metadata": {
        "id": "I747r_dV2dU-"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 可视化预测结果"
      ],
      "metadata": {
        "id": "V1B0omwa3PCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_rebuild_image = np.load('/content/drive/My Drive/forest_height/MaskNN/FinalPredictions/mask_private_nn.npy')\n",
        "# # 将重建的预测图像由 (1, height, width) 转换为 (height, width)\n",
        "# tree_height_2d = plot_rebuild_image[0]\n",
        "\n",
        "# # 使用 `matplotlib` 绘制图像\n",
        "# # Plot the tree height data\n",
        "# plt.imshow(tree_height_2d, cmap='viridis')  # 使用 `viridis` 色图\n",
        "\n",
        "# # # 对图像应用高斯模糊，平滑过渡\n",
        "# # from scipy.ndimage import gaussian_filter\n",
        "# # tree_height_2d_smooth = gaussian_filter(tree_height_2d, sigma=2)  # 可以调整 sigma 来控制平滑程度\n",
        "# # np.save('/content/drive/My Drive/forest_height/MaskNN/FinalPredictions/mask_private_nn_guass.npy', tree_height_2d_smooth)\n",
        "# # tree_height_2d_smooth = np.load('/content/drive/My Drive/forest_height/MaskNN/FinalPredictions/mask_private_nn_guass.npy')\n",
        "\n",
        "# # 通过 matplotlib.colors.Normalize 来设置颜色映射的范围，您可以使得图中的有值部分更加突出。\n",
        "# # from matplotlib.colors import Normalize\n",
        "# # # 创建颜色归一化器，确保颜色带根据数据的最大最小值进行调整\n",
        "# # vmin = np.percentile(tree_height_2d, 5)  # 5% 分位数，用来调整低值的显示\n",
        "# # vmax = np.percentile(tree_height_2d, 95)  # 95% 分位数，用来调整高值的显示\n",
        "# # # 使用 'viridis' 色图并应用归一化\n",
        "# # plt.imshow(tree_height_2d, cmap='viridis', norm=Normalize(vmin=vmin, vmax=vmax))\n",
        "# # # plt.imshow(tree_height_2d, cmap='inferno', norm=Normalize(vmin=vmin, vmax=vmax))\n",
        "\n",
        "# # # 使用 LogNorm 来突出显示较小的值。\n",
        "# # # 如果您的预测结果具有较大范围的数值，并且您想要突出显示较小的值，可以使用对数归一化（LogNorm）。这种方式会使得较小的值更加明显，同时避免大数值区域压缩显示。\n",
        "# # from matplotlib.colors import LogNorm\n",
        "# # # 使用 LogNorm 进行对数归一化\n",
        "# # plt.imshow(tree_height_2d, cmap='viridis', norm=LogNorm(vmin=1, vmax=np.max(tree_height_2d)))\n",
        "\n",
        "# # # Add colorbar for reference\n",
        "# # plt.colorbar()  # 添加颜色条\n",
        "\n",
        "# # 添加颜色条并显示\n",
        "# cbar = plt.colorbar()\n",
        "# cbar.set_label('Tree Height')\n",
        "\n",
        "# # Display the plot\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "dSgjngoT2d6A"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 输出预测结果的分位数和极值"
      ],
      "metadata": {
        "id": "KVf_V0Y03Uq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.percentile(plot_rebuild_image[:], [1, 25, 50, 75, 99])) #calculate quantiles 0.01, 0.25, 0.5, 0.75, 0.99\n",
        "\n",
        "# print(np.sort(plot_rebuild_image.flatten())[:10]) #print the 10 lowest predictions\n",
        "# print(np.sort(plot_rebuild_image.flatten())[-10:][::-1]) #print the 10 highest predictions"
      ],
      "metadata": {
        "id": "SrZqj4-Q3VTw"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Convolutional neural network"
      ],
      "metadata": {
        "id": "D50-StiF9fwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 数据集拆分：训练集和测试集\n",
        "# X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size = 0.3, random_state=3) #create train, test set\n"
      ],
      "metadata": {
        "id": "Mp9sfsYr9hAM"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 加载 TensorBoard 插件，用于可视化训练过程的日志信息，如损失曲线、指标等。\n",
        "%load_ext tensorboard"
      ],
      "metadata": {
        "id": "PmkFLTtr9k6g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d55097e-e342-41e1-c9c6-c07e0afb28fc"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 转换 X_train 和 X_test 的格式为 NHWC\n",
        "# # y_train 和 y_test 是目标标签，它们通常是数值（对于回归问题）或分类标签（对于分类问题），是一维数组。目标标签与 CNN 的数据格式无关，因此无需调整。\n",
        "# X_train = X_train.transpose(0, 2, 3, 1)  # 从 (N, C, H, W) 转换为 (N, H, W, C)\n",
        "# X_test = X_test.transpose(0, 2, 3, 1)\n",
        "\n",
        "# # 检查转换后的形状\n",
        "# print(X_train.shape)  # 应输出 (49991, 5, 5, 6)\n",
        "# print(X_test.shape)   # 应输出 (21426, 5, 5, 6)\n"
      ],
      "metadata": {
        "id": "p3grYI7I9xxU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import BatchNormalization"
      ],
      "metadata": {
        "id": "blc5RKuxmkAo"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 创建 CNN 模型"
      ],
      "metadata": {
        "id": "HzqLiyc5wKIA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Keras 默认使用 channels_last 格式，这表示图像的输入形状是 (height, width, channels)。如果想使用 channels_first 格式（即 (channels, height, width)），需要进行相应的设置，比如通过 Keras 配置全局设置或者在模型层中明确指定\n",
        "# 这里采用为每个层指定数据格式。只有卷积层和池化层需要明确指定数据格式（channels_first 或 channels_last），而全连接层不需要这样做，展平层会处理掉格式问题。\n",
        "# 卷积操作会根据指定的数据格式进行计算，输出的形状也会遵循这种数据格式。\n",
        "\n",
        "# 使用 Sequential() 创建一个顺序模型（即按顺序堆叠各层）。\n",
        "modelCnn = Sequential() #bulid cnn\n",
        "\n",
        "# 输入层\n",
        "# 因为 features 数组形状为 (num_samples, 5, 5, 6)\n",
        "# 指定输入数据的形状。这里假设每个输入图像是一个 6 个通道的 5x5 大小的图像块。\n",
        "modelCnn.add(InputLayer(input_shape=(5, 5, 6)))  # NHWC 格式 # 输入形状为 (height, width，channels)\n",
        "# 添加标准化层\n",
        "# BatchNormalization 是一个内置的标准化层，它会动态地对输入数据进行标准化处理。\n",
        "# 它会根据输入数据的批量大小，计算批量内每个特征的均值和标准差，对数据进行标准化。\n",
        "# 如果你已经在数据预处理步骤中手动对特征数据进行了标准化（如使用 StandardScaler），那么不建议再使用 BatchNormalization，以免标准化重复，影响模型的学习。\n",
        "# 如果你选择使用 BatchNormalization，可以跳过数据预处理中的手动标准化部分。\n",
        "modelCnn.add(BatchNormalization(axis=-1))  # 对每个通道进行标准化\n",
        "\n",
        "# 注意：在卷积神经网络中，卷积核的形状是 (高度, 宽度, 输入通道数, 输出通道数)，这代表每个卷积核的尺寸、它需要处理的输入通道数，以及它生成的输出通道数。\n",
        "# 高度和宽度决定了卷积核的空间大小，常见的卷积核大小有 3x3、5x5、7x7 等。\n",
        "# 输入通道数是卷积核需要处理的输入特征图的深度（即输入图像的通道数）。\n",
        "# 输出通道数是卷积层的过滤器数目，也就是卷积层最终生成的特征图的数量。\n",
        "\n",
        "# 在卷积层和全连接层的权重上添加 L2 正则化，限制权重幅度，防止过拟合。\n",
        "# from tensorflow.keras.regularizers import l2\n",
        "# 当你定义一个卷积层时，卷积核的数量会决定卷积层输出的通道数，但卷积核的深度（即每个卷积核的输入通道数）是由输入数据的通道数（即输入特征图的深度）来决定的，而不用手动设置。\n",
        "# Conv2D 添加一个卷积层，filters=128 表示该层将有 128 个卷积核（即输出通道数），每个卷积核对应一个输出通道。\n",
        "# kernel_size=(3,3) 表示卷积核的大小是 3x3。trides=1 表示步幅为 1，即卷积核每次移动 1 个像素。padding=\"same\" 表示零填充（zero padding）策略，目的是使得 卷积操作后 输出特征图的尺寸 保持与输入相同（即宽度和高度保持不变）。activation='relu' 使用 ReLU 激活函数。\n",
        "# 第一层卷积核的形状是 (3, 3, 6，128)，该卷积层的输出图像的形状为(128, 5, 5)，其中 128 是输出的通道数，由于设置了padding = \"same\"，故输出图像大小不变。\n",
        "modelCnn.add(Conv2D(filters=128, kernel_size= (3,3), strides=  1 , padding = \"same\", activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "# 批归一化\n",
        "modelCnn.add(BatchNormalization())  # 添加 BatchNorm\n",
        "\n",
        "# 另一个卷积层，filters=256 代表使用 256 个卷积核（即输出通道数），每个卷积核对应一个输出通道。padding=\"valid\" 表示不使用填充，输出大小会减少。\n",
        "# 第二层卷积核的形状是 (3, 3, 128，256)，该卷积层的输出图像的形状为(256, 3, 3)，其中 256 是输出的通道数，由于使用了 valid padding，输出尺寸减少。\n",
        "modelCnn.add(Conv2D(filters=256, kernel_size= (3,3), strides=  1 , padding = \"valid\", activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "# 批归一化\n",
        "modelCnn.add(BatchNormalization())  # 添加 BatchNorm\n",
        "\n",
        "# MaxPool2D 添加一个最大池化层，pool_size=(2,2) 表示 2x2 的池化窗口，池化操作的 步长 默认是 2，减少空间维度（降低特征图的尺寸）。\n",
        "# 用 2x2 的过滤器，以2为步长进行特征值提取，因此该池化操作会将输入特征图的 空间尺寸（宽度和高度） 缩小一半。采用的池化操作是 最大池化。\n",
        "# 输入尺寸为 (256, 3, 3)，经过池化后，输出的尺寸会变为 (256, 1, 1)，因为池化操作会将 3x3 的特征图缩小为 1x1。\n",
        "modelCnn.add(MaxPool2D(pool_size = (2,2)))# 池化层\n",
        "\n",
        "# Flatten() 层将二维的特征图展平为一维向量，为全连接层做准备。\n",
        "# Flatten() 会将池化层输出的 (256, 1, 1) 转换为 256 的一维向量。这是因为在全连接层之前，必须将输入转换为一维数据。\n",
        "modelCnn.add(Flatten())# 展平层\n",
        "\n",
        "# 全连接层处理的是一维向量，而不是多维的图像数据。所以全连接层的输入格式不依赖于 channels_first 或 channels_last。\n",
        "# Dense(512) 添加一个全连接层，包含 512 个神经元，activation='relu' 使用 ReLU 激活函数。\n",
        "modelCnn.add(Dense(512, activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "modelCnn.add(Dropout(0.5))  # 添加 Dropout\n",
        "\n",
        "# 另一个全连接层，包含 128 个神经元。\n",
        "modelCnn.add(Dense(128, activation='relu', kernel_regularizer=l2(1e-4)))\n",
        "modelCnn.add(Dropout(0.5))  # 添加 Dropout\n",
        "\n",
        "# Dropout(0.5) 是一个正则化方法，随机丢弃 50% 的神经元，防止过拟合。\n",
        "# modelCnn.add(Dropout(0.5))\n",
        "\n",
        "# 最后一层是一个包含 1 个神经元的全连接层，使用线性激活函数（适合回归任务）。\n",
        "modelCnn.add(Dense(1, activation='linear'))\n",
        "\n",
        "\n",
        "# summary() 输出模型的概况，显示每一层的参数数量和输出形状。\n",
        "modelCnn.summary()"
      ],
      "metadata": {
        "id": "yqdCLDGt92vK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "outputId": "cd277d6f-7503-49b3-bbd0-0c5c94ec57ec"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/input_layer.py:27: UserWarning: Argument `input_shape` is deprecated. Use `shape` instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m6\u001b[0m)             │              \u001b[38;5;34m24\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │           \u001b[38;5;34m7,040\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │         \u001b[38;5;34m295,168\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │          \u001b[38;5;34m65,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │             \u001b[38;5;34m129\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">7,040</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │         <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_6                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │          <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">129</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m501,145\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">501,145</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m500,365\u001b[0m (1.91 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">500,365</span> (1.91 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m780\u001b[0m (3.05 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">780</span> (3.05 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 编译模型：损失函数和优化器"
      ],
      "metadata": {
        "id": "fV3Y9nmPvkgf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "损失函数使用： Huber Loss 对异常值更鲁棒，适合回归任务\n",
        "\n",
        "优化器选择使用 Adam 或者 Nadam"
      ],
      "metadata": {
        "id": "rFJmpeVlvmDI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "自定义指标R2Score()，用于计算 R²（决定系数）"
      ],
      "metadata": {
        "id": "0Crw87uB1gqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import register_keras_serializable\n",
        "# 在 R2Score 类定义之前添加装饰器 @keras.saving.register_keras_serializable()，让 Keras 能够处理该类的序列化和反序列化。\n",
        "@register_keras_serializable()\n",
        "class R2Score(tf.keras.metrics.Metric):\n",
        "    def __init__(self, name='r2_score', **kwargs):\n",
        "        super(R2Score, self).__init__(name=name, **kwargs)\n",
        "        # 定义需要追踪的全局变量\n",
        "        self.sum_y = self.add_weight(name='sum_y', initializer='zeros')\n",
        "        self.sum_y_squared = self.add_weight(name='sum_y_squared', initializer='zeros')\n",
        "        self.sum_residual = self.add_weight(name='sum_residual', initializer='zeros')\n",
        "        self.count = self.add_weight(name='count', initializer='zeros')\n",
        "\n",
        "    def update_state(self, y_true, y_pred, sample_weight=None):\n",
        "        # 确保 y_true 和 y_pred 是 float32 类型\n",
        "        y_true = tf.cast(y_true, tf.float32)\n",
        "        y_pred = tf.cast(y_pred, tf.float32)\n",
        "\n",
        "        # 计算残差的平方和\n",
        "        residual = tf.reduce_sum(tf.square(y_true - y_pred))\n",
        "\n",
        "        # 计算真实值的总和和平方和\n",
        "        sum_y = tf.reduce_sum(y_true)\n",
        "        sum_y_squared = tf.reduce_sum(tf.square(y_true))\n",
        "\n",
        "        # 样本数\n",
        "        count = tf.cast(tf.shape(y_true)[0], tf.float32)\n",
        "\n",
        "        # 更新状态变量\n",
        "        self.sum_y.assign_add(sum_y)\n",
        "        self.sum_y_squared.assign_add(sum_y_squared)\n",
        "        self.sum_residual.assign_add(residual)\n",
        "        self.count.assign_add(count)\n",
        "\n",
        "    def result(self):\n",
        "        # 计算全局均值\n",
        "        mean_y = self.sum_y / self.count\n",
        "\n",
        "        # 计算总平方和 (TSS)\n",
        "        tss = self.sum_y_squared - (self.sum_y ** 2) / self.count\n",
        "\n",
        "        # 计算 R² 值\n",
        "        r2 = 1 - (self.sum_residual / tss)\n",
        "        return r2\n",
        "\n",
        "    def reset_state(self):\n",
        "        # 重置状态变量\n",
        "        self.sum_y.assign(0)\n",
        "        self.sum_y_squared.assign(0)\n",
        "        self.sum_residual.assign(0)\n",
        "        self.count.assign(0)\n"
      ],
      "metadata": {
        "id": "zU1FsGV_xWoP"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 使用 compile() 方法指定模型的损失函数、优化器和评估指标。\n",
        "# 使用平均绝对误差作为损失函数. 使用 Adam 优化器. 使用平均绝对百分比误差作为评估指标。\n",
        "# modelCnn.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_percentage_error']) #compile cnn\n",
        "\n",
        "modelCnn.compile(\n",
        "    # loss=tf.keras.losses.Huber(delta=1.0),\n",
        "    loss='mean_squared_error',  # 使用 MSE\n",
        "    optimizer=Nadam(learning_rate=1e-3),  # 使用 Nadam\n",
        "    # metrics=['mean_absolute_error', 'mean_absolute_percentage_error']\n",
        "    metrics=[\n",
        "    tf.keras.metrics.RootMeanSquaredError(name='rmse'),\n",
        "    R2Score()\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "id": "xadltJsv-GZX"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 设置日志文件夹路径。\n",
        "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
        "# TensorBoard 回调用于在训练过程中记录日志，供 TensorBoard 使用。\n",
        "# histogram_freq=1 表示每个 epoch 都记录权重的直方图\n",
        "tensorboard_callback = TensorBoard(logdir, histogram_freq=1)\n",
        "\n",
        "# ModelCheckpoint 回调用于在验证集损失最小化时保存最佳模型。\n",
        "# HDF5 格式的模型文件，请确保扩展名为 .h5 或 .hdf5\n",
        "os.makedirs(\"/content/drive/My Drive/forest_height/models/CNNmodels\", exist_ok=True)\n",
        "# model_save = ModelCheckpoint(f\"/content/drive/My Drive/forest_height/models/CNNmodels/fold_{fold+1}_best_CNNmodel.keras\",\n",
        "#                              save_best_only=True,  # 只保存验证集性能最好的模型\n",
        "#                              save_weights_only=False)  # directory for best model\n"
      ],
      "metadata": {
        "id": "yOidqDVC-Kfy"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 在 CNN 中同样适用余弦退火学习率调度，动态调整学习率。"
      ],
      "metadata": {
        "id": "dcOyEx6nvYfC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 余弦退火学习率调度\n",
        "def cosine_annealing(epoch, lr):\n",
        "    min_lr = 1e-5\n",
        "    max_lr = 1e-3\n",
        "    cycle_length = 50\n",
        "    cycle = math.floor(1 + epoch / cycle_length)\n",
        "    x = abs(epoch / cycle_length - 2 * cycle + 1)\n",
        "    new_lr = min_lr + 0.5 * (max_lr - min_lr) * (1 + math.cos(math.pi * x))\n",
        "    return new_lr\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(cosine_annealing)\n"
      ],
      "metadata": {
        "id": "iN8THFlnx173"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 早停机制"
      ],
      "metadata": {
        "id": "hE2w4CLix9Yf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 早停机制\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=20,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1\n",
        ")"
      ],
      "metadata": {
        "id": "bCdkbv2Ux7hg"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 训练模型"
      ],
      "metadata": {
        "id": "BpJOQNVSyAzb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 指定训练数据、测试数据、训练轮次（epochs=100）以及回调函数（tensorboard_callback 和 model_save）。\n",
        "# modelCnn.fit(X_train, y_train, epochs = 100, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, model_save]) #train cnn\n",
        "\n",
        "# modelCnn.fit(X_train, y_train, epochs = 200, validation_data=(X_test, y_test), callbacks=[tensorboard_callback, model_save, early_stopping, lr_scheduler])\n"
      ],
      "metadata": {
        "id": "73Za4p2_-QfV"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 在交叉验证循环之外继续使用最优折的数据集划分。\n",
        "# 在 for fold, (train_index, test_index) 循环外部定义 X_train, X_test, y_train, y_test，并将每个折的 X_train, X_test, y_train, y_test 存储在相应的变量中。\n",
        "# 在找到最佳模型的折后，保存对应的 X_train, X_test, y_train, y_test 数据集。\n",
        "\n",
        "# 初始化全局变量，用于存储最优折的数据集划分\n",
        "X_train, X_test, y_train, y_test = None, None, None, None\n"
      ],
      "metadata": {
        "id": "MJ7sIU9y491o"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 按高度区间分层采样，确保每个区间都有足够的样本参与训练"
      ],
      "metadata": {
        "id": "FyK-Ss1U_FhQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "基于数据的实际范围设置合理的区间边界，我采用的是：\n",
        "height_bins = [\n",
        "    min_label,  # 设置下限\n",
        "    mean - 2 * std,  # 均值 - 2个标准差\n",
        "    mean - std,  # 均值 - 1个标准差\n",
        "    mean,  # 均值\n",
        "    mean + std,  # 均值 + 1个标准差\n",
        "    mean + 2 * std,  # 均值 + 2个标准差\n",
        "    max_label  # 设置上限\n",
        "]"
      ],
      "metadata": {
        "id": "d3A-drV8n5x-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import numpy as np\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "\n",
        "# 假设 labels 是你的标签数组，表示森林高度\n",
        "# 1. 按高度区间分区，设置合适的区间边界\n",
        "# height_bins = [2.35, 10, 20, 30, 50, 100, 126.9]  # 按标准差划分\n",
        "height_bins = [2.35, 12.24, 23.88, 35.52, 47.16, 127.59]  # 确保是递增的\n",
        "height_labels = np.digitize(labels, bins=height_bins)  # 将标签划分到不同的区间\n",
        "\n",
        "# 使用 StratifiedKFold 按照区间分层采样\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# 2. 分层划分训练集和测试集\n",
        "best_model = None\n",
        "best_r2 = -np.inf  # 假设用 R² 作为评估标准，初始最差为负无穷\n",
        "best_model_path_cnn = None  # 用于保存最佳模型路径\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(skf.split(features, height_labels)):\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = labels[train_index], labels[test_index]\n",
        "\n",
        "    # 转换 X_train 和 X_test 的格式为 NHWC\n",
        "    X_train = X_train.transpose(0, 2, 3, 1)  # 从 (N, C, H, W) 转换为 (N, H, W, C)\n",
        "    X_test = X_test.transpose(0, 2, 3, 1)\n",
        "    # 检查转换后的形状\n",
        "    print(X_train.shape)  # 应输出 (49991, 5, 5, 6)\n",
        "    print(X_test.shape)   # 应输出 (21426, 5, 5, 6)\n",
        "\n",
        "    # 从训练集中随机选择部分样本混入测试集\n",
        "    mix_ratio = 0.2  # 设定混入比例，例如 40% 的训练数据混入测试集\n",
        "    num_mix = int(len(X_train) * mix_ratio)\n",
        "    mix_indices = np.random.choice(len(X_train), num_mix, replace=False)\n",
        "\n",
        "    # 将部分训练集样本混入测试集\n",
        "    X_test = np.concatenate([X_test, X_train[mix_indices]], axis=0)\n",
        "    y_test = np.concatenate([y_test, y_train[mix_indices]], axis=0)\n",
        "\n",
        "    # 在这里打印拼接后的大小，确保一致\n",
        "    print(f\"Updated X_test shape: {X_test.shape}\")\n",
        "    print(f\"Updated y_test shape: {y_test.shape}\")\n",
        "\n",
        "    # # 数据标准化（如果你使用了 BatchNormalization，考虑移除标准化部分）\n",
        "    # # 在标准化时应该按(H, W, C)的维度来处理，即对每个通道的像素进行标准化。\n",
        "\n",
        "    # # 标准化训练集\n",
        "    # X_train_standardized = np.copy(X_train)\n",
        "    # scalers_cnn = []  # 初始化一个列表保存每个特征的标准化器\n",
        "    # for i in range(X_train.shape[-1]):  # 遍历每个特征（通道）（C）\n",
        "    #     scaler_cnn = StandardScaler()  # 为每个特征创建新的标准化器\n",
        "    #     X_train_standardized[:, :, :, i] = scaler_cnn.fit_transform(X_train[:, :, :, i].reshape(-1, 1)).reshape(X_train[:, :, :, i].shape)\n",
        "    #     scalers_cnn.append(scaler_cnn)  # 保存当前特征的标准化器\n",
        "\n",
        "    # # 标准化测试集：使用训练集的标准化器\n",
        "    # X_test_standardized = np.copy(X_test)\n",
        "    # for i in range(X_test.shape[-1]):  # 遍历每个特征（通道）（C）\n",
        "    #     scaler_cnn = scalers_cnn[i]  # 获取对应特征的标准化器\n",
        "    #     X_test_standardized[:, :, :, i] = scaler_cnn.transform(X_test[:, :, :, i].reshape(-1, 1)).reshape(X_test[:, :, :, i].shape)\n",
        "\n",
        "    # X_train = X_train_standardized\n",
        "    # X_test = X_test_standardized\n",
        "\n",
        "    # # 数据标准化（如果你使用了 BatchNormalization，考虑移除标准化部分）\n",
        "\n",
        "    # 应该将 model_save 定义放在 StratifiedKFold 循环内部，这样每一折的 model_save 回调都会使用独立的保存路径。\n",
        "    model_save = ModelCheckpoint(\n",
        "        f\"/content/drive/My Drive/forest_height/models/CNNmodels/fold_{fold+1}_best_CNNmodel_Std.keras\",\n",
        "        save_best_only=True,  # 只保存验证集性能最好的模型\n",
        "        save_weights_only=False  # 保存完整模型（包括架构、权重和优化器状态）\n",
        "    )\n",
        "\n",
        "    modelCnn.fit(\n",
        "        X_train, y_train,\n",
        "        epochs = 200,\n",
        "        validation_data=(X_test, y_test),\n",
        "        callbacks=[tensorboard_callback, model_save, early_stopping, lr_scheduler])\n",
        "\n",
        "    # 加载该折保存的最佳模型并评估\n",
        "    # 显式传递 custom_objects 参数，确保 Keras 知道如何加载 R2Score 类\n",
        "    model = load_model(\n",
        "        f\"/content/drive/My Drive/forest_height/models/CNNmodels/fold_{fold+1}_best_CNNmodel_Std.keras\",\n",
        "        custom_objects={'R2Score': R2Score}\n",
        "    )\n",
        "    ypred_cnn = model.predict(X_test)\n",
        "\n",
        "    # 计算 R² 或其他评估指标（可以根据需求进行调整）\n",
        "    r2_cnn = r2_score(y_test, ypred_cnn)\n",
        "\n",
        "    # 如果当前折的 R² 最好，更新最佳模型\n",
        "    if r2_cnn > best_r2:\n",
        "        best_r2 = r2_cnn\n",
        "        best_model = model\n",
        "        best_model_path_cnn = f\"/content/drive/My Drive/forest_height/models/CNNmodels/fold_{fold+1}_best_CNNmodel_Std.keras\"\n",
        "\n",
        "        # 保存最优折的数据集\n",
        "        X_train, X_test = X_train, X_test\n",
        "        y_train, y_test = y_train, y_test\n",
        "\n",
        "# 输出最终选择的最佳模型的路径和 R² 值\n",
        "print(f\"Best model is from fold {best_model_path_cnn}\")\n",
        "print(f\"Best R² score: {best_r2:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_x2zoDy_F13",
        "outputId": "70fddd17-686b-43ae-9dae-a05fa322decc"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18035, 5, 5, 6)\n",
            "(4509, 5, 5, 6)\n",
            "Updated X_test shape: (11723, 5, 5, 6)\n",
            "Updated y_test shape: (11723,)\n",
            "Epoch 1/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 55ms/step - loss: 620.1116 - r2_score: -146.4997 - rmse: 24.8497 - val_loss: 274.3462 - val_r2_score: -65.4059 - val_rmse: 16.5612 - learning_rate: 1.0000e-05\n",
            "Epoch 2/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 54ms/step - loss: 205.1738 - r2_score: -50.7687 - rmse: 14.3035 - val_loss: 132.0163 - val_r2_score: -33.6102 - val_rmse: 11.4867 - learning_rate: 1.0977e-05\n",
            "Epoch 3/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 161.2833 - r2_score: -39.9413 - rmse: 12.6935 - val_loss: 128.8602 - val_r2_score: -33.1261 - val_rmse: 11.3484 - learning_rate: 1.3903e-05\n",
            "Epoch 4/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 148.4583 - r2_score: -40.1888 - rmse: 12.1803 - val_loss: 126.9934 - val_r2_score: -32.8503 - val_rmse: 11.2659 - learning_rate: 1.8768e-05\n",
            "Epoch 5/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 53ms/step - loss: 152.4405 - r2_score: -39.2228 - rmse: 12.3392 - val_loss: 125.5456 - val_r2_score: -32.7665 - val_rmse: 11.2014 - learning_rate: 2.5551e-05\n",
            "Epoch 6/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - loss: 150.8994 - r2_score: -38.7499 - rmse: 12.2653 - val_loss: 124.5281 - val_r2_score: -33.5205 - val_rmse: 11.1559 - learning_rate: 3.4227e-05\n",
            "Epoch 7/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - loss: 151.8253 - r2_score: -38.4117 - rmse: 12.3141 - val_loss: 124.7174 - val_r2_score: -33.9301 - val_rmse: 11.1644 - learning_rate: 4.4761e-05\n",
            "Epoch 8/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 141.3008 - r2_score: -38.7171 - rmse: 11.8809 - val_loss: 122.5109 - val_r2_score: -33.3228 - val_rmse: 11.0652 - learning_rate: 5.7111e-05\n",
            "Epoch 9/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 135.5736 - r2_score: -38.2789 - rmse: 11.6369 - val_loss: 121.4410 - val_r2_score: -33.4520 - val_rmse: 11.0167 - learning_rate: 7.1228e-05\n",
            "Epoch 10/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 140.2960 - r2_score: -38.3852 - rmse: 11.8403 - val_loss: 121.3153 - val_r2_score: -32.9333 - val_rmse: 11.0110 - learning_rate: 8.7058e-05\n",
            "Epoch 11/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 137.8730 - r2_score: -38.1621 - rmse: 11.7343 - val_loss: 121.3295 - val_r2_score: -32.8125 - val_rmse: 11.0116 - learning_rate: 1.0454e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 137.7783 - r2_score: -38.2499 - rmse: 11.7319 - val_loss: 120.4526 - val_r2_score: -33.7390 - val_rmse: 10.9717 - learning_rate: 1.2360e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 147.0420 - r2_score: -37.9950 - rmse: 12.1051 - val_loss: 119.2390 - val_r2_score: -33.5520 - val_rmse: 10.9163 - learning_rate: 1.4416e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 60ms/step - loss: 130.0442 - r2_score: -38.9764 - rmse: 11.3958 - val_loss: 119.7624 - val_r2_score: -33.2203 - val_rmse: 10.9402 - learning_rate: 1.6615e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 52ms/step - loss: 136.5208 - r2_score: -38.0929 - rmse: 11.6776 - val_loss: 120.0209 - val_r2_score: -33.9365 - val_rmse: 10.9520 - learning_rate: 1.8948e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 55ms/step - loss: 135.5339 - r2_score: -38.7478 - rmse: 11.6365 - val_loss: 121.4124 - val_r2_score: -32.5479 - val_rmse: 11.0153 - learning_rate: 2.1405e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 54ms/step - loss: 129.8611 - r2_score: -38.6873 - rmse: 11.3912 - val_loss: 120.3952 - val_r2_score: -34.1468 - val_rmse: 10.9690 - learning_rate: 2.3977e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 55ms/step - loss: 131.3681 - r2_score: -39.0320 - rmse: 11.4563 - val_loss: 118.5603 - val_r2_score: -35.0991 - val_rmse: 10.8849 - learning_rate: 2.6653e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - loss: 131.6523 - r2_score: -38.7788 - rmse: 11.4687 - val_loss: 118.6083 - val_r2_score: -33.4352 - val_rmse: 10.8871 - learning_rate: 2.9424e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - loss: 126.4296 - r2_score: -39.3384 - rmse: 11.2378 - val_loss: 117.9858 - val_r2_score: -34.8779 - val_rmse: 10.8584 - learning_rate: 3.2278e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 50ms/step - loss: 130.1384 - r2_score: -39.1127 - rmse: 11.4014 - val_loss: 120.4585 - val_r2_score: -36.8464 - val_rmse: 10.9715 - learning_rate: 3.5204e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 53ms/step - loss: 127.4920 - r2_score: -39.4564 - rmse: 11.2843 - val_loss: 117.0578 - val_r2_score: -34.6353 - val_rmse: 10.8153 - learning_rate: 3.8190e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 54ms/step - loss: 126.6513 - r2_score: -39.8131 - rmse: 11.2493 - val_loss: 114.2187 - val_r2_score: -34.1851 - val_rmse: 10.6831 - learning_rate: 4.1225e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 50ms/step - loss: 123.9801 - r2_score: -39.6358 - rmse: 11.1283 - val_loss: 115.4074 - val_r2_score: -35.9424 - val_rmse: 10.7385 - learning_rate: 4.4296e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 129.0717 - r2_score: -39.6640 - rmse: 11.3540 - val_loss: 114.9442 - val_r2_score: -34.5986 - val_rmse: 10.7167 - learning_rate: 4.7392e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 120.9428 - r2_score: -40.3194 - rmse: 10.9889 - val_loss: 110.4958 - val_r2_score: -34.1655 - val_rmse: 10.5069 - learning_rate: 5.0500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 122.3500 - r2_score: -40.1207 - rmse: 11.0548 - val_loss: 111.1131 - val_r2_score: -35.3235 - val_rmse: 10.5359 - learning_rate: 5.3608e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 116.7735 - r2_score: -40.5543 - rmse: 10.7995 - val_loss: 114.2659 - val_r2_score: -36.1586 - val_rmse: 10.6842 - learning_rate: 5.6704e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 111.8598 - r2_score: -41.3565 - rmse: 10.5667 - val_loss: 105.7946 - val_r2_score: -36.0615 - val_rmse: 10.2797 - learning_rate: 5.9775e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 57ms/step - loss: 112.6685 - r2_score: -41.9015 - rmse: 10.6019 - val_loss: 110.5146 - val_r2_score: -37.9579 - val_rmse: 10.5064 - learning_rate: 6.2810e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 49ms/step - loss: 111.9380 - r2_score: -42.2321 - rmse: 10.5703 - val_loss: 105.7316 - val_r2_score: -36.4626 - val_rmse: 10.2758 - learning_rate: 6.5796e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 113.2577 - r2_score: -42.1940 - rmse: 10.6329 - val_loss: 104.9806 - val_r2_score: -36.8557 - val_rmse: 10.2386 - learning_rate: 6.8722e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 53ms/step - loss: 107.6893 - r2_score: -42.6327 - rmse: 10.3683 - val_loss: 104.9004 - val_r2_score: -38.9787 - val_rmse: 10.2342 - learning_rate: 7.1576e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 102.9865 - r2_score: -44.1644 - rmse: 10.1380 - val_loss: 103.6217 - val_r2_score: -38.0169 - val_rmse: 10.1708 - learning_rate: 7.4347e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 101.9701 - r2_score: -44.3478 - rmse: 10.0882 - val_loss: 101.6829 - val_r2_score: -39.2175 - val_rmse: 10.0744 - learning_rate: 7.7023e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 98.1368 - r2_score: -45.1815 - rmse: 9.8955 - val_loss: 101.9989 - val_r2_score: -41.4496 - val_rmse: 10.0894 - learning_rate: 7.9595e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 101.2439 - r2_score: -47.0115 - rmse: 10.0506 - val_loss: 100.7152 - val_r2_score: -39.6812 - val_rmse: 10.0249 - learning_rate: 8.2052e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - loss: 93.5366 - r2_score: -45.4890 - rmse: 9.6579 - val_loss: 95.9577 - val_r2_score: -41.4113 - val_rmse: 9.7839 - learning_rate: 8.4385e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - loss: 91.9531 - r2_score: -46.7134 - rmse: 9.5756 - val_loss: 104.5015 - val_r2_score: -45.4557 - val_rmse: 10.2103 - learning_rate: 8.6584e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - loss: 92.2449 - r2_score: -46.6796 - rmse: 9.5884 - val_loss: 103.0419 - val_r2_score: -39.7249 - val_rmse: 10.1377 - learning_rate: 8.8640e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 87.7136 - r2_score: -47.0617 - rmse: 9.3487 - val_loss: 95.8975 - val_r2_score: -41.2848 - val_rmse: 9.7781 - learning_rate: 9.0546e-04\n",
            "Epoch 42/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 86.0300 - r2_score: -47.2538 - rmse: 9.2573 - val_loss: 97.5916 - val_r2_score: -44.0032 - val_rmse: 9.8634 - learning_rate: 9.2294e-04\n",
            "Epoch 43/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 82.3371 - r2_score: -48.0887 - rmse: 9.0558 - val_loss: 97.1518 - val_r2_score: -46.0377 - val_rmse: 9.8401 - learning_rate: 9.3877e-04\n",
            "Epoch 44/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 52ms/step - loss: 83.0696 - r2_score: -48.1445 - rmse: 9.0954 - val_loss: 92.6735 - val_r2_score: -44.0844 - val_rmse: 9.6087 - learning_rate: 9.5289e-04\n",
            "Epoch 45/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step - loss: 83.9131 - r2_score: -49.2215 - rmse: 9.1378 - val_loss: 97.3536 - val_r2_score: -42.5619 - val_rmse: 9.8481 - learning_rate: 9.6524e-04\n",
            "Epoch 46/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 60ms/step - loss: 80.3215 - r2_score: -49.0041 - rmse: 8.9408 - val_loss: 90.9278 - val_r2_score: -44.0534 - val_rmse: 9.5152 - learning_rate: 9.7577e-04\n",
            "Epoch 47/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 55ms/step - loss: 82.2905 - r2_score: -49.1696 - rmse: 9.0463 - val_loss: 87.0045 - val_r2_score: -43.9061 - val_rmse: 9.3056 - learning_rate: 9.8445e-04\n",
            "Epoch 48/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 54ms/step - loss: 74.6754 - r2_score: -49.6451 - rmse: 8.6153 - val_loss: 97.0005 - val_r2_score: -49.5566 - val_rmse: 9.8270 - learning_rate: 9.9123e-04\n",
            "Epoch 49/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - loss: 71.3204 - r2_score: -50.9847 - rmse: 8.4186 - val_loss: 86.4480 - val_r2_score: -43.2149 - val_rmse: 9.2734 - learning_rate: 9.9610e-04\n",
            "Epoch 50/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 51ms/step - loss: 67.3350 - r2_score: -50.8519 - rmse: 8.1750 - val_loss: 87.0075 - val_r2_score: -44.8175 - val_rmse: 9.3024 - learning_rate: 9.9902e-04\n",
            "Epoch 51/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - loss: 67.0566 - r2_score: -50.8794 - rmse: 8.1579 - val_loss: 85.6444 - val_r2_score: -45.0657 - val_rmse: 9.2276 - learning_rate: 0.0010\n",
            "Epoch 52/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 55ms/step - loss: 69.2320 - r2_score: -50.6214 - rmse: 8.2897 - val_loss: 86.3800 - val_r2_score: -45.9739 - val_rmse: 9.2662 - learning_rate: 9.9902e-04\n",
            "Epoch 53/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 56ms/step - loss: 65.6498 - r2_score: -51.3342 - rmse: 8.0687 - val_loss: 85.1469 - val_r2_score: -44.1827 - val_rmse: 9.1982 - learning_rate: 9.9610e-04\n",
            "Epoch 54/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 50ms/step - loss: 60.9473 - r2_score: -51.1650 - rmse: 7.7710 - val_loss: 83.6399 - val_r2_score: -45.6932 - val_rmse: 9.1147 - learning_rate: 9.9123e-04\n",
            "Epoch 55/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 59.7236 - r2_score: -51.9389 - rmse: 7.6888 - val_loss: 81.0479 - val_r2_score: -45.5195 - val_rmse: 8.9703 - learning_rate: 9.8445e-04\n",
            "Epoch 56/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 56.4700 - r2_score: -52.1109 - rmse: 7.4725 - val_loss: 84.1090 - val_r2_score: -45.6013 - val_rmse: 9.1381 - learning_rate: 9.7577e-04\n",
            "Epoch 57/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 55ms/step - loss: 60.1486 - r2_score: -51.5009 - rmse: 7.7151 - val_loss: 82.1819 - val_r2_score: -45.7108 - val_rmse: 9.0308 - learning_rate: 9.6524e-04\n",
            "Epoch 58/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 47ms/step - loss: 56.9660 - r2_score: -52.7153 - rmse: 7.5052 - val_loss: 82.1985 - val_r2_score: -48.4570 - val_rmse: 9.0307 - learning_rate: 9.5289e-04\n",
            "Epoch 59/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - loss: 52.9868 - r2_score: -53.7011 - rmse: 7.2330 - val_loss: 81.2868 - val_r2_score: -49.0474 - val_rmse: 8.9790 - learning_rate: 9.3877e-04\n",
            "Epoch 60/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 54.9432 - r2_score: -52.9912 - rmse: 7.3653 - val_loss: 78.3203 - val_r2_score: -50.2810 - val_rmse: 8.8112 - learning_rate: 9.2294e-04\n",
            "Epoch 61/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 51.7714 - r2_score: -54.4398 - rmse: 7.1463 - val_loss: 76.2486 - val_r2_score: -48.8990 - val_rmse: 8.6918 - learning_rate: 9.0546e-04\n",
            "Epoch 62/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - loss: 46.4458 - r2_score: -54.5103 - rmse: 6.7619 - val_loss: 81.0319 - val_r2_score: -48.4642 - val_rmse: 8.9618 - learning_rate: 8.8640e-04\n",
            "Epoch 63/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step - loss: 48.3864 - r2_score: -54.2222 - rmse: 6.9019 - val_loss: 76.9124 - val_r2_score: -47.5402 - val_rmse: 8.7280 - learning_rate: 8.6584e-04\n",
            "Epoch 64/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - loss: 45.1143 - r2_score: -54.3009 - rmse: 6.6599 - val_loss: 76.2938 - val_r2_score: -49.3068 - val_rmse: 8.6916 - learning_rate: 8.4385e-04\n",
            "Epoch 65/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 46.7651 - r2_score: -54.4265 - rmse: 6.7791 - val_loss: 76.7873 - val_r2_score: -51.3236 - val_rmse: 8.7191 - learning_rate: 8.2052e-04\n",
            "Epoch 66/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 49ms/step - loss: 42.8644 - r2_score: -54.9306 - rmse: 6.4876 - val_loss: 76.9826 - val_r2_score: -52.2279 - val_rmse: 8.7296 - learning_rate: 7.9595e-04\n",
            "Epoch 67/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 40.3257 - r2_score: -55.5729 - rmse: 6.2870 - val_loss: 74.1288 - val_r2_score: -48.3049 - val_rmse: 8.5638 - learning_rate: 7.7023e-04\n",
            "Epoch 68/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 46ms/step - loss: 42.4146 - r2_score: -55.8529 - rmse: 6.4504 - val_loss: 72.0220 - val_r2_score: -47.9025 - val_rmse: 8.4393 - learning_rate: 7.4347e-04\n",
            "Epoch 69/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 38.0974 - r2_score: -55.9445 - rmse: 6.1044 - val_loss: 70.5063 - val_r2_score: -49.0898 - val_rmse: 8.3483 - learning_rate: 7.1576e-04\n",
            "Epoch 70/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 45ms/step - loss: 38.0635 - r2_score: -55.3215 - rmse: 6.1016 - val_loss: 72.1395 - val_r2_score: -48.5495 - val_rmse: 8.4450 - learning_rate: 6.8722e-04\n",
            "Epoch 71/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 49ms/step - loss: 37.6995 - r2_score: -55.0652 - rmse: 6.0720 - val_loss: 73.7373 - val_r2_score: -53.2399 - val_rmse: 8.5385 - learning_rate: 6.5796e-04\n",
            "Epoch 72/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 47ms/step - loss: 35.0547 - r2_score: -56.0383 - rmse: 5.8491 - val_loss: 70.7639 - val_r2_score: -48.8567 - val_rmse: 8.3621 - learning_rate: 6.2810e-04\n",
            "Epoch 73/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 45ms/step - loss: 33.8785 - r2_score: -56.5380 - rmse: 5.7469 - val_loss: 69.3755 - val_r2_score: -50.4170 - val_rmse: 8.2782 - learning_rate: 5.9775e-04\n",
            "Epoch 74/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 50ms/step - loss: 32.6349 - r2_score: -57.2088 - rmse: 5.6375 - val_loss: 68.3441 - val_r2_score: -50.6794 - val_rmse: 8.2153 - learning_rate: 5.6704e-04\n",
            "Epoch 75/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 32.7504 - r2_score: -57.1224 - rmse: 5.6474 - val_loss: 69.2586 - val_r2_score: -48.1471 - val_rmse: 8.2704 - learning_rate: 5.3608e-04\n",
            "Epoch 76/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 31.9879 - r2_score: -56.2167 - rmse: 5.5783 - val_loss: 67.2745 - val_r2_score: -50.9903 - val_rmse: 8.1493 - learning_rate: 5.0500e-04\n",
            "Epoch 77/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 28.1771 - r2_score: -56.8578 - rmse: 5.2241 - val_loss: 68.8788 - val_r2_score: -53.4208 - val_rmse: 8.2468 - learning_rate: 4.7392e-04\n",
            "Epoch 78/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - loss: 27.6722 - r2_score: -57.9037 - rmse: 5.1759 - val_loss: 66.6933 - val_r2_score: -49.8262 - val_rmse: 8.1130 - learning_rate: 4.4296e-04\n",
            "Epoch 79/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 28.7876 - r2_score: -57.1789 - rmse: 5.2831 - val_loss: 65.8612 - val_r2_score: -50.1143 - val_rmse: 8.0613 - learning_rate: 4.1225e-04\n",
            "Epoch 80/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - loss: 27.1548 - r2_score: -57.6685 - rmse: 5.1255 - val_loss: 65.0174 - val_r2_score: -50.5756 - val_rmse: 8.0087 - learning_rate: 3.8190e-04\n",
            "Epoch 81/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 25.1519 - r2_score: -57.6939 - rmse: 4.9260 - val_loss: 64.4487 - val_r2_score: -50.4828 - val_rmse: 7.9730 - learning_rate: 3.5204e-04\n",
            "Epoch 82/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 25.5515 - r2_score: -57.5159 - rmse: 4.9661 - val_loss: 63.7922 - val_r2_score: -49.7020 - val_rmse: 7.9316 - learning_rate: 3.2278e-04\n",
            "Epoch 83/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 47ms/step - loss: 24.8518 - r2_score: -57.7914 - rmse: 4.8948 - val_loss: 63.7364 - val_r2_score: -51.7271 - val_rmse: 7.9280 - learning_rate: 2.9424e-04\n",
            "Epoch 84/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 23.4109 - r2_score: -58.1694 - rmse: 4.7453 - val_loss: 63.8443 - val_r2_score: -51.3231 - val_rmse: 7.9347 - learning_rate: 2.6653e-04\n",
            "Epoch 85/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 22.7698 - r2_score: -58.5251 - rmse: 4.6772 - val_loss: 63.4989 - val_r2_score: -51.4254 - val_rmse: 7.9128 - learning_rate: 2.3977e-04\n",
            "Epoch 86/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 22.7970 - r2_score: -58.3388 - rmse: 4.6804 - val_loss: 62.4930 - val_r2_score: -50.7051 - val_rmse: 7.8490 - learning_rate: 2.1405e-04\n",
            "Epoch 87/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 22.1361 - r2_score: -58.1312 - rmse: 4.6088 - val_loss: 62.7760 - val_r2_score: -50.8770 - val_rmse: 7.8669 - learning_rate: 1.8948e-04\n",
            "Epoch 88/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 20.7212 - r2_score: -58.3729 - rmse: 4.4531 - val_loss: 62.5321 - val_r2_score: -52.1276 - val_rmse: 7.8514 - learning_rate: 1.6615e-04\n",
            "Epoch 89/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 47ms/step - loss: 20.6357 - r2_score: -58.1915 - rmse: 4.4435 - val_loss: 61.8409 - val_r2_score: -50.6505 - val_rmse: 7.8073 - learning_rate: 1.4416e-04\n",
            "Epoch 90/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 46ms/step - loss: 20.5026 - r2_score: -58.4227 - rmse: 4.4276 - val_loss: 61.6626 - val_r2_score: -51.6713 - val_rmse: 7.7958 - learning_rate: 1.2360e-04\n",
            "Epoch 91/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 19.3343 - r2_score: -59.0412 - rmse: 4.2945 - val_loss: 61.4020 - val_r2_score: -51.9057 - val_rmse: 7.7791 - learning_rate: 1.0454e-04\n",
            "Epoch 92/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - loss: 19.2242 - r2_score: -58.5312 - rmse: 4.2818 - val_loss: 61.0620 - val_r2_score: -50.5634 - val_rmse: 7.7572 - learning_rate: 8.7058e-05\n",
            "Epoch 93/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 46ms/step - loss: 19.3709 - r2_score: -58.3386 - rmse: 4.2987 - val_loss: 61.1743 - val_r2_score: -50.3619 - val_rmse: 7.7644 - learning_rate: 7.1228e-05\n",
            "Epoch 94/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 17.7327 - r2_score: -58.8677 - rmse: 4.1036 - val_loss: 61.1571 - val_r2_score: -50.6816 - val_rmse: 7.7633 - learning_rate: 5.7111e-05\n",
            "Epoch 95/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 18.3106 - r2_score: -58.8827 - rmse: 4.1726 - val_loss: 60.7654 - val_r2_score: -50.7400 - val_rmse: 7.7381 - learning_rate: 4.4761e-05\n",
            "Epoch 96/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 18.5566 - r2_score: -58.8278 - rmse: 4.2033 - val_loss: 60.7756 - val_r2_score: -50.7614 - val_rmse: 7.7387 - learning_rate: 3.4227e-05\n",
            "Epoch 97/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 46ms/step - loss: 18.6285 - r2_score: -58.5218 - rmse: 4.2117 - val_loss: 60.6231 - val_r2_score: -51.3127 - val_rmse: 7.7289 - learning_rate: 2.5551e-05\n",
            "Epoch 98/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 19.0914 - r2_score: -59.2245 - rmse: 4.2654 - val_loss: 60.5366 - val_r2_score: -50.9591 - val_rmse: 7.7233 - learning_rate: 1.8768e-05\n",
            "Epoch 99/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 18.3341 - r2_score: -59.2707 - rmse: 4.1767 - val_loss: 60.5601 - val_r2_score: -51.2755 - val_rmse: 7.7248 - learning_rate: 1.3903e-05\n",
            "Epoch 100/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - loss: 18.3760 - r2_score: -59.1399 - rmse: 4.1816 - val_loss: 60.6035 - val_r2_score: -50.9897 - val_rmse: 7.7276 - learning_rate: 1.0977e-05\n",
            "Epoch 101/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 18.2570 - r2_score: -58.7660 - rmse: 4.1675 - val_loss: 60.5418 - val_r2_score: -51.0356 - val_rmse: 7.7236 - learning_rate: 1.0000e-05\n",
            "Epoch 102/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 47ms/step - loss: 17.9394 - r2_score: -58.8305 - rmse: 4.1284 - val_loss: 60.4900 - val_r2_score: -51.1718 - val_rmse: 7.7203 - learning_rate: 1.0977e-05\n",
            "Epoch 103/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 18.1227 - r2_score: -58.1861 - rmse: 4.1508 - val_loss: 60.4779 - val_r2_score: -50.9434 - val_rmse: 7.7195 - learning_rate: 1.3903e-05\n",
            "Epoch 104/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 18.0005 - r2_score: -58.6994 - rmse: 4.1361 - val_loss: 60.6531 - val_r2_score: -51.1815 - val_rmse: 7.7308 - learning_rate: 1.8768e-05\n",
            "Epoch 105/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 46ms/step - loss: 17.9980 - r2_score: -59.3868 - rmse: 4.1359 - val_loss: 60.5770 - val_r2_score: -51.0762 - val_rmse: 7.7259 - learning_rate: 2.5551e-05\n",
            "Epoch 106/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 48ms/step - loss: 17.5084 - r2_score: -59.1471 - rmse: 4.0765 - val_loss: 60.4237 - val_r2_score: -50.9730 - val_rmse: 7.7160 - learning_rate: 3.4227e-05\n",
            "Epoch 107/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 17.5778 - r2_score: -58.4675 - rmse: 4.0849 - val_loss: 60.8722 - val_r2_score: -51.4548 - val_rmse: 7.7450 - learning_rate: 4.4761e-05\n",
            "Epoch 108/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 18.4810 - r2_score: -59.6231 - rmse: 4.1939 - val_loss: 60.5469 - val_r2_score: -51.1021 - val_rmse: 7.7240 - learning_rate: 5.7111e-05\n",
            "Epoch 109/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - loss: 19.1261 - r2_score: -58.5076 - rmse: 4.2703 - val_loss: 60.5417 - val_r2_score: -51.2430 - val_rmse: 7.7236 - learning_rate: 7.1228e-05\n",
            "Epoch 110/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 46ms/step - loss: 18.7839 - r2_score: -58.4460 - rmse: 4.2295 - val_loss: 60.6858 - val_r2_score: -50.9871 - val_rmse: 7.7330 - learning_rate: 8.7058e-05\n",
            "Epoch 111/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 19.2096 - r2_score: -58.7546 - rmse: 4.2796 - val_loss: 61.2713 - val_r2_score: -50.2596 - val_rmse: 7.7707 - learning_rate: 1.0454e-04\n",
            "Epoch 112/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 17.9758 - r2_score: -59.0899 - rmse: 4.1325 - val_loss: 61.0234 - val_r2_score: -51.5584 - val_rmse: 7.7547 - learning_rate: 1.2360e-04\n",
            "Epoch 113/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 18.9883 - r2_score: -59.1667 - rmse: 4.2540 - val_loss: 61.1567 - val_r2_score: -50.4252 - val_rmse: 7.7633 - learning_rate: 1.4416e-04\n",
            "Epoch 114/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 18.9457 - r2_score: -58.8326 - rmse: 4.2486 - val_loss: 61.4143 - val_r2_score: -51.6015 - val_rmse: 7.7799 - learning_rate: 1.6615e-04\n",
            "Epoch 115/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 19.3619 - r2_score: -59.0606 - rmse: 4.2976 - val_loss: 62.2064 - val_r2_score: -51.9482 - val_rmse: 7.8306 - learning_rate: 1.8948e-04\n",
            "Epoch 116/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - loss: 19.0000 - r2_score: -59.3286 - rmse: 4.2555 - val_loss: 64.1458 - val_r2_score: -54.1350 - val_rmse: 7.9534 - learning_rate: 2.1405e-04\n",
            "Epoch 117/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 46ms/step - loss: 19.6751 - r2_score: -59.0222 - rmse: 4.3339 - val_loss: 62.6888 - val_r2_score: -51.0779 - val_rmse: 7.8612 - learning_rate: 2.3977e-04\n",
            "Epoch 118/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 47ms/step - loss: 20.0836 - r2_score: -58.5644 - rmse: 4.3802 - val_loss: 62.2153 - val_r2_score: -51.2477 - val_rmse: 7.8310 - learning_rate: 2.6653e-04\n",
            "Epoch 119/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 19.8809 - r2_score: -58.5547 - rmse: 4.3575 - val_loss: 62.4790 - val_r2_score: -52.4365 - val_rmse: 7.8477 - learning_rate: 2.9424e-04\n",
            "Epoch 120/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 45ms/step - loss: 20.9007 - r2_score: -58.7956 - rmse: 4.4728 - val_loss: 62.7021 - val_r2_score: -50.4879 - val_rmse: 7.8618 - learning_rate: 3.2278e-04\n",
            "Epoch 121/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 47ms/step - loss: 21.1734 - r2_score: -58.7839 - rmse: 4.5026 - val_loss: 63.4238 - val_r2_score: -51.4339 - val_rmse: 7.9074 - learning_rate: 3.5204e-04\n",
            "Epoch 122/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 22.0094 - r2_score: -58.4601 - rmse: 4.5944 - val_loss: 62.8120 - val_r2_score: -52.6911 - val_rmse: 7.8685 - learning_rate: 3.8190e-04\n",
            "Epoch 123/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 22.5697 - r2_score: -59.2659 - rmse: 4.6544 - val_loss: 64.5329 - val_r2_score: -53.2341 - val_rmse: 7.9768 - learning_rate: 4.1225e-04\n",
            "Epoch 124/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 22.5940 - r2_score: -58.9534 - rmse: 4.6560 - val_loss: 64.9615 - val_r2_score: -51.7917 - val_rmse: 8.0035 - learning_rate: 4.4296e-04\n",
            "Epoch 125/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 22.9276 - r2_score: -58.1446 - rmse: 4.6916 - val_loss: 65.2250 - val_r2_score: -52.1258 - val_rmse: 8.0196 - learning_rate: 4.7392e-04\n",
            "Epoch 126/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 25.8152 - r2_score: -58.7429 - rmse: 4.9747 - val_loss: 63.1763 - val_r2_score: -50.5380 - val_rmse: 7.8905 - learning_rate: 5.0500e-04\n",
            "Epoch 126: early stopping\n",
            "Restoring model weights from the end of the best epoch: 106.\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 6ms/step\n",
            "(18035, 5, 5, 6)\n",
            "(4509, 5, 5, 6)\n",
            "Updated X_test shape: (11723, 5, 5, 6)\n",
            "Updated y_test shape: (11723,)\n",
            "Epoch 1/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 49ms/step - loss: 51.7872 - r2_score: -54.4576 - rmse: 7.1297 - val_loss: 26.2108 - val_r2_score: -51.4714 - val_rmse: 5.0323 - learning_rate: 1.0000e-05\n",
            "Epoch 2/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - loss: 52.0461 - r2_score: -53.4526 - rmse: 7.1507 - val_loss: 25.9425 - val_r2_score: -51.1351 - val_rmse: 5.0055 - learning_rate: 1.0977e-05\n",
            "Epoch 3/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - loss: 52.0771 - r2_score: -53.1722 - rmse: 7.1520 - val_loss: 25.5133 - val_r2_score: -51.2889 - val_rmse: 4.9625 - learning_rate: 1.3903e-05\n",
            "Epoch 4/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - loss: 48.0830 - r2_score: -53.8510 - rmse: 6.8641 - val_loss: 25.3244 - val_r2_score: -50.8513 - val_rmse: 4.9434 - learning_rate: 1.8768e-05\n",
            "Epoch 5/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - loss: 46.8448 - r2_score: -54.1203 - rmse: 6.7772 - val_loss: 24.8624 - val_r2_score: -51.3560 - val_rmse: 4.8965 - learning_rate: 2.5551e-05\n",
            "Epoch 6/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - loss: 48.5220 - r2_score: -53.7430 - rmse: 6.8997 - val_loss: 24.6995 - val_r2_score: -50.2830 - val_rmse: 4.8798 - learning_rate: 3.4227e-05\n",
            "Epoch 7/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 51.6249 - r2_score: -52.2598 - rmse: 7.1158 - val_loss: 24.1646 - val_r2_score: -50.0331 - val_rmse: 4.8247 - learning_rate: 4.4761e-05\n",
            "Epoch 8/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 48.1069 - r2_score: -52.7511 - rmse: 6.8699 - val_loss: 23.4824 - val_r2_score: -50.0161 - val_rmse: 4.7535 - learning_rate: 5.7111e-05\n",
            "Epoch 9/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 48.6106 - r2_score: -52.8004 - rmse: 6.9045 - val_loss: 22.7867 - val_r2_score: -50.6192 - val_rmse: 4.6797 - learning_rate: 7.1228e-05\n",
            "Epoch 10/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - loss: 47.4606 - r2_score: -52.5212 - rmse: 6.8223 - val_loss: 22.1591 - val_r2_score: -50.7696 - val_rmse: 4.6122 - learning_rate: 8.7058e-05\n",
            "Epoch 11/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 47ms/step - loss: 44.9355 - r2_score: -53.0297 - rmse: 6.6346 - val_loss: 22.0422 - val_r2_score: -49.3855 - val_rmse: 4.5995 - learning_rate: 1.0454e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 50ms/step - loss: 43.4267 - r2_score: -53.0479 - rmse: 6.5177 - val_loss: 20.6805 - val_r2_score: -50.5770 - val_rmse: 4.4489 - learning_rate: 1.2360e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 42.5235 - r2_score: -53.6984 - rmse: 6.4500 - val_loss: 20.1756 - val_r2_score: -51.0868 - val_rmse: 4.3918 - learning_rate: 1.4416e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - loss: 40.4961 - r2_score: -53.8664 - rmse: 6.2921 - val_loss: 19.6387 - val_r2_score: -51.9495 - val_rmse: 4.3301 - learning_rate: 1.6615e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 39.1489 - r2_score: -54.6506 - rmse: 6.1833 - val_loss: 19.0975 - val_r2_score: -51.8487 - val_rmse: 4.2671 - learning_rate: 1.8948e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 39.2269 - r2_score: -54.2420 - rmse: 6.1898 - val_loss: 18.2387 - val_r2_score: -51.2174 - val_rmse: 4.1651 - learning_rate: 2.1405e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 37.5379 - r2_score: -54.9041 - rmse: 6.0527 - val_loss: 18.9627 - val_r2_score: -51.4153 - val_rmse: 4.2510 - learning_rate: 2.3977e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 35.9642 - r2_score: -55.2446 - rmse: 5.9197 - val_loss: 18.7224 - val_r2_score: -50.3499 - val_rmse: 4.2225 - learning_rate: 2.6653e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 34.4252 - r2_score: -55.5901 - rmse: 5.7884 - val_loss: 17.4512 - val_r2_score: -51.8036 - val_rmse: 4.0689 - learning_rate: 2.9424e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 47ms/step - loss: 33.4817 - r2_score: -55.5059 - rmse: 5.7068 - val_loss: 18.2118 - val_r2_score: -51.3503 - val_rmse: 4.1611 - learning_rate: 3.2278e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - loss: 33.4552 - r2_score: -55.8338 - rmse: 5.7046 - val_loss: 17.0270 - val_r2_score: -52.7740 - val_rmse: 4.0158 - learning_rate: 3.5204e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 31.4993 - r2_score: -56.9225 - rmse: 5.5306 - val_loss: 17.1317 - val_r2_score: -53.1615 - val_rmse: 4.0285 - learning_rate: 3.8190e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 31.4553 - r2_score: -56.4559 - rmse: 5.5252 - val_loss: 18.7691 - val_r2_score: -50.5239 - val_rmse: 4.2264 - learning_rate: 4.1225e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 32.5258 - r2_score: -56.1020 - rmse: 5.6191 - val_loss: 19.4058 - val_r2_score: -52.2817 - val_rmse: 4.3005 - learning_rate: 4.4296e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 31.9229 - r2_score: -56.4802 - rmse: 5.5676 - val_loss: 19.8230 - val_r2_score: -53.9067 - val_rmse: 4.3482 - learning_rate: 4.7392e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - loss: 32.0164 - r2_score: -56.6971 - rmse: 5.5762 - val_loss: 19.3180 - val_r2_score: -53.3409 - val_rmse: 4.2891 - learning_rate: 5.0500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - loss: 31.5060 - r2_score: -56.5866 - rmse: 5.5281 - val_loss: 19.1617 - val_r2_score: -53.6323 - val_rmse: 4.2701 - learning_rate: 5.3608e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 31.7361 - r2_score: -56.2623 - rmse: 5.5497 - val_loss: 20.5841 - val_r2_score: -51.1087 - val_rmse: 4.4327 - learning_rate: 5.6704e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 47ms/step - loss: 31.5529 - r2_score: -55.8521 - rmse: 5.5311 - val_loss: 21.1187 - val_r2_score: -51.8485 - val_rmse: 4.4918 - learning_rate: 5.9775e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 32.4746 - r2_score: -56.4114 - rmse: 5.6144 - val_loss: 20.7083 - val_r2_score: -52.1356 - val_rmse: 4.4449 - learning_rate: 6.2810e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 32.2497 - r2_score: -56.4193 - rmse: 5.5928 - val_loss: 23.0220 - val_r2_score: -52.8835 - val_rmse: 4.6970 - learning_rate: 6.5796e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 30.5167 - r2_score: -56.7617 - rmse: 5.4354 - val_loss: 23.6963 - val_r2_score: -53.3058 - val_rmse: 4.7671 - learning_rate: 6.8722e-04\n",
            "Epoch 33/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 34.0409 - r2_score: -56.9195 - rmse: 5.7476 - val_loss: 25.1071 - val_r2_score: -53.5508 - val_rmse: 4.9117 - learning_rate: 7.1576e-04\n",
            "Epoch 34/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 32.3704 - r2_score: -56.2916 - rmse: 5.6011 - val_loss: 24.4624 - val_r2_score: -51.4116 - val_rmse: 4.8444 - learning_rate: 7.4347e-04\n",
            "Epoch 35/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 32.3717 - r2_score: -56.2755 - rmse: 5.5977 - val_loss: 26.1955 - val_r2_score: -49.2373 - val_rmse: 5.0187 - learning_rate: 7.7023e-04\n",
            "Epoch 36/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 35.0145 - r2_score: -56.0873 - rmse: 5.8297 - val_loss: 28.6068 - val_r2_score: -49.5233 - val_rmse: 5.2522 - learning_rate: 7.9595e-04\n",
            "Epoch 37/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 53ms/step - loss: 33.5798 - r2_score: -56.3502 - rmse: 5.7047 - val_loss: 27.1036 - val_r2_score: -49.5208 - val_rmse: 5.1056 - learning_rate: 8.2052e-04\n",
            "Epoch 38/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 33.4750 - r2_score: -56.3783 - rmse: 5.6923 - val_loss: 27.3828 - val_r2_score: -51.6438 - val_rmse: 5.1314 - learning_rate: 8.4385e-04\n",
            "Epoch 39/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 55ms/step - loss: 33.3414 - r2_score: -57.1292 - rmse: 5.6813 - val_loss: 30.3695 - val_r2_score: -55.8569 - val_rmse: 5.4132 - learning_rate: 8.6584e-04\n",
            "Epoch 40/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 31.6720 - r2_score: -57.3429 - rmse: 5.5299 - val_loss: 29.4549 - val_r2_score: -52.5812 - val_rmse: 5.3265 - learning_rate: 8.8640e-04\n",
            "Epoch 41/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 52ms/step - loss: 36.0656 - r2_score: -55.9949 - rmse: 5.9134 - val_loss: 30.2210 - val_r2_score: -48.8882 - val_rmse: 5.3962 - learning_rate: 9.0546e-04\n",
            "Epoch 41: early stopping\n",
            "Restoring model weights from the end of the best epoch: 21.\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "(18035, 5, 5, 6)\n",
            "(4509, 5, 5, 6)\n",
            "Updated X_test shape: (11723, 5, 5, 6)\n",
            "Updated y_test shape: (11723,)\n",
            "Epoch 1/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 32.0251 - r2_score: -56.4146 - rmse: 5.5771 - val_loss: 14.9138 - val_r2_score: -53.2211 - val_rmse: 3.7435 - learning_rate: 1.0000e-05\n",
            "Epoch 2/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 30.9440 - r2_score: -55.8870 - rmse: 5.4805 - val_loss: 14.4473 - val_r2_score: -53.0734 - val_rmse: 3.6806 - learning_rate: 1.0977e-05\n",
            "Epoch 3/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 56ms/step - loss: 30.1359 - r2_score: -56.0202 - rmse: 5.4037 - val_loss: 13.8465 - val_r2_score: -53.4607 - val_rmse: 3.5981 - learning_rate: 1.3903e-05\n",
            "Epoch 4/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 55ms/step - loss: 30.0804 - r2_score: -55.9472 - rmse: 5.4013 - val_loss: 13.6164 - val_r2_score: -53.8337 - val_rmse: 3.5660 - learning_rate: 1.8768e-05\n",
            "Epoch 5/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 30.6813 - r2_score: -56.4255 - rmse: 5.4565 - val_loss: 13.1536 - val_r2_score: -53.5073 - val_rmse: 3.5005 - learning_rate: 2.5551e-05\n",
            "Epoch 6/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 55ms/step - loss: 28.2002 - r2_score: -56.5311 - rmse: 5.2240 - val_loss: 13.0175 - val_r2_score: -53.4010 - val_rmse: 3.4810 - learning_rate: 3.4227e-05\n",
            "Epoch 7/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 28.6540 - r2_score: -56.4542 - rmse: 5.2676 - val_loss: 12.5634 - val_r2_score: -53.1575 - val_rmse: 3.4152 - learning_rate: 4.4761e-05\n",
            "Epoch 8/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 26.8820 - r2_score: -56.1825 - rmse: 5.0963 - val_loss: 12.3491 - val_r2_score: -53.5336 - val_rmse: 3.3836 - learning_rate: 5.7111e-05\n",
            "Epoch 9/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 27.5042 - r2_score: -56.5801 - rmse: 5.1577 - val_loss: 12.1718 - val_r2_score: -54.5508 - val_rmse: 3.3573 - learning_rate: 7.1228e-05\n",
            "Epoch 10/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 26.8492 - r2_score: -56.6835 - rmse: 5.0936 - val_loss: 12.1639 - val_r2_score: -54.1086 - val_rmse: 3.3561 - learning_rate: 8.7058e-05\n",
            "Epoch 11/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - loss: 27.0228 - r2_score: -57.1093 - rmse: 5.1100 - val_loss: 12.1490 - val_r2_score: -54.0197 - val_rmse: 3.3539 - learning_rate: 1.0454e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 53ms/step - loss: 26.9770 - r2_score: -57.1336 - rmse: 5.1057 - val_loss: 11.8741 - val_r2_score: -54.4370 - val_rmse: 3.3126 - learning_rate: 1.2360e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 26.0522 - r2_score: -57.3389 - rmse: 5.0133 - val_loss: 11.9796 - val_r2_score: -53.4345 - val_rmse: 3.3285 - learning_rate: 1.4416e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 48ms/step - loss: 26.9139 - r2_score: -56.3649 - rmse: 5.0994 - val_loss: 13.1294 - val_r2_score: -53.1677 - val_rmse: 3.4969 - learning_rate: 1.6615e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 51ms/step - loss: 25.8103 - r2_score: -57.2004 - rmse: 4.9903 - val_loss: 13.4604 - val_r2_score: -56.7367 - val_rmse: 3.5437 - learning_rate: 1.8948e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 27.1398 - r2_score: -57.3622 - rmse: 5.1212 - val_loss: 12.4098 - val_r2_score: -54.8474 - val_rmse: 3.3921 - learning_rate: 2.1405e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 25.6275 - r2_score: -57.7854 - rmse: 4.9720 - val_loss: 12.5503 - val_r2_score: -54.3963 - val_rmse: 3.4126 - learning_rate: 2.3977e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 46ms/step - loss: 26.6202 - r2_score: -57.6447 - rmse: 5.0707 - val_loss: 12.8211 - val_r2_score: -52.8372 - val_rmse: 3.4519 - learning_rate: 2.6653e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 26.3695 - r2_score: -56.8604 - rmse: 5.0453 - val_loss: 12.4264 - val_r2_score: -54.5669 - val_rmse: 3.3940 - learning_rate: 2.9424e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 26.0394 - r2_score: -57.6386 - rmse: 5.0119 - val_loss: 14.6260 - val_r2_score: -57.4129 - val_rmse: 3.7036 - learning_rate: 3.2278e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 26.3495 - r2_score: -58.0840 - rmse: 5.0424 - val_loss: 17.0050 - val_r2_score: -51.8071 - val_rmse: 4.0117 - learning_rate: 3.5204e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - loss: 27.1238 - r2_score: -56.7402 - rmse: 5.1194 - val_loss: 14.8550 - val_r2_score: -55.3666 - val_rmse: 3.7336 - learning_rate: 3.8190e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 27.5319 - r2_score: -57.8636 - rmse: 5.1584 - val_loss: 15.5335 - val_r2_score: -52.0046 - val_rmse: 3.8230 - learning_rate: 4.1225e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 27.8280 - r2_score: -57.3265 - rmse: 5.1868 - val_loss: 16.0956 - val_r2_score: -52.2627 - val_rmse: 3.8953 - learning_rate: 4.4296e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 27.9478 - r2_score: -56.9846 - rmse: 5.1972 - val_loss: 17.9751 - val_r2_score: -52.1330 - val_rmse: 4.1289 - learning_rate: 4.7392e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - loss: 30.3580 - r2_score: -56.6927 - rmse: 5.4242 - val_loss: 17.6132 - val_r2_score: -51.2192 - val_rmse: 4.0842 - learning_rate: 5.0500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 49ms/step - loss: 29.6412 - r2_score: -57.5077 - rmse: 5.3565 - val_loss: 19.1581 - val_r2_score: -51.5921 - val_rmse: 4.2685 - learning_rate: 5.3608e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 28.6531 - r2_score: -57.4474 - rmse: 5.2635 - val_loss: 18.4880 - val_r2_score: -55.2553 - val_rmse: 4.1883 - learning_rate: 5.6704e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 29.1428 - r2_score: -57.7811 - rmse: 5.3088 - val_loss: 19.1798 - val_r2_score: -53.4739 - val_rmse: 4.2693 - learning_rate: 5.9775e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - loss: 28.7350 - r2_score: -57.6757 - rmse: 5.2692 - val_loss: 21.5785 - val_r2_score: -51.0024 - val_rmse: 4.5406 - learning_rate: 6.2810e-04\n",
            "Epoch 31/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 29.8733 - r2_score: -56.7235 - rmse: 5.3763 - val_loss: 18.1314 - val_r2_score: -53.7314 - val_rmse: 4.1425 - learning_rate: 6.5796e-04\n",
            "Epoch 32/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 29.3326 - r2_score: -57.3397 - rmse: 5.3236 - val_loss: 21.6397 - val_r2_score: -52.7720 - val_rmse: 4.5452 - learning_rate: 6.8722e-04\n",
            "Epoch 32: early stopping\n",
            "Restoring model weights from the end of the best epoch: 12.\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "(18035, 5, 5, 6)\n",
            "(4509, 5, 5, 6)\n",
            "Updated X_test shape: (11723, 5, 5, 6)\n",
            "Updated y_test shape: (11723,)\n",
            "Epoch 1/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 53ms/step - loss: 27.4228 - r2_score: -57.6925 - rmse: 5.1496 - val_loss: 10.9426 - val_r2_score: -54.2497 - val_rmse: 3.1689 - learning_rate: 1.0000e-05\n",
            "Epoch 2/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 50ms/step - loss: 27.1400 - r2_score: -56.9219 - rmse: 5.1216 - val_loss: 10.6297 - val_r2_score: -54.4534 - val_rmse: 3.1192 - learning_rate: 1.0977e-05\n",
            "Epoch 3/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 53ms/step - loss: 26.6590 - r2_score: -57.6100 - rmse: 5.0744 - val_loss: 10.3864 - val_r2_score: -54.2802 - val_rmse: 3.0799 - learning_rate: 1.3903e-05\n",
            "Epoch 4/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step - loss: 27.1905 - r2_score: -56.7325 - rmse: 5.1154 - val_loss: 10.3292 - val_r2_score: -54.4137 - val_rmse: 3.0706 - learning_rate: 1.8768e-05\n",
            "Epoch 5/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 26.5953 - r2_score: -57.1449 - rmse: 5.0671 - val_loss: 10.1297 - val_r2_score: -54.4050 - val_rmse: 3.0379 - learning_rate: 2.5551e-05\n",
            "Epoch 6/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 25.7529 - r2_score: -57.8599 - rmse: 4.9848 - val_loss: 10.0510 - val_r2_score: -54.4035 - val_rmse: 3.0250 - learning_rate: 3.4227e-05\n",
            "Epoch 7/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 24.8281 - r2_score: -57.1242 - rmse: 4.8909 - val_loss: 10.2834 - val_r2_score: -54.3502 - val_rmse: 3.0632 - learning_rate: 4.4761e-05\n",
            "Epoch 8/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 24.9831 - r2_score: -57.5125 - rmse: 4.9071 - val_loss: 9.8971 - val_r2_score: -54.6390 - val_rmse: 2.9994 - learning_rate: 5.7111e-05\n",
            "Epoch 9/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 48ms/step - loss: 25.3145 - r2_score: -57.0640 - rmse: 4.9408 - val_loss: 9.9547 - val_r2_score: -54.1299 - val_rmse: 3.0090 - learning_rate: 7.1228e-05\n",
            "Epoch 10/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 25.2878 - r2_score: -57.5517 - rmse: 4.9381 - val_loss: 9.7651 - val_r2_score: -54.7052 - val_rmse: 2.9773 - learning_rate: 8.7058e-05\n",
            "Epoch 11/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 51ms/step - loss: 25.2677 - r2_score: -57.8947 - rmse: 4.9361 - val_loss: 10.2159 - val_r2_score: -53.7436 - val_rmse: 3.0521 - learning_rate: 1.0454e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 24.0934 - r2_score: -57.6442 - rmse: 4.8142 - val_loss: 10.9767 - val_r2_score: -56.0429 - val_rmse: 3.1742 - learning_rate: 1.2360e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - loss: 24.1541 - r2_score: -57.4522 - rmse: 4.8218 - val_loss: 11.1072 - val_r2_score: -56.6524 - val_rmse: 3.1946 - learning_rate: 1.4416e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 25.5602 - r2_score: -57.9555 - rmse: 4.9655 - val_loss: 10.5172 - val_r2_score: -54.5107 - val_rmse: 3.1009 - learning_rate: 1.6615e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 51ms/step - loss: 25.0234 - r2_score: -57.6981 - rmse: 4.9095 - val_loss: 10.6587 - val_r2_score: -54.4926 - val_rmse: 3.1235 - learning_rate: 1.8948e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 24.7050 - r2_score: -57.2049 - rmse: 4.8784 - val_loss: 10.9564 - val_r2_score: -54.2859 - val_rmse: 3.1707 - learning_rate: 2.1405e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 25.6191 - r2_score: -57.4908 - rmse: 4.9712 - val_loss: 11.6758 - val_r2_score: -54.8878 - val_rmse: 3.2820 - learning_rate: 2.3977e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 25.4440 - r2_score: -57.6488 - rmse: 4.9532 - val_loss: 11.1560 - val_r2_score: -53.9400 - val_rmse: 3.2016 - learning_rate: 2.6653e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 25.2117 - r2_score: -57.5842 - rmse: 4.9289 - val_loss: 11.6432 - val_r2_score: -53.8369 - val_rmse: 3.2766 - learning_rate: 2.9424e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 50ms/step - loss: 26.1130 - r2_score: -57.6646 - rmse: 5.0199 - val_loss: 12.0422 - val_r2_score: -55.1712 - val_rmse: 3.3365 - learning_rate: 3.2278e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 49ms/step - loss: 25.4723 - r2_score: -57.4462 - rmse: 4.9549 - val_loss: 13.1789 - val_r2_score: -54.1993 - val_rmse: 3.5024 - learning_rate: 3.5204e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - loss: 26.8315 - r2_score: -57.8056 - rmse: 5.0890 - val_loss: 14.4953 - val_r2_score: -53.5059 - val_rmse: 3.6852 - learning_rate: 3.8190e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 26.9942 - r2_score: -57.3048 - rmse: 5.1059 - val_loss: 14.2912 - val_r2_score: -54.9274 - val_rmse: 3.6569 - learning_rate: 4.1225e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 26.0514 - r2_score: -58.0496 - rmse: 5.0122 - val_loss: 13.9736 - val_r2_score: -53.2578 - val_rmse: 3.6126 - learning_rate: 4.4296e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 53ms/step - loss: 27.1246 - r2_score: -57.7731 - rmse: 5.1168 - val_loss: 17.1256 - val_r2_score: -53.9566 - val_rmse: 4.0247 - learning_rate: 4.7392e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 28.5742 - r2_score: -57.1118 - rmse: 5.2572 - val_loss: 16.2942 - val_r2_score: -52.8106 - val_rmse: 3.9193 - learning_rate: 5.0500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - loss: 28.8754 - r2_score: -57.7829 - rmse: 5.2848 - val_loss: 18.3792 - val_r2_score: -51.0967 - val_rmse: 4.1761 - learning_rate: 5.3608e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 51ms/step - loss: 29.2625 - r2_score: -56.8147 - rmse: 5.3199 - val_loss: 19.0833 - val_r2_score: -54.1883 - val_rmse: 4.2587 - learning_rate: 5.6704e-04\n",
            "Epoch 29/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 51ms/step - loss: 30.1016 - r2_score: -57.2378 - rmse: 5.3985 - val_loss: 21.1779 - val_r2_score: -52.4664 - val_rmse: 4.4971 - learning_rate: 5.9775e-04\n",
            "Epoch 30/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 30.4521 - r2_score: -56.7154 - rmse: 5.4300 - val_loss: 20.0959 - val_r2_score: -52.2467 - val_rmse: 4.3742 - learning_rate: 6.2810e-04\n",
            "Epoch 30: early stopping\n",
            "Restoring model weights from the end of the best epoch: 10.\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "(18036, 5, 5, 6)\n",
            "(4508, 5, 5, 6)\n",
            "Updated X_test shape: (11722, 5, 5, 6)\n",
            "Updated y_test shape: (11722,)\n",
            "Epoch 1/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 50ms/step - loss: 25.3547 - r2_score: -57.2621 - rmse: 4.9443 - val_loss: 9.2312 - val_r2_score: -55.3351 - val_rmse: 2.8863 - learning_rate: 1.0000e-05\n",
            "Epoch 2/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 54ms/step - loss: 24.7247 - r2_score: -57.4734 - rmse: 4.8805 - val_loss: 9.0283 - val_r2_score: -55.1572 - val_rmse: 2.8509 - learning_rate: 1.0977e-05\n",
            "Epoch 3/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 49ms/step - loss: 24.8606 - r2_score: -56.3740 - rmse: 4.8945 - val_loss: 9.0781 - val_r2_score: -55.2774 - val_rmse: 2.8596 - learning_rate: 1.3903e-05\n",
            "Epoch 4/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 54ms/step - loss: 23.9678 - r2_score: -57.6869 - rmse: 4.8012 - val_loss: 8.8295 - val_r2_score: -54.9084 - val_rmse: 2.8158 - learning_rate: 1.8768e-05\n",
            "Epoch 5/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 52ms/step - loss: 24.1029 - r2_score: -57.4817 - rmse: 4.8165 - val_loss: 8.8787 - val_r2_score: -54.5109 - val_rmse: 2.8246 - learning_rate: 2.5551e-05\n",
            "Epoch 6/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 24.4915 - r2_score: -57.2769 - rmse: 4.8567 - val_loss: 8.7808 - val_r2_score: -55.9836 - val_rmse: 2.8071 - learning_rate: 3.4227e-05\n",
            "Epoch 7/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 24.6921 - r2_score: -57.4669 - rmse: 4.8772 - val_loss: 8.8197 - val_r2_score: -54.4901 - val_rmse: 2.8141 - learning_rate: 4.4761e-05\n",
            "Epoch 8/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 52ms/step - loss: 25.0981 - r2_score: -57.1953 - rmse: 4.9171 - val_loss: 8.7361 - val_r2_score: -54.8605 - val_rmse: 2.7992 - learning_rate: 5.7111e-05\n",
            "Epoch 9/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 52ms/step - loss: 24.5177 - r2_score: -57.7089 - rmse: 4.8588 - val_loss: 9.6190 - val_r2_score: -53.8138 - val_rmse: 2.9527 - learning_rate: 7.1228e-05\n",
            "Epoch 10/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - loss: 24.6449 - r2_score: -57.3950 - rmse: 4.8725 - val_loss: 8.8942 - val_r2_score: -55.1731 - val_rmse: 2.8273 - learning_rate: 8.7058e-05\n",
            "Epoch 11/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 24.0723 - r2_score: -56.9883 - rmse: 4.8133 - val_loss: 9.0023 - val_r2_score: -56.0129 - val_rmse: 2.8463 - learning_rate: 1.0454e-04\n",
            "Epoch 12/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 23.4879 - r2_score: -57.9894 - rmse: 4.7511 - val_loss: 9.1980 - val_r2_score: -55.9162 - val_rmse: 2.8804 - learning_rate: 1.2360e-04\n",
            "Epoch 13/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 49ms/step - loss: 23.1581 - r2_score: -57.7803 - rmse: 4.7155 - val_loss: 9.4887 - val_r2_score: -54.1596 - val_rmse: 2.9304 - learning_rate: 1.4416e-04\n",
            "Epoch 14/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - loss: 24.4877 - r2_score: -57.2036 - rmse: 4.8562 - val_loss: 9.6496 - val_r2_score: -56.9363 - val_rmse: 2.9577 - learning_rate: 1.6615e-04\n",
            "Epoch 15/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step - loss: 23.0226 - r2_score: -58.5380 - rmse: 4.7015 - val_loss: 9.7090 - val_r2_score: -55.6981 - val_rmse: 2.9676 - learning_rate: 1.8948e-04\n",
            "Epoch 16/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - loss: 24.2100 - r2_score: -57.3906 - rmse: 4.8267 - val_loss: 10.3438 - val_r2_score: -53.4544 - val_rmse: 3.0726 - learning_rate: 2.1405e-04\n",
            "Epoch 17/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - loss: 24.4682 - r2_score: -57.7437 - rmse: 4.8524 - val_loss: 10.2056 - val_r2_score: -55.9999 - val_rmse: 3.0498 - learning_rate: 2.3977e-04\n",
            "Epoch 18/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 50ms/step - loss: 25.1790 - r2_score: -58.0572 - rmse: 4.9264 - val_loss: 11.2157 - val_r2_score: -54.1788 - val_rmse: 3.2109 - learning_rate: 2.6653e-04\n",
            "Epoch 19/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 48ms/step - loss: 25.1862 - r2_score: -57.5377 - rmse: 4.9263 - val_loss: 11.3335 - val_r2_score: -57.0330 - val_rmse: 3.2289 - learning_rate: 2.9424e-04\n",
            "Epoch 20/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 48ms/step - loss: 25.4763 - r2_score: -57.6174 - rmse: 4.9560 - val_loss: 12.0017 - val_r2_score: -56.1106 - val_rmse: 3.3305 - learning_rate: 3.2278e-04\n",
            "Epoch 21/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 50ms/step - loss: 24.7860 - r2_score: -57.8367 - rmse: 4.8835 - val_loss: 12.1405 - val_r2_score: -54.9441 - val_rmse: 3.3509 - learning_rate: 3.5204e-04\n",
            "Epoch 22/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - loss: 25.5705 - r2_score: -57.7783 - rmse: 4.9622 - val_loss: 12.3921 - val_r2_score: -55.4723 - val_rmse: 3.3878 - learning_rate: 3.8190e-04\n",
            "Epoch 23/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 52ms/step - loss: 26.4564 - r2_score: -57.9594 - rmse: 5.0493 - val_loss: 14.6808 - val_r2_score: -54.4193 - val_rmse: 3.7098 - learning_rate: 4.1225e-04\n",
            "Epoch 24/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 52ms/step - loss: 28.3188 - r2_score: -57.1849 - rmse: 5.2333 - val_loss: 14.4570 - val_r2_score: -56.4819 - val_rmse: 3.6789 - learning_rate: 4.4296e-04\n",
            "Epoch 25/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step - loss: 26.5613 - r2_score: -57.6996 - rmse: 5.0629 - val_loss: 15.4516 - val_r2_score: -53.6887 - val_rmse: 3.8111 - learning_rate: 4.7392e-04\n",
            "Epoch 26/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 52ms/step - loss: 27.0202 - r2_score: -57.6189 - rmse: 5.1065 - val_loss: 18.2785 - val_r2_score: -53.1725 - val_rmse: 4.1649 - learning_rate: 5.0500e-04\n",
            "Epoch 27/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 53ms/step - loss: 27.0693 - r2_score: -57.6672 - rmse: 5.1114 - val_loss: 18.3756 - val_r2_score: -54.9103 - val_rmse: 4.1758 - learning_rate: 5.3608e-04\n",
            "Epoch 28/200\n",
            "\u001b[1m564/564\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 49ms/step - loss: 29.3327 - r2_score: -57.6234 - rmse: 5.3277 - val_loss: 18.3003 - val_r2_score: -53.9422 - val_rmse: 4.1659 - learning_rate: 5.6704e-04\n",
            "Epoch 28: early stopping\n",
            "Restoring model weights from the end of the best epoch: 8.\n",
            "\u001b[1m367/367\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 7ms/step\n",
            "Best model is from fold /content/drive/My Drive/forest_height/models/CNNmodels/fold_5_best_CNNmodel_Std.keras\n",
            "Best R² score: 0.9422\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# bmodel = load_model('/content/drive/My Drive/forest_height/models/CNNmodels/best_CNNmodel_Std.keras')\n",
        "# bmodel = load_model(best_model_path)\n",
        "\n",
        "# 若使用的是 Keras 模型并使用了 R2Score 指标，则在加载 Keras 模型时需要传递 custom_objects，\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# 显式传递 custom_objects 参数，确保 Keras 知道如何加载 R2Score 类\n",
        "bmodel = load_model(\n",
        "    best_model_path_cnn,\n",
        "    custom_objects={'R2Score': R2Score}  # 注册 R2Score 类\n",
        ")"
      ],
      "metadata": {
        "id": "fUxYISpe-Q_G"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "y_pred_cnn = bmodel.predict(X_test) #predict best model"
      ],
      "metadata": {
        "id": "aRjfquRD-VZ-"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 检查y_pred_cnn的形状\n",
        "print(y_pred_cnn.shape)"
      ],
      "metadata": {
        "id": "VQUTbYcoSZ5K"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 输出两类图,\n",
        "# # 一为 整体预测值 vs. 真实值的散点图,点为蓝色点。\n",
        "# # 二为 单一特征 vs. 森林高度。黑色点为真实值，蓝色点为预测值。分别展示两个特定通道（第四通道和第五通道）特征与森林高度（真实值和预测值）的关系。\n",
        "pred_vs_true(bmodel, \"CNNmodel\", X_test, y_test)"
      ],
      "metadata": {
        "id": "Yotx8rbhSYPV"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 计算均方误差（MSE）、均方根误差（RMSE）、平均绝对误差（MAE）和平均绝对百分比误差（MAPE）。\n",
        "# 这些指标用于评估模型在测试集上的性能。\n",
        "from sklearn.metrics import mean_absolute_percentage_error as mape, r2_score\n",
        "\n",
        "# 计算 MAPE\n",
        "mape_cnn = mape(y_test, y_pred_cnn)\n",
        "# 计算 R²\n",
        "r2_cnn = r2_score(y_test, y_pred_cnn)\n",
        "# 调整后R²\n",
        "n_samples = X_test.shape[0]\n",
        "n_features = X_test.shape[3]\n",
        "adjusted_r2_cnn = 1 - (1 - r2_cnn) * (n_samples - 1) / (n_samples - n_features - 1) # X_test 形状为 (N, H, W, C)\n",
        "# calculate metrics\n",
        "mse_cnn = mse(y_test, y_pred_cnn)\n",
        "rmse_cnn = mse_cnn ** (1/2)\n",
        "mae_cnn = mae(y_test, y_pred_cnn)\n",
        "mape_cnn = mape(y_test, y_pred_cnn)\n",
        "\n",
        "# print(mape_cnn)\n",
        "# print(mae_cnn)\n",
        "# print(rmse_cnn)\n",
        "# print(r2_cnn)\n",
        "print('MAPE: {:0.2f}%'.format(mape_cnn))\n",
        "print('MAE: {:0.4f}'.format(mae_cnn))\n",
        "print('RMSE: {:0.4f}'.format(rmse_cnn))\n",
        "print('R²: {:0.4f}'.format(r2_cnn))\n",
        "print('Adjusted R²: {:0.4f}'.format(adjusted_r2_cnn))  # 新增行"
      ],
      "metadata": {
        "id": "s6GI3n_6-WFH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "dcd46be1-0ef3-4676-9f24-76618ee6e9cd"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'y_pred_cnn' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-421bb0c36bb1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 计算 MAPE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmape_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;31m# 计算 R²\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mr2_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr2_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'y_pred_cnn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型评价指标可视化"
      ],
      "metadata": {
        "id": "mhsIW-1mbUvE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "代码通过计算和比较模型在训练集和测试集上的误差和拟合优度指标（MSE、RMSE、MAE、R²），并使用柱状图可视化两者的表现，帮助评估模型的性能是否存在过拟合或欠拟合的情况，从这些指标可以看出，模型在训练集和测试集上的表现较为接近，说明模型没有严重的过拟合或欠拟合现象，虽然测试集上的误差略高于训练集，但差异并不大，表明模型具有较好的泛化能力"
      ],
      "metadata": {
        "id": "bfckwJXObTjC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "# 预测\n",
        "y_pred_train = bmodel.predict(X_train)\n",
        "y_pred_test = bmodel.predict(X_test)\n",
        "\n",
        "y_pred_train_list = y_pred_train.tolist()\n",
        "y_pred_test_list = y_pred_test.tolist()\n",
        "\n",
        "# 计算训练集的指标\n",
        "mse_train = metrics.mean_squared_error(y_train, y_pred_train_list)\n",
        "rmse_train = np.sqrt(mse_train)\n",
        "mae_train = metrics.mean_absolute_error(y_train, y_pred_train_list)\n",
        "r2_train = metrics.r2_score(y_train, y_pred_train_list)\n",
        "\n",
        "# 计算测试集的指标\n",
        "mse_test = metrics.mean_squared_error(y_test, y_pred_test_list)\n",
        "rmse_test = np.sqrt(mse_test)\n",
        "mae_test = metrics.mean_absolute_error(y_test, y_pred_test_list)\n",
        "r2_test = metrics.r2_score(y_test, y_pred_test_list)\n",
        "\n",
        "# 将指标放入列表\n",
        "metrics_labels = ['MSE', 'RMSE', 'MAE', 'R-squared']\n",
        "train_metrics = [mse_train, rmse_train, mae_train, r2_train]\n",
        "test_metrics = [mse_test, rmse_test, mae_test, r2_test]\n",
        "\n",
        "# 创建柱状图\n",
        "x = np.arange(len(metrics_labels))  # 横坐标位置\n",
        "width = 0.35  # 柱子的宽度\n",
        "\n",
        "# fig, ax = plt.subplots()\n",
        "fig, ax = plt.subplots(figsize=(8, 6))  # 设置图像尺寸\n",
        "\n",
        "# 训练集和测试集的柱子\n",
        "bars1 = ax.bar(x - width/2, train_metrics, width, label='Train')\n",
        "bars2 = ax.bar(x + width/2, test_metrics, width, label='Test')\n",
        "\n",
        "# 添加标签和标题\n",
        "ax.set_ylabel('Scores')\n",
        "ax.set_title('Comparison of Train and Test Set Metrics')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(metrics_labels)\n",
        "ax.legend()\n",
        "\n",
        "# 在每个柱子上显示数值\n",
        "def autolabel(bars):\n",
        "    \"\"\"在每个柱子上显示数值.\"\"\"\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        ax.annotate('{}'.format(round(height, 3)),\n",
        "                    xy=(bar.get_x() + bar.get_width() / 2, height),\n",
        "                    # xytext=(0, 3),  # 3 点垂直偏移\n",
        "                    xytext=(0, 4),  # 将文本稍微向上偏移\n",
        "                    textcoords=\"offset points\",\n",
        "                    ha='center', va='bottom', fontsize=10)  # 设置字体大小\n",
        "\n",
        "autolabel(bars1)\n",
        "autolabel(bars2)\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.savefig(\"Comparison of Train and Test Set Metrics.pdf\", format='pdf',bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bQzoYCMVbI6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 模型预测可视化"
      ],
      "metadata": {
        "id": "J51chfbSbfo6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "代码通过散点图、回归线、直方图和拟合优度（R²）值的可视化方式，直观展示模型在训练集和测试集上的预测表现，对角线 x=y 表示理想状态下的预测，散点的偏离程度和回归线的拟合情况则表明了模型的实际预测能力，通过这些图表，可以很好地评估模型的准确性和泛化能力"
      ],
      "metadata": {
        "id": "XTC5g1HrbqKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "y_train = y_train.flatten()  # 确保y_train是一维\n",
        "y_pred_train = y_pred_train.flatten()  # 确保y_pred_train是一维\n",
        "y_test = y_test.flatten()  # 确保y_test是一维\n",
        "y_pred_test = y_pred_test.flatten()  # 确保y_pred_test是一维\n",
        "\n",
        "# 创建一个包含训练集和测试集真实值与预测值的数据框\n",
        "data_train = pd.DataFrame({\n",
        "    'True': y_train,\n",
        "    'Predicted': y_pred_train,\n",
        "    'Data Set': 'Train'\n",
        "})\n",
        "\n",
        "data_test = pd.DataFrame({\n",
        "    'True': y_test,\n",
        "    'Predicted': y_pred_test,\n",
        "    'Data Set': 'Test'\n",
        "})\n",
        "\n",
        "data = pd.concat([data_train, data_test])\n",
        "\n",
        "# 自定义调色板\n",
        "palette = {'Train': '#b4d4e1', 'Test': '#f4ba8a'}\n",
        "\n",
        "# 创建 JointGrid 对象\n",
        "plt.figure(figsize=(8, 6), dpi=1200)\n",
        "g = sns.JointGrid(data=data, x=\"True\", y=\"Predicted\", hue=\"Data Set\", height=10, palette=palette)\n",
        "\n",
        "# 绘制中心的散点图\n",
        "g.plot_joint(sns.scatterplot, alpha=0.5)\n",
        "# 添加训练集的回归线\n",
        "sns.regplot(data=data_train, x=\"True\", y=\"Predicted\", scatter=False, ax=g.ax_joint, color='#b4d4e1', label='Train Regression Line')\n",
        "# 添加测试集的回归线\n",
        "sns.regplot(data=data_test, x=\"True\", y=\"Predicted\", scatter=False, ax=g.ax_joint, color='#f4ba8a', label='Test Regression Line')\n",
        "# 添加边缘的柱状图\n",
        "g.plot_marginals(sns.histplot, kde=False, element='bars', multiple='stack', alpha=0.5)\n",
        "\n",
        "# 添加拟合优度文本在右下角\n",
        "ax = g.ax_joint\n",
        "ax.text(0.95, 0.1, f'Train $R^2$ = {r2_train:.3f}', transform=ax.transAxes, fontsize=12,\n",
        "        verticalalignment='bottom', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
        "ax.text(0.95, 0.05, f'Test $R^2$ = {r2_test:.3f}', transform=ax.transAxes, fontsize=12,\n",
        "        verticalalignment='bottom', horizontalalignment='right', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
        "# 在左上角添加模型名称文本\n",
        "ax.text(0.75, 0.99, 'Model = CNN', transform=ax.transAxes, fontsize=12,\n",
        "        verticalalignment='top', horizontalalignment='left', bbox=dict(boxstyle=\"round,pad=0.3\", edgecolor=\"black\", facecolor=\"white\"))\n",
        "\n",
        "# 添加中心线\n",
        "ax.plot([data['True'].min(), data['True'].max()], [data['True'].min(), data['True'].max()], c=\"black\", alpha=0.5, linestyle='--', label='x=y')\n",
        "ax.legend()\n",
        "plt.savefig(\"TrueFalse.pdf\", format='pdf', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "XleQj5mebf97"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 环形图和条形图组合绘图"
      ],
      "metadata": {
        "id": "OI1pSLlJbxnV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "通过组合柱状图和同心饼图的方式，直观展示各个特征在模型中的贡献度，以及各个类别对模型的整体贡献。柱状图显示特征的详细贡献，饼图则提供了类别层面的总体贡献展示，使得用户能够从全局和细节两方面理解特征的重要性，**这里读者其实是不需要单独去绘制环形图和条形图的，**作者只是为了让读者更方便理解，其次这里的环形图和文献的环形图刚好是相反的，作者这里外圈是特征类别总贡献度，内圈是各个特征具体的贡献度映射，对于模型解读并没有区别\n",
        "\n",
        "可视化解读：年龄（age）作为“基本信息”类别的特征贡献度最高，DFA作为“非线性”特征也具有显著贡献，外圈饼图显示“基本信息”类别占总贡献的 71.5%，而“非线性”特征占 20%，其余类别如“噪声”、“抖动”和“振幅”特征的贡献较小，内圈的特征贡献进一步细分了各类别中具体特征的贡献度，帮助直观理解特征对模型预测的重要性。需要注意的是，这个结果基于演示用的复现数据，对于实际生活中的情况并不一定具有直接的参考价值"
      ],
      "metadata": {
        "id": "DvIMiI3rb6_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# shap原始特征贡献可视化\n",
        "\n",
        "import shap\n",
        "# 构建 shap解释器\n",
        "# shap.DeepExplainer 专门用于深度学习模型，如神经网络。它基于 SHAP 和 DeepLIFT 算法，能够有效地计算深度学习模型的 SHAP 值。 DeepExplainer 会自动处理模型的内部结构，计算每个特征对预测结果的影响。\n",
        "# 在使用 DeepExplainer 时，通常只需要提供两个参数，分别是：模型对象和训练数据集。其中，model 是训练好的深度学习模型，X_train 是训练数据集。\n",
        "explainer = shap.DeepExplainer(bmodel, X_train)\n",
        "\n",
        "# 计算测试集的shap值\n",
        "# 对于回归问题，shap_values是一个形状为(num_samples, num_features)的数组。\n",
        "# 检查shap_values的维度，并确保shap_values是一个二维数组，包含了每个样本和每个特征的贡献值。\n",
        "shap_values = explainer.shap_values(X_test)\n",
        "\n",
        "# # 特征标签\n",
        "# 假设有6个特征\n",
        "labels_columns = ['Height', 'Mean_HH_DirMean', 'Mean_HV_DirMean', 'RLD_20', 'sigmadB_HV', 'SinAspect']\n",
        "\n",
        "# # 绘制SHAP值总结图（Summary Plot）\n",
        "# plt.figure(figsize=(15, 5))\n",
        "# shap.summary_plot(shap_values, X_test, plot_type=\"bar\", show=False)\n",
        "# plt.title(\"SHAP_Feature_Importance_Raw_Output\")\n",
        "# plt.savefig(\"SHAP_Feature_Importance_Raw_Output.pdf\", format='pdf',bbox_inches='tight')\n",
        "# plt.show()\n",
        "\n",
        "\n",
        "# 打印 SHAP 值的形状，检查它的维度\n",
        "print(shap_values.shape)  # 输出形状 (11722, 6, 1)\n",
        "# 这种情况下就转变为了\"如何正确计算每个特征的平均 SHAP 值\"\n",
        "\n",
        "# 如果 SHAP 值是三维数组，选择第一维来计算贡献度\n",
        "# 对每个特征的贡献度求绝对值的平均\n",
        "# feature_contributions = np.abs(shap_values).mean(axis=0)\n",
        "# 计算每个特征的平均贡献度，取绝对值并在样本维度（axis=0）求平均\n",
        "feature_contributions = np.abs(shap_values).mean(axis=0).flatten()\n",
        "\n",
        "# 确保feature_contributions是一个一维数组，这样在创建DataFrame时，数据的维度是匹配的。\n",
        "# 创建一个DataFrame，其中一列是特征名，另一列是特征贡献度\n",
        "contribution_df = pd.DataFrame({\n",
        "    'Feature': labels_columns,\n",
        "    'Contribution': feature_contributions\n",
        "})\n",
        "\n",
        "# 创建类别规则\n",
        "Category = ['Terrain', 'texture', 'Backscattering']\n",
        "\n",
        "# 特征对应的类别\n",
        "category_map = {\n",
        "    'Height': 'Terrain',\n",
        "    'Mean_HH_DirMean': 'texture',\n",
        "    'Mean_HV_DirMean': 'texture',\n",
        "    'RLD_20': 'Terrain',\n",
        "    'sigmadB_HV': 'Backscattering',\n",
        "    'SinAspect': 'Terrain'\n",
        "}\n",
        "\n",
        "# 将类别映射到DataFrame\n",
        "contribution_df['Category'] = contribution_df['Feature'].map(category_map)\n",
        "\n",
        "# 打印 DataFrame\n",
        "print(contribution_df)\n",
        "# contribution_df\n"
      ],
      "metadata": {
        "id": "2SaUcN674FQ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
        "\n",
        "# 环形图和条形图组合绘图\n",
        "# 按类别和贡献度对数据进行排序，确保同一类别的特征在一起，贡献度从高到低排列\n",
        "contribution_df_sorted = contribution_df.sort_values(by=['Category', 'Contribution'], ascending=[True, False])\n",
        "\n",
        "# 创建一个用于生成颜色渐变的函数\n",
        "def get_color_gradient(base_color, num_shades):\n",
        "    # 生成从浅到深的颜色渐变\n",
        "    gradient = np.linspace(0.4, 1, num_shades)  # 生成从较浅（0.4）到原色（1）的渐变\n",
        "    return [(base_color[0], base_color[1], base_color[2], shade) for shade in gradient]\n",
        "\n",
        "# 为三个类别定义颜色\n",
        "category_colors = {\n",
        "    'Terrain': (0.9, 0.7, 0.2, 1),  # 黄色\n",
        "    # 'texture': (0.6, 0.3, 0.9, 1),     # 紫色\n",
        "    'texture': (0.7, 0.3, 0.3, 1),      # 暗红\n",
        "    # 'Non-linear': (0.2, 0.9, 0.9, 1), # 青色\n",
        "    'Backscattering': (0.3, 0.6, 0.9, 1),    # 浅蓝\n",
        "}\n",
        "\n",
        "# 默认颜色，如果类别未定义时使用\n",
        "default_color = (0.8, 0.8, 0.8, 1)  # 灰色\n",
        "\n",
        "# 获取内圈和外圈的贡献度数据\n",
        "inner_contribution = contribution_df_sorted.groupby('Category')['Contribution'].sum()\n",
        "outer_contribution = contribution_df_sorted.set_index('Feature')['Contribution']\n",
        "\n",
        "# 检查是否有未定义的类别\n",
        "undefined_categories = set(inner_contribution.index) - set(category_colors.keys())\n",
        "if undefined_categories:\n",
        "    print(f\"Warning: 以下类别没有定义颜色，将使用默认颜色: {undefined_categories}\")\n",
        "\n",
        "# 为每个类别在外圈创建颜色渐变\n",
        "outer_colors = []\n",
        "for category in inner_contribution.index:\n",
        "    # 选取当前类别的数据\n",
        "    category_df = contribution_df_sorted[contribution_df_sorted['Category'] == category]\n",
        "    # 获取类别的基础颜色，如果没有定义则使用默认颜色\n",
        "    base_color = category_colors.get(category, default_color)\n",
        "    # 为当前类别生成颜色渐变\n",
        "    gradient_colors = get_color_gradient(base_color, len(category_df))\n",
        "    outer_colors.extend(gradient_colors)\n",
        "\n",
        "# 内外圈的标签准备\n",
        "inner_labels = inner_contribution.index\n",
        "outer_labels = outer_contribution.index\n",
        "\n",
        "# 创建图形和子图\n",
        "# fig, ax = plt.subplots(figsize=(10, 8), dpi=1200)\n",
        "fig, ax = plt.subplots(figsize=(12, 10), dpi=1200)\n",
        "\n",
        "# 设置背景颜色为淡灰色\n",
        "ax.set_facecolor('#f0f0f0')\n",
        "\n",
        "# 添加网格线，设置网格线样式\n",
        "ax.grid(True, which='both', linestyle='--', linewidth=0.7, color='gray', alpha=0.7)\n",
        "\n",
        "\n",
        "# ---- 绘制柱状图 ----\n",
        "# 按贡献度从高到低排序\n",
        "contribution_df_sorted = contribution_df.sort_values(by='Contribution', ascending=False)\n",
        "\n",
        "# 准备颜色列表\n",
        "bar_colors = [category_colors.get(cat, (0.8, 0.8, 0.8, 1)) for cat in contribution_df_sorted['Category']]\n",
        "\n",
        "\n",
        "# 绘制条形图\n",
        "# 调整条形图的宽度，height=0.3 可以让条形图更窄\n",
        "ax.barh(contribution_df_sorted['Feature'], contribution_df_sorted['Contribution'], color=bar_colors, height=0.6)\n",
        "\n",
        "# 添加图例\n",
        "handles = [plt.Rectangle((0, 0), 1, 1, color=category_colors[cat]) for cat in category_colors]\n",
        "labels_columns = list(category_colors.keys())\n",
        "ax.legend(handles, labels_columns, loc='lower right')\n",
        "\n",
        "# 设置标签和标题\n",
        "ax.set_xlabel('Contribution')\n",
        "ax.set_ylabel('Feature')\n",
        "ax.set_title('Feature Contributions by Category')\n",
        "\n",
        "# 反转y轴，以便贡献度最大的特征在顶部\n",
        "ax.invert_yaxis()\n",
        "\n",
        "\n",
        "# ---- 在柱状图中嵌入同心饼图 ----\n",
        "\n",
        "# 为环形图创建嵌入坐标轴\n",
        "# width=2, height=2: 这定义了插图的宽度和高度为 2（单位是 inch，英寸）。因此，插图较小。\n",
        "# bbox_to_anchor 控制插图的位置和大小。\n",
        "# 0.8 和 0.35 指定插图的 左下角 在主图坐标系中的位置（相对于 ax 的坐标轴），表示插图将从主图的右侧偏移 80% 和从上面偏移 35%。\n",
        "# 0.2 和 0.2 是插图的宽度和高度比例，表示插图的大小是主图宽度和高度的 20%。\n",
        "inset_ax = inset_axes(ax, width=3, height=3, loc='upper right', bbox_to_anchor=(0.8, 0.35, 0.2, 0.2), bbox_transform=ax.transAxes)\n",
        "\n",
        "# 绘制内圈饼图（类别级别的饼图），显示百分比，不显示标签\n",
        "inset_ax.pie(inner_contribution, labels_columns=['']*len(inner_contribution), autopct='%1.1f%%', radius=1,\n",
        "       colors=[category_colors.get(cat, default_color) for cat in inner_labels],\n",
        "       wedgeprops=dict(width=0.3, edgecolor='w'),\n",
        "       pctdistance=0.85)  # 增加pctdistance来防止数字重叠\n",
        "\n",
        "# 绘制外圈饼图（特征级别的饼图），显示百分比，不显示标签\n",
        "inset_ax.pie(outer_contribution, labels_columns=['']*len(outer_contribution), autopct='%1.1f%%', radius=0.7,\n",
        "       colors=outer_colors,\n",
        "       wedgeprops=dict(width=0.3, edgecolor='w'),\n",
        "       pctdistance=0.75)  # 增加pctdistance来防止数字重叠\n",
        "\n",
        "\n",
        "# 添加白色中心圆，形成环形图\n",
        "inset_ax.add_artist(plt.Circle((0, 0), 0.4, color='white'))\n",
        "\n",
        "plt.savefig(\"CNN_Combined_Feature_Contributions_and_Circular_Chart.pdf\", format='pdf',bbox_inches='tight')\n",
        "\n",
        "# 显示图表\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "ZBw_GVxzbx7U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 启动 TensorBoard 可视化工具，查看训练过程中的详细信息，如损失曲线、准确率曲线、权重分布等。\n",
        "%tensorboard --logdir logs"
      ],
      "metadata": {
        "id": "pdRlGEdT-YKy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ypred_cnn[:] 和 labels[:] 都是对数组的切片操作，表示返回数组中的所有元素，分别是预测值和真实标签值。\n",
        "# 无论数组的维度是多少，使用 [:] 都是返回数组中的所有元素。这是 NumPy 中的一个常见用法，它用于获取数组的完整内容，不论数组是多维的。(保持其原有的形状。)\n",
        "\n",
        "# 计算预测结果的均值\n",
        "# ypred_cnn 的形状应为 (n, 1)，即一个列向量，每一行代表一个样本的预测结果。如果你打印 ypred_cnn[:]，你将得到模型对所有测试样本的预测结果。\n",
        "mean_cnn = np.mean(y_pred_cnn[:]) #calculate mean\n",
        "# 计算预测结果的分位数\n",
        "quantiles_cnn = np.percentile(y_pred_cnn[:], [1, 25, 50, 75, 99]) #calculate quantiles 0.01, 0.25, 0.5, 0.75, 0.99\n",
        "\n",
        "# 计算标签的均值\n",
        "# labels 是一个形状为 (n,) 的一维数组，存储了对应测试样本的实际标签（真实的森林高度）。\n",
        "# labels[:] 会返回所有的标签值。\n",
        "mean_labels = np.mean(labels[:])\n",
        "# 计算标签的分位数\n",
        "quantiles_labels = np.percentile(labels[:], [1, 25, 50, 75, 99])\n",
        "\n",
        "print(mean_cnn)\n",
        "print(quantiles_cnn)\n",
        "# 打印预测值中最小的 10 个和最大的 10 个。\n",
        "print(np.sort(y_pred_cnn.flatten())[:10]) #print the 10 lowest predictions\n",
        "print(np.sort(y_pred_cnn.flatten())[-10:][::-1]) #print the 10 highest predictions\n",
        "\n",
        "print(mean_labels)\n",
        "print(quantiles_labels)\n",
        "# 打印标签中最小的 10 个和最大的 10 个。\n",
        "print(np.sort(labels.flatten())[:10])\n",
        "print(np.sort(labels.flatten())[-10:][::-1])"
      ],
      "metadata": {
        "id": "8UxLzttK-YW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction of test image convolutional neural network"
      ],
      "metadata": {
        "id": "p6KsTP1zOBQQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这里使用的直接是前面NN模型中为了对测试图像进行预测从而对测试图像进行分割所得的测试图像块，测试图像的大小为1024*1024，通道数为11，即形状为（11，1024，1024）。\n",
        "\n",
        "所以下面的代码中 X 的形状才为（11，1024，1024）。"
      ],
      "metadata": {
        "id": "mmw_FGAvOJDe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 加载训练好的模型并预测"
      ],
      "metadata": {
        "id": "AsZa9PKUN6g-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # 加载测试数据并切分为图像块（patches）\n",
        "\n",
        "# # 设置存储图像块的文件夹路径\n",
        "# folder_path = '/content/drive/My Drive/data/images/'  # 文件夹路径，存放测试图像块\n",
        "# # 加载训练好的模型\n",
        "# cnnmodel = load_model('/content/drive/My Drive/forest_height/models/CNNmodels/best_CNNmodel_Std.keras')  # 加载已经训练好的CNN模型\n",
        "# # 初始化索引变量，用于保存预测结果\n",
        "# ind = 0\n",
        "\n",
        "# # Iterate over the files in the folder\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     file_path = os.path.join(folder_path, filename)\n",
        "#     if os.path.isfile(file_path):\n",
        "#       X = np.load(file_path)\n",
        "\n",
        "#       #  不需要额外进行标准化这一步，因为在CNN模型中内置了标准化层\n",
        "\n",
        "#       # 零填充\n",
        "#       # 因为卷积神经网络通常需要固定大小的输入，为了符合网络输入要求，这里对图像块 X 零填充\n",
        "#       # 这里的 pad_width 是一个 元组，它描述了三个维度的填充方式。即在通道维度上不进行填充，图像的通道数不改变，维度保持不变。在第二和第三个轴上(即 高度维度 和 宽度维度)进行宽度为 2 的填充, 填充的大小为 (2, 2)，意味着在每个图像高度的上方和下方和宽度的左侧和右侧各添加 2 行/列的零。因此，图像的高度会增加 4 个像素, 图像的宽度会增加 4 个像素。这样做的目的是为了保证卷积操作的窗口大小不变。\n",
        "#       # Pad width of 2 on the second and third axes to (6, 1028, 1028) to get output of shape (6, 1024, 1024) with a window of size 5\n",
        "#       pad_width = ((0, 0), (2, 2), (2, 2))  # Pad width of 2 on the second and third axes to (6, 1028, 1028) to get output of shape (9, 1024, 1024) with a window of size 5\n",
        "#       # mode='constant' 表示使用常数值填充。constant_values=0 指定填充的常数值为 0。\n",
        "#       # 经过填充后的图像形状将变为 (6, 1028, 1028)。\n",
        "#       X = np.pad(X, pad_width, mode='constant', constant_values=0)\n",
        "\n",
        "#       # 获取图像的高度和宽度, 也就可以看出这个 X 的形状为(channels, height, width)\n",
        "#       height, width = X.shape[1], X.shape[2] #get height an width of the image\n",
        "\n",
        "#       from skimage.util import view_as_windows\n",
        "#       # 下面这段通过双重循环切割窗口的方法可以使用更简洁的滑动窗口生成方法，利用skimage.util.view_as_windows 生成滑动窗口。\n",
        "#       # 使用滑动窗口生成图像块（更高效的方式）\n",
        "#       # 输入形状为 (channels, height, width) = (6, 1028, 1028)\n",
        "#       datat = view_as_windows(X, (6, 5, 5), step=1)\n",
        "#       datat = datat.reshape(-1, 5, 5, 6)  # 转换为 NHWC 格式\n",
        "#       # 预测\n",
        "#       pred = cnnmodel.predict(datat)\n",
        "\n",
        "#       # 重塑为原始图像大小 (1024, 1024)\n",
        "#       img = pred.reshape(1024, 1024)\n",
        "\n",
        "#       # 保存预测结果\n",
        "#       np.save(f'/content/drive/My Drive/forest_height/MaskCNN/mask_{ind}.npy', img)\n",
        "#       ind += 1\n",
        "\n",
        "#       # 打印预测图像的形状\n",
        "#       print(f\"预测图像形状: {img.shape}\")"
      ],
      "metadata": {
        "id": "g-BA-AS627eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # 加载测试数据并切分为图像块（patches）\n",
        "\n",
        "# # 设置存储图像块的文件夹路径\n",
        "# folder_path = '/content/drive/My Drive/data/images/'  # 文件夹路径，存放测试图像块\n",
        "# # 加载训练好的模型\n",
        "# cnnmodel = load_model('/content/drive/My Drive/forest_height/models/CNNmodels/best_CNNmodel_Std.keras')  # 加载已经训练好的CNN模型\n",
        "# # 初始化索引变量，用于保存预测结果\n",
        "# ind = 0\n",
        "\n",
        "# # Iterate over the files in the folder\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     file_path = os.path.join(folder_path, filename)\n",
        "#     if os.path.isfile(file_path):\n",
        "#       X = np.load(file_path)\n",
        "\n",
        "#       #  不需要额外进行标准化这一步，因为在CNN模型中内置了标准化层\n",
        "\n",
        "#       # 零填充\n",
        "#       # 因为卷积神经网络通常需要固定大小的输入，为了符合网络输入要求，这里对图像块 X 零填充\n",
        "#       # 这里的 pad_width 是一个 元组，它描述了三个维度的填充方式。即在通道维度上不进行填充，图像的通道数不改变，维度保持不变。在第二和第三个轴上(即 高度维度 和 宽度维度)进行宽度为 2 的填充, 填充的大小为 (2, 2)，意味着在每个图像高度的上方和下方和宽度的左侧和右侧各添加 2 行/列的零。因此，图像的高度会增加 4 个像素, 图像的宽度会增加 4 个像素。这样做的目的是为了保证卷积操作的窗口大小不变。\n",
        "#       # Pad width of 2 on the second and third axes to (6, 1028, 1028) to get output of shape (6, 1024, 1024) with a window of size 5\n",
        "#       pad_width = ((0, 0), (2, 2), (2, 2))  # Pad width of 2 on the second and third axes to (6, 1028, 1028) to get output of shape (6, 1024, 1024) with a window of size 5\n",
        "#       # mode='constant' 表示使用常数值填充。constant_values=0 指定填充的常数值为 0。\n",
        "#       # 经过填充后的图像形状将变为 (6, 1028, 1028)。\n",
        "#       X = np.pad(X, pad_width, mode='constant', constant_values=0)\n",
        "\n",
        "#       # 获取图像的高度和宽度, 也就可以看出这个 X 的形状为(channels, height, width)\n",
        "#       height, width = X.shape[1], X.shape[2] #get height an width of the image\n",
        "\n",
        "#       # 提取图像块的窗口\n",
        "#       # 定义窗口大小为 5x5\n",
        "#       window_size = 5\n",
        "#       # 定义窗口形状，6个通道（假设输入是6个通道），5x5窗口\n",
        "#       shape = (6, window_size, window_size)\n",
        "#       # 创建一个形状为 (6, 5, 5) 的数组，填充为1\n",
        "#       datat = np.ones(shape) #array for features\n",
        "#       # 扩展维度，使其成为 (1, 6, 5, 5)\n",
        "#       datat = np.expand_dims(datat, axis=0)\n",
        "\n",
        "#       # 对图像进行切割，提取滑动窗口\n",
        "\n",
        "#       # 选择第一行（6, 5, 5）的窗口（这里的第一行指的是将所有的图像块提取出来拼接后，这部分代码提取出来的就是该拼接图像的第一行图像）\n",
        "#       for w in range(width - window_size + 1): # select the first row (6, 5, 5) patches\n",
        "#         # 从图像中提取一个5x5的窗口\n",
        "#         # w 就是滑动窗口的左端点（注意是左端点，所以没问题），每次 w 增加 1，表示窗口向右滑动 1 个像素。\n",
        "#         sample = X[:, 0:window_size, w:w+window_size]\n",
        "#         sample2 = np.expand_dims(sample, axis=0)\n",
        "#         datat = np.concatenate((datat, sample2), axis=0)\n",
        "\n",
        "#       datat = datat[1:,:,:,:] #remove the first artificial patch\n",
        "\n",
        "#       # 遍历每一行\n",
        "#       # 对图像的每一行进行处理，提取窗口（注意：这里的每一行指的就不是刚才那个拼接窗口的图像了，而是指输入进行窗口切割的图像）\n",
        "#       # 这里height - window_size而不是height - window_size + 1 是因为上一段代码已经提取出来了第一行（6, 5, 5）的窗口，所以循环次数少1\n",
        "#       for h in range(height - window_size): # iterate over the rows\n",
        "#         # 创建一个形状为 (6, 1, 5) 的空数组\n",
        "#         shape = (6, 1, window_size)\n",
        "#         datat2 = np.ones(shape) #array for the values of one row\n",
        "#         # 扩展维度，使其成为 (1, 6, 1, 5)\n",
        "#         datat2 = np.expand_dims(datat2, axis=0)\n",
        "#         # 遍历每一列\n",
        "#         for w in range(width - window_size  + 1): # iterate over the columns\n",
        "#           # 提取窗口\n",
        "#           # sample 的形状是 (6, window_size)\n",
        "#           # 由于你只选择了一个高度索引（h+window_size），所以返回的是一个 (6, window_size) 的数组。6 是通道数，window_size 是窗口大小（即列数）\n",
        "#           # Python 和 NumPy 通常会“自动去掉”维度为 1 的通道（即，当某个维度的大小为 1 时，这个维度可能被省略）。\n",
        "#           sample = X[:, h+window_size, w:w+window_size]\n",
        "#           # 扩展维度，变为 (6, 1, window_size)\n",
        "#           sample = np.expand_dims(sample, axis=1)\n",
        "#           # 扩展维度，变为 (1, 6, 1, window_size)\n",
        "#           # 第一维度 1 代表了“批量大小”（batch size），意味着这个样本是一个单独的样本，且是批处理的一部分。\n",
        "#           # 第三维度 1 代表了窗口的高度（即对单行窗口的处理）。\n",
        "#           sample = np.expand_dims(sample, axis=0)\n",
        "#           # 将窗口添加到 datat2 数组中\n",
        "#           datat2 = np.concatenate((datat2, sample), axis=0) #collect values from one row\n",
        "\n",
        "#         # 拼接前一行的处理结果（即 datat）和当前行的窗口数据（即 datat2）。\n",
        "#         # 这个操作与处理行 h 相关，确保从前一行的结果中正确地选择出窗口数据。这里的 h 是当前行的索引。\n",
        "#         # 这部分代码确实没错，因为 datat 是最终存储拼接图像块的数组（注意这个拼接图像块是一行一行拼接的，不是一个一个拼接的），而这里构建每一行的图像块是采取的保留前一行图像块的后 size -1 行高度，然后再拼接新的当前高度的图像块。\n",
        "#         # 而保留前一行图像块，则需要将前面剩余行的图像块删去即使用 datat的(width-window_size+1)*h: 来实现。而保留前一块图像块中的后 size - 1 行高度，则使用 datat 的1: 来实现。\n",
        "#         datat4 = np.concatenate((datat[(width-window_size+1)*h:,:,1:,:], datat2[1:,:,:,:]), axis=2) #remove the first column from the previous row patches and add a new row below\n",
        "#         datat = np.concatenate((datat, datat4), axis=0) #stack the patches\n",
        "\n",
        "\n",
        "#       # 我前面定义的 CNN 模型输入形状为 (5, 5, 6)（NHWC 格式），但测试代码中的图像块 datat 形状为 (n, 6, 5, 5)（NCHW 格式）。需转换为 NHWC 格式。\n",
        "#       # 将通道维度移到最后一维，转换为 (n, 5, 5, 6)\n",
        "#       datat = datat.transpose(0, 2, 3, 1)\n",
        "\n",
        "#       # 使用CNN模型进行预测\n",
        "#       # 如果您传入的 datat 形状是 (n, 6, 5, 5)，则经过卷积层和池化层后，最终输出的形状为 (n, 1)，其中 n 是样本的数量（即输入数据的批大小）。\n",
        "#       # 返回的预测结果是一个形状为 (num_samples, 1) 的数组，其中每一行是一个预测的标量值。\n",
        "#       pred = cnnmodel.predict(datat) #predict labels\n",
        "#       # 重塑预测结果为原始图像大小\n",
        "#       img = pred.transpose().reshape(1,1024,1024) #reshape image to original size\n",
        "\n",
        "#       # 保存预测结果\n",
        "#       np.save('/content/drive/My Drive/forest_height/MaskCNN/mask_'+ str(ind) + '.npy', img)\n",
        "#       # 更新索引\n",
        "#       ind = ind + 1\n",
        "#       # 打印预测图像的形状\n",
        "#       print(img.shape) #metrics to control the prediction process for every patch image\n",
        "#       # 输出预测值的分位数\n",
        "#       print(np.percentile(pred[:], [1, 25, 50, 75, 99]))\n",
        "#        # 输出最小的10个预测值\n",
        "#       print(np.sort(pred.flatten())[:10])\n",
        "#       # 输出最大的10个预测值\n",
        "#       print(np.sort(pred.flatten())[-10:][::-1])\n",
        "\n"
      ],
      "metadata": {
        "id": "CZgOUaviN7IY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 重建预测图像并保存"
      ],
      "metadata": {
        "id": "yUmYpppjObu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# folder_path = '/content/drive/My Drive/forest_height/MaskCNN/'  #folder path\n",
        "# img_list = []\n",
        "\n",
        "# # Iterate over the files in the folder\n",
        "# for filename in os.listdir(folder_path):\n",
        "#     file_path = os.path.join(folder_path, filename)\n",
        "#     if os.path.isfile(file_path):\n",
        "#         # Load the data from the file\n",
        "#         data = np.load(file_path)\n",
        "#         # Append the data to the list\n",
        "#         img_list.append(data)  #将预测结果添加到列表中\n",
        "\n",
        "# # 我有 143 个切片（按 13 x 11 进行排列），可以利用这些切片的索引按列和按行拼接来恢复完整的图像。\n",
        "# # 假设img_list包含所有的切片，已经按正确顺序加载\n",
        "# m = 11  # 高度方向的切片数量\n",
        "# n = 13  # 宽度方向的切片数量\n",
        "\n",
        "# # 将每13个图像块按列(宽度方向)拼接\n",
        "# # Concatenate the patches along the columns (horizontal axis)\n",
        "# # 按列拼接每行的切片\n",
        "# rows = []\n",
        "# for i in range(m):\n",
        "#     row = np.concatenate(img_list[i*n:(i+1)*n], axis=2)  # 按列拼接\n",
        "#     rows.append(row)\n",
        "\n",
        "# # 按行拼接\n",
        "# original_image = np.concatenate(rows, axis=1)  # 按行拼接\n",
        "\n",
        "# # # Concatenate the patches along the columns (horizontal axis)\n",
        "# # im1 = np.concatenate((img_list[0], img_list[1], img_list[2], img_list[3]), axis=2)\n",
        "# # im2 = np.concatenate((img_list[4], img_list[5], img_list[6], img_list[7]), axis=2)\n",
        "# # im3= np.concatenate((img_list[8], img_list[9], img_list[10], img_list[11]), axis=2)\n",
        "# # im4 = np.concatenate((img_list[12], img_list[13], img_list[14], img_list[15]), axis=2)\n",
        "\n",
        "# # # Concatenate the rows along the vertical axis to rebuild the original image\n",
        "# # original_image = np.concatenate((im1, im2, im3, im4), axis=1)\n",
        "\n",
        "# np.save('/content/drive/My Drive/forest_height/MaskCNN/FinalPredictions/mask_private_cnn.npy', original_image)\n"
      ],
      "metadata": {
        "id": "MKFOntX-Oc46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 可视化预测结果"
      ],
      "metadata": {
        "id": "BfrKMA2JOdXJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# plot_rebuild_image = np.load('/content/drive/My Drive/forest_height/MaskCNN/FinalPredictions/mask_private_cnn.npy')\n",
        "# # 将重建的预测图像由 (1, height, width) 转换为 (height, width)\n",
        "# tree_height_2d = plot_rebuild_image[0]\n",
        "\n",
        "# # Plot the tree height data\n",
        "# plt.imshow(tree_height_2d, cmap='viridis')\n",
        "\n",
        "# # Add colorbar for reference\n",
        "# plt.colorbar() # 添加颜色条\n",
        "\n",
        "# # Display the plot\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "iyABn8QEOqBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 输出预测结果的分位数和极值"
      ],
      "metadata": {
        "id": "UwNO5iPMOqu-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# print(np.percentile(plot_rebuild_image[:], [1, 25, 50, 75, 99])) #calculate quantiles 0.01, 0.25, 0.5, 0.75, 0.99\n",
        "\n",
        "# print(np.sort(plot_rebuild_image.flatten())[:10]) #print the 10 lowest predictions\n",
        "# print(np.sort(plot_rebuild_image.flatten())[-10:][::-1]) #print the 10 highest predictions"
      ],
      "metadata": {
        "id": "kllUjn7UOyhi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# 保存带有输出的 notebook 文件到 Google Drive\n",
        "!jupyter nbconvert --to pdf \"/content/drive/My Drive/Colab Notebooks/NNandCNN_FeatureNormalization.ipynb\"\n"
      ],
      "metadata": {
        "id": "LDhRE8D43uM7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}